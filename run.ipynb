{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = None\n",
    "RUNS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: tape-arxiv-2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"arxiv_2023\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !WANDB_DISABLED=True TOKENIZERS_PARALLELISM=False CUDA_VISIBLE_DEVICES=0 python -m core.trainLM dataset $dataset seed $SEED runs $RUNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !WANDB_DISABLED=True TOKENIZERS_PARALLELISM=False CUDA_VISIBLE_DEVICES=0 python -m core.trainLM dataset $dataset seed $SEED runs $RUNS lm.train.use_gpt True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Node2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running train at 05-22 10:46:39\n",
      "Epoch: 0, Time: 21.0059, Loss: 4.0978, TrainAcc: 0.2275, ValAcc: 0.2246, ES: \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 35, in <module>\n",
      "    main(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 18, in main\n",
      "    trainer.train()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/utils.py\", line 80, in wrapper\n",
      "    ret = func(*args, **kw)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 106, in train\n",
      "    val_acc, _, _ = self._evaluate()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 88, in _evaluate\n",
      "    test_acc = self.model.test(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch_geometric/nn/models/node2vec.py\", line 185, in test\n",
      "    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1302, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 452, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 359, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 279, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 253, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainNode2Vec dataset $dataset seed $SEED runs $RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP and GNNs on TAPE Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:11:30\n",
      "Epoch: 0, Time: 0.8543, Loss: 3.8062, TrainAcc: 0.0360, ValAcc: 0.3172, ES: 00/50 | BestVal=0.3172@E0\n",
      "Epoch: 10, Time: 0.0312, Loss: 1.7327, TrainAcc: 0.6547, ValAcc: 0.6750, ES: 05/50 | BestVal=0.6880@E5\n",
      "Epoch: 20, Time: 0.0137, Loss: 1.3013, TrainAcc: 0.7018, ValAcc: 0.7052, ES: 00/50 | BestVal=0.7052@E20\n",
      "Epoch: 30, Time: 0.0130, Loss: 1.1162, TrainAcc: 0.7451, ValAcc: 0.7218, ES: 00/50 | BestVal=0.7218@E30\n",
      "Epoch: 40, Time: 0.0130, Loss: 1.0096, TrainAcc: 0.7696, ValAcc: 0.7351, ES: 00/50 | BestVal=0.7351@E40\n",
      "Epoch: 50, Time: 0.0134, Loss: 0.9385, TrainAcc: 0.7855, ValAcc: 0.7500, ES: 00/50 | BestVal=0.7500@E50\n",
      "Epoch: 60, Time: 0.0109, Loss: 0.8777, TrainAcc: 0.7985, ValAcc: 0.7512, ES: 02/50 | BestVal=0.7516@E58\n",
      "Epoch: 70, Time: 0.0133, Loss: 0.8329, TrainAcc: 0.8039, ValAcc: 0.7557, ES: 00/50 | BestVal=0.7557@E70\n",
      "Epoch: 80, Time: 0.0129, Loss: 0.7965, TrainAcc: 0.8159, ValAcc: 0.7602, ES: 00/50 | BestVal=0.7602@E80\n",
      "Epoch: 90, Time: 0.0130, Loss: 0.7664, TrainAcc: 0.8190, ValAcc: 0.7615, ES: 00/50 | BestVal=0.7615@E90\n",
      "Epoch: 100, Time: 0.0108, Loss: 0.7353, TrainAcc: 0.8242, ValAcc: 0.7634, ES: 01/50 | BestVal=0.7642@E99\n",
      "Epoch: 110, Time: 0.0127, Loss: 0.7061, TrainAcc: 0.8310, ValAcc: 0.7677, ES: 00/50 | BestVal=0.7677@E110\n",
      "Epoch: 120, Time: 0.0150, Loss: 0.6793, TrainAcc: 0.8364, ValAcc: 0.7697, ES: 03/50 | BestVal=0.7700@E117\n",
      "Epoch: 130, Time: 0.0167, Loss: 0.6634, TrainAcc: 0.8380, ValAcc: 0.7728, ES: 00/50 | BestVal=0.7728@E130\n",
      "Epoch: 140, Time: 0.0105, Loss: 0.6427, TrainAcc: 0.8418, ValAcc: 0.7738, ES: 01/50 | BestVal=0.7742@E139\n",
      "Epoch: 150, Time: 0.0104, Loss: 0.6241, TrainAcc: 0.8473, ValAcc: 0.7726, ES: 11/50 | BestVal=0.7742@E139\n",
      "Epoch: 160, Time: 0.0127, Loss: 0.6053, TrainAcc: 0.8519, ValAcc: 0.7749, ES: 00/50 | BestVal=0.7749@E160\n",
      "Epoch: 170, Time: 0.0105, Loss: 0.5906, TrainAcc: 0.8529, ValAcc: 0.7748, ES: 01/50 | BestVal=0.7753@E169\n",
      "Epoch: 180, Time: 0.0109, Loss: 0.5693, TrainAcc: 0.8596, ValAcc: 0.7760, ES: 05/50 | BestVal=0.7779@E175\n",
      "Epoch: 190, Time: 0.0110, Loss: 0.5652, TrainAcc: 0.8601, ValAcc: 0.7754, ES: 15/50 | BestVal=0.7779@E175\n",
      "Finished running train at 05-22 17:11:34, running time = 3.79s.\n",
      "[MLP + TA] ValAcc: 0.7779, TestAcc: 0.7776\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:11:35\n",
      "Epoch: 0, Time: 0.0155, Loss: 3.8845, TrainAcc: 0.0162, ValAcc: 0.0301, ES: 00/50 | BestVal=0.0301@E0\n",
      "Epoch: 10, Time: 0.0142, Loss: 1.9943, TrainAcc: 0.5804, ValAcc: 0.6084, ES: 00/50 | BestVal=0.6084@E10\n",
      "Epoch: 20, Time: 0.0145, Loss: 1.6527, TrainAcc: 0.6143, ValAcc: 0.6325, ES: 00/50 | BestVal=0.6325@E20\n",
      "Epoch: 30, Time: 0.0145, Loss: 1.5014, TrainAcc: 0.6355, ValAcc: 0.6576, ES: 00/50 | BestVal=0.6576@E30\n",
      "Epoch: 40, Time: 0.0149, Loss: 1.3962, TrainAcc: 0.6569, ValAcc: 0.6808, ES: 00/50 | BestVal=0.6808@E40\n",
      "Epoch: 50, Time: 0.0144, Loss: 1.3164, TrainAcc: 0.6738, ValAcc: 0.7144, ES: 00/50 | BestVal=0.7144@E50\n",
      "Epoch: 60, Time: 0.0137, Loss: 1.2543, TrainAcc: 0.6852, ValAcc: 0.7265, ES: 01/50 | BestVal=0.7266@E59\n",
      "Epoch: 70, Time: 0.0141, Loss: 1.1946, TrainAcc: 0.6982, ValAcc: 0.7352, ES: 00/50 | BestVal=0.7352@E70\n",
      "Epoch: 80, Time: 0.0127, Loss: 1.1492, TrainAcc: 0.7098, ValAcc: 0.7410, ES: 01/50 | BestVal=0.7415@E79\n",
      "Epoch: 90, Time: 0.0130, Loss: 1.1185, TrainAcc: 0.7144, ValAcc: 0.7422, ES: 03/50 | BestVal=0.7429@E87\n",
      "Epoch: 100, Time: 0.0144, Loss: 1.0840, TrainAcc: 0.7219, ValAcc: 0.7476, ES: 00/50 | BestVal=0.7476@E100\n",
      "Epoch: 110, Time: 0.0147, Loss: 1.0657, TrainAcc: 0.7241, ValAcc: 0.7487, ES: 00/50 | BestVal=0.7487@E110\n",
      "Epoch: 120, Time: 0.0128, Loss: 1.0465, TrainAcc: 0.7248, ValAcc: 0.7487, ES: 09/50 | BestVal=0.7488@E111\n",
      "Epoch: 130, Time: 0.0141, Loss: 1.0263, TrainAcc: 0.7278, ValAcc: 0.7506, ES: 00/50 | BestVal=0.7506@E130\n",
      "Epoch: 140, Time: 0.0130, Loss: 1.0120, TrainAcc: 0.7319, ValAcc: 0.7514, ES: 04/50 | BestVal=0.7518@E136\n",
      "Epoch: 150, Time: 0.0141, Loss: 1.0030, TrainAcc: 0.7323, ValAcc: 0.7541, ES: 00/50 | BestVal=0.7541@E150\n",
      "Epoch: 160, Time: 0.0124, Loss: 0.9910, TrainAcc: 0.7380, ValAcc: 0.7554, ES: 01/50 | BestVal=0.7560@E159\n",
      "Epoch: 170, Time: 0.0130, Loss: 0.9716, TrainAcc: 0.7373, ValAcc: 0.7563, ES: 05/50 | BestVal=0.7570@E165\n",
      "Epoch: 180, Time: 0.0128, Loss: 0.9660, TrainAcc: 0.7385, ValAcc: 0.7580, ES: 01/50 | BestVal=0.7584@E179\n",
      "Epoch: 190, Time: 0.0144, Loss: 0.9591, TrainAcc: 0.7411, ValAcc: 0.7591, ES: 00/50 | BestVal=0.7591@E190\n",
      "Finished running train at 05-22 17:11:38, running time = 2.78s.\n",
      "[MLP + P] ValAcc: 0.7595, TestAcc: 0.7498\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:11:39\n",
      "Epoch: 0, Time: 0.0129, Loss: 3.8326, TrainAcc: 0.0290, ValAcc: 0.3310, ES: 00/50 | BestVal=0.3310@E0\n",
      "Epoch: 10, Time: 0.0122, Loss: 1.7686, TrainAcc: 0.6424, ValAcc: 0.6938, ES: 00/50 | BestVal=0.6938@E10\n",
      "Epoch: 20, Time: 0.0127, Loss: 1.3677, TrainAcc: 0.6885, ValAcc: 0.7058, ES: 00/50 | BestVal=0.7058@E20\n",
      "Epoch: 30, Time: 0.0123, Loss: 1.2082, TrainAcc: 0.7218, ValAcc: 0.7259, ES: 00/50 | BestVal=0.7259@E30\n",
      "Epoch: 40, Time: 0.0127, Loss: 1.1109, TrainAcc: 0.7440, ValAcc: 0.7473, ES: 00/50 | BestVal=0.7473@E40\n",
      "Epoch: 50, Time: 0.0123, Loss: 1.0389, TrainAcc: 0.7628, ValAcc: 0.7534, ES: 00/50 | BestVal=0.7534@E50\n",
      "Epoch: 60, Time: 0.0110, Loss: 0.9829, TrainAcc: 0.7727, ValAcc: 0.7530, ES: 07/50 | BestVal=0.7540@E53\n",
      "Epoch: 70, Time: 0.0128, Loss: 0.9435, TrainAcc: 0.7789, ValAcc: 0.7540, ES: 00/50 | BestVal=0.7540@E70\n",
      "Epoch: 80, Time: 0.0122, Loss: 0.9135, TrainAcc: 0.7810, ValAcc: 0.7555, ES: 00/50 | BestVal=0.7555@E80\n",
      "Epoch: 90, Time: 0.0122, Loss: 0.8892, TrainAcc: 0.7877, ValAcc: 0.7590, ES: 00/50 | BestVal=0.7590@E90\n",
      "Epoch: 100, Time: 0.0105, Loss: 0.8617, TrainAcc: 0.7914, ValAcc: 0.7627, ES: 01/50 | BestVal=0.7628@E99\n",
      "Epoch: 110, Time: 0.0127, Loss: 0.8369, TrainAcc: 0.7970, ValAcc: 0.7670, ES: 00/50 | BestVal=0.7670@E110\n",
      "Epoch: 120, Time: 0.0111, Loss: 0.8176, TrainAcc: 0.7993, ValAcc: 0.7709, ES: 01/50 | BestVal=0.7711@E119\n",
      "Epoch: 130, Time: 0.0129, Loss: 0.7974, TrainAcc: 0.8047, ValAcc: 0.7728, ES: 00/50 | BestVal=0.7728@E130\n",
      "Epoch: 140, Time: 0.0109, Loss: 0.7798, TrainAcc: 0.8094, ValAcc: 0.7733, ES: 08/50 | BestVal=0.7737@E132\n",
      "Epoch: 150, Time: 0.0110, Loss: 0.7647, TrainAcc: 0.8114, ValAcc: 0.7732, ES: 05/50 | BestVal=0.7742@E145\n",
      "Epoch: 160, Time: 0.0110, Loss: 0.7473, TrainAcc: 0.8148, ValAcc: 0.7741, ES: 02/50 | BestVal=0.7749@E158\n",
      "Epoch: 170, Time: 0.0104, Loss: 0.7335, TrainAcc: 0.8153, ValAcc: 0.7751, ES: 02/50 | BestVal=0.7777@E168\n",
      "Epoch: 180, Time: 0.0108, Loss: 0.7194, TrainAcc: 0.8214, ValAcc: 0.7759, ES: 12/50 | BestVal=0.7777@E168\n",
      "Epoch: 190, Time: 0.0109, Loss: 0.7115, TrainAcc: 0.8231, ValAcc: 0.7747, ES: 22/50 | BestVal=0.7777@E168\n",
      "Finished running train at 05-22 17:11:41, running time = 2.37s.\n",
      "[MLP + E] ValAcc: 0.7777, TestAcc: 0.7713\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7965, TestAcc: 0.7969\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:11:44\n",
      "Epoch: 0, Time: 0.0224, Loss: 3.8708, TrainAcc: 0.0165, ValAcc: 0.0634, ES: 00/50 | BestVal=0.0634@E0\n",
      "Epoch: 10, Time: 0.0112, Loss: 1.6516, TrainAcc: 0.6951, ValAcc: 0.7066, ES: 06/50 | BestVal=0.7166@E4\n",
      "Epoch: 20, Time: 0.0129, Loss: 1.2245, TrainAcc: 0.7343, ValAcc: 0.7177, ES: 00/50 | BestVal=0.7177@E20\n",
      "Epoch: 30, Time: 0.0122, Loss: 1.0341, TrainAcc: 0.7716, ValAcc: 0.7367, ES: 00/50 | BestVal=0.7367@E30\n",
      "Epoch: 40, Time: 0.0130, Loss: 0.9237, TrainAcc: 0.7987, ValAcc: 0.7457, ES: 00/50 | BestVal=0.7457@E40\n",
      "Epoch: 50, Time: 0.0127, Loss: 0.8475, TrainAcc: 0.8165, ValAcc: 0.7548, ES: 00/50 | BestVal=0.7548@E50\n",
      "Epoch: 60, Time: 0.0113, Loss: 0.7929, TrainAcc: 0.8270, ValAcc: 0.7581, ES: 01/50 | BestVal=0.7582@E59\n",
      "Epoch: 70, Time: 0.0125, Loss: 0.7491, TrainAcc: 0.8345, ValAcc: 0.7585, ES: 00/50 | BestVal=0.7585@E70\n",
      "Epoch: 80, Time: 0.0128, Loss: 0.7204, TrainAcc: 0.8389, ValAcc: 0.7621, ES: 00/50 | BestVal=0.7621@E80\n",
      "Epoch: 90, Time: 0.0113, Loss: 0.6900, TrainAcc: 0.8439, ValAcc: 0.7650, ES: 01/50 | BestVal=0.7653@E89\n",
      "Epoch: 100, Time: 0.0127, Loss: 0.6621, TrainAcc: 0.8473, ValAcc: 0.7683, ES: 00/50 | BestVal=0.7683@E100\n",
      "Epoch: 110, Time: 0.0105, Loss: 0.6418, TrainAcc: 0.8544, ValAcc: 0.7689, ES: 06/50 | BestVal=0.7700@E104\n",
      "Epoch: 120, Time: 0.0122, Loss: 0.6144, TrainAcc: 0.8590, ValAcc: 0.7714, ES: 00/50 | BestVal=0.7714@E120\n",
      "Epoch: 130, Time: 0.0127, Loss: 0.5974, TrainAcc: 0.8623, ValAcc: 0.7732, ES: 00/50 | BestVal=0.7732@E130\n",
      "Epoch: 140, Time: 0.0127, Loss: 0.5753, TrainAcc: 0.8640, ValAcc: 0.7747, ES: 00/50 | BestVal=0.7747@E140\n",
      "Epoch: 150, Time: 0.0105, Loss: 0.5621, TrainAcc: 0.8679, ValAcc: 0.7761, ES: 02/50 | BestVal=0.7764@E148\n",
      "Epoch: 160, Time: 0.0128, Loss: 0.5415, TrainAcc: 0.8713, ValAcc: 0.7769, ES: 00/50 | BestVal=0.7769@E160\n",
      "Epoch: 170, Time: 0.0110, Loss: 0.5292, TrainAcc: 0.8768, ValAcc: 0.7778, ES: 01/50 | BestVal=0.7789@E169\n",
      "Epoch: 180, Time: 0.0108, Loss: 0.5153, TrainAcc: 0.8762, ValAcc: 0.7777, ES: 11/50 | BestVal=0.7789@E169\n",
      "Epoch: 190, Time: 0.0111, Loss: 0.5035, TrainAcc: 0.8816, ValAcc: 0.7767, ES: 02/50 | BestVal=0.7789@E188\n",
      "Finished running train at 05-22 17:11:46, running time = 2.41s.\n",
      "[MLP + TA] ValAcc: 0.7789, TestAcc: 0.7756\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:11:48\n",
      "Epoch: 0, Time: 0.0230, Loss: 3.8446, TrainAcc: 0.0250, ValAcc: 0.1364, ES: 00/50 | BestVal=0.1364@E0\n",
      "Epoch: 10, Time: 0.0124, Loss: 1.9699, TrainAcc: 0.5841, ValAcc: 0.6167, ES: 01/50 | BestVal=0.6171@E9\n",
      "Epoch: 20, Time: 0.0147, Loss: 1.6168, TrainAcc: 0.6209, ValAcc: 0.6510, ES: 00/50 | BestVal=0.6510@E20\n",
      "Epoch: 30, Time: 0.0142, Loss: 1.4620, TrainAcc: 0.6456, ValAcc: 0.6737, ES: 00/50 | BestVal=0.6737@E30\n",
      "Epoch: 40, Time: 0.0145, Loss: 1.3657, TrainAcc: 0.6652, ValAcc: 0.7001, ES: 00/50 | BestVal=0.7001@E40\n",
      "Epoch: 50, Time: 0.0140, Loss: 1.2844, TrainAcc: 0.6861, ValAcc: 0.7145, ES: 00/50 | BestVal=0.7145@E50\n",
      "Epoch: 60, Time: 0.0145, Loss: 1.2277, TrainAcc: 0.6967, ValAcc: 0.7275, ES: 00/50 | BestVal=0.7275@E60\n",
      "Epoch: 70, Time: 0.0141, Loss: 1.1796, TrainAcc: 0.7043, ValAcc: 0.7356, ES: 00/50 | BestVal=0.7356@E70\n",
      "Epoch: 80, Time: 0.0140, Loss: 1.1459, TrainAcc: 0.7108, ValAcc: 0.7369, ES: 00/50 | BestVal=0.7369@E80\n",
      "Epoch: 90, Time: 0.0127, Loss: 1.1124, TrainAcc: 0.7164, ValAcc: 0.7367, ES: 10/50 | BestVal=0.7369@E80\n",
      "Epoch: 100, Time: 0.0121, Loss: 1.0894, TrainAcc: 0.7178, ValAcc: 0.7361, ES: 09/50 | BestVal=0.7371@E91\n",
      "Epoch: 110, Time: 0.0123, Loss: 1.0617, TrainAcc: 0.7215, ValAcc: 0.7376, ES: 01/50 | BestVal=0.7377@E109\n",
      "Epoch: 120, Time: 0.0141, Loss: 1.0368, TrainAcc: 0.7267, ValAcc: 0.7410, ES: 00/50 | BestVal=0.7410@E120\n",
      "Epoch: 130, Time: 0.0141, Loss: 1.0308, TrainAcc: 0.7242, ValAcc: 0.7458, ES: 00/50 | BestVal=0.7458@E130\n",
      "Epoch: 140, Time: 0.0145, Loss: 1.0019, TrainAcc: 0.7301, ValAcc: 0.7483, ES: 00/50 | BestVal=0.7483@E140\n",
      "Epoch: 150, Time: 0.0152, Loss: 0.9917, TrainAcc: 0.7322, ValAcc: 0.7515, ES: 00/50 | BestVal=0.7515@E150\n",
      "Epoch: 160, Time: 0.0147, Loss: 0.9841, TrainAcc: 0.7365, ValAcc: 0.7524, ES: 00/50 | BestVal=0.7524@E160\n",
      "Epoch: 170, Time: 0.0129, Loss: 0.9681, TrainAcc: 0.7396, ValAcc: 0.7534, ES: 03/50 | BestVal=0.7540@E167\n",
      "Epoch: 180, Time: 0.0122, Loss: 0.9672, TrainAcc: 0.7376, ValAcc: 0.7537, ES: 02/50 | BestVal=0.7544@E178\n",
      "Epoch: 190, Time: 0.0145, Loss: 0.9505, TrainAcc: 0.7413, ValAcc: 0.7557, ES: 00/50 | BestVal=0.7557@E190\n",
      "Finished running train at 05-22 17:11:50, running time = 2.78s.\n",
      "[MLP + P] ValAcc: 0.7567, TestAcc: 0.7550\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:11:51\n",
      "Epoch: 0, Time: 0.0183, Loss: 3.8721, TrainAcc: 0.0169, ValAcc: 0.0274, ES: 00/50 | BestVal=0.0274@E0\n",
      "Epoch: 10, Time: 0.0104, Loss: 1.7497, TrainAcc: 0.6618, ValAcc: 0.6994, ES: 05/50 | BestVal=0.7214@E5\n",
      "Epoch: 20, Time: 0.0108, Loss: 1.3595, TrainAcc: 0.6985, ValAcc: 0.7140, ES: 15/50 | BestVal=0.7214@E5\n",
      "Epoch: 30, Time: 0.0128, Loss: 1.1916, TrainAcc: 0.7331, ValAcc: 0.7323, ES: 00/50 | BestVal=0.7323@E30\n",
      "Epoch: 40, Time: 0.0129, Loss: 1.0976, TrainAcc: 0.7538, ValAcc: 0.7408, ES: 00/50 | BestVal=0.7408@E40\n",
      "Epoch: 50, Time: 0.0143, Loss: 1.0367, TrainAcc: 0.7669, ValAcc: 0.7470, ES: 01/50 | BestVal=0.7472@E49\n",
      "Epoch: 60, Time: 0.0265, Loss: 0.9901, TrainAcc: 0.7728, ValAcc: 0.7459, ES: 11/50 | BestVal=0.7472@E49\n",
      "Epoch: 70, Time: 0.0208, Loss: 0.9495, TrainAcc: 0.7757, ValAcc: 0.7462, ES: 21/50 | BestVal=0.7472@E49\n",
      "Epoch: 80, Time: 0.0460, Loss: 0.9200, TrainAcc: 0.7796, ValAcc: 0.7516, ES: 00/50 | BestVal=0.7516@E80\n",
      "Epoch: 90, Time: 0.0158, Loss: 0.8911, TrainAcc: 0.7877, ValAcc: 0.7574, ES: 00/50 | BestVal=0.7574@E90\n",
      "Epoch: 100, Time: 0.0174, Loss: 0.8686, TrainAcc: 0.7882, ValAcc: 0.7610, ES: 00/50 | BestVal=0.7610@E100\n",
      "Epoch: 110, Time: 0.0108, Loss: 0.8502, TrainAcc: 0.7932, ValAcc: 0.7632, ES: 03/50 | BestVal=0.7636@E107\n",
      "Epoch: 120, Time: 0.0129, Loss: 0.8352, TrainAcc: 0.7925, ValAcc: 0.7648, ES: 00/50 | BestVal=0.7648@E120\n",
      "Epoch: 130, Time: 0.0110, Loss: 0.8119, TrainAcc: 0.7986, ValAcc: 0.7657, ES: 06/50 | BestVal=0.7669@E124\n",
      "Epoch: 140, Time: 0.0105, Loss: 0.7975, TrainAcc: 0.8023, ValAcc: 0.7658, ES: 03/50 | BestVal=0.7672@E137\n",
      "Epoch: 150, Time: 0.0105, Loss: 0.7905, TrainAcc: 0.8030, ValAcc: 0.7697, ES: 02/50 | BestVal=0.7703@E148\n",
      "Epoch: 160, Time: 0.0112, Loss: 0.7659, TrainAcc: 0.8071, ValAcc: 0.7702, ES: 04/50 | BestVal=0.7714@E156\n",
      "Epoch: 170, Time: 0.0105, Loss: 0.7515, TrainAcc: 0.8107, ValAcc: 0.7703, ES: 02/50 | BestVal=0.7715@E168\n",
      "Epoch: 180, Time: 0.0110, Loss: 0.7428, TrainAcc: 0.8124, ValAcc: 0.7694, ES: 12/50 | BestVal=0.7715@E168\n",
      "Epoch: 190, Time: 0.0110, Loss: 0.7302, TrainAcc: 0.8163, ValAcc: 0.7685, ES: 22/50 | BestVal=0.7715@E168\n",
      "Finished running train at 05-22 17:11:55, running time = 3.31s.\n",
      "[MLP + E] ValAcc: 0.7715, TestAcc: 0.7731\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7948, TestAcc: 0.7959\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:11:57\n",
      "Epoch: 0, Time: 0.0154, Loss: 3.8930, TrainAcc: 0.0246, ValAcc: 0.3660, ES: 00/50 | BestVal=0.3660@E0\n",
      "Epoch: 10, Time: 0.0118, Loss: 1.6788, TrainAcc: 0.6636, ValAcc: 0.6698, ES: 06/50 | BestVal=0.6852@E4\n",
      "Epoch: 20, Time: 0.0124, Loss: 1.2641, TrainAcc: 0.7134, ValAcc: 0.6999, ES: 00/50 | BestVal=0.6999@E20\n",
      "Epoch: 30, Time: 0.0127, Loss: 1.0647, TrainAcc: 0.7591, ValAcc: 0.7258, ES: 00/50 | BestVal=0.7258@E30\n",
      "Epoch: 40, Time: 0.0123, Loss: 0.9481, TrainAcc: 0.7866, ValAcc: 0.7380, ES: 00/50 | BestVal=0.7380@E40\n",
      "Epoch: 50, Time: 0.0126, Loss: 0.8693, TrainAcc: 0.8054, ValAcc: 0.7508, ES: 00/50 | BestVal=0.7508@E50\n",
      "Epoch: 60, Time: 0.0136, Loss: 0.8171, TrainAcc: 0.8159, ValAcc: 0.7547, ES: 00/50 | BestVal=0.7547@E60\n",
      "Epoch: 70, Time: 0.0106, Loss: 0.7663, TrainAcc: 0.8272, ValAcc: 0.7563, ES: 01/50 | BestVal=0.7565@E69\n",
      "Epoch: 80, Time: 0.0129, Loss: 0.7375, TrainAcc: 0.8310, ValAcc: 0.7569, ES: 00/50 | BestVal=0.7569@E80\n",
      "Epoch: 90, Time: 0.0135, Loss: 0.6962, TrainAcc: 0.8377, ValAcc: 0.7613, ES: 00/50 | BestVal=0.7613@E90\n",
      "Epoch: 100, Time: 0.0124, Loss: 0.6707, TrainAcc: 0.8402, ValAcc: 0.7643, ES: 00/50 | BestVal=0.7643@E100\n",
      "Epoch: 110, Time: 0.0123, Loss: 0.6464, TrainAcc: 0.8464, ValAcc: 0.7668, ES: 00/50 | BestVal=0.7668@E110\n",
      "Epoch: 120, Time: 0.0122, Loss: 0.6158, TrainAcc: 0.8526, ValAcc: 0.7692, ES: 00/50 | BestVal=0.7692@E120\n",
      "Epoch: 130, Time: 0.0127, Loss: 0.5996, TrainAcc: 0.8543, ValAcc: 0.7736, ES: 00/50 | BestVal=0.7736@E130\n",
      "Epoch: 140, Time: 0.0127, Loss: 0.5836, TrainAcc: 0.8594, ValAcc: 0.7774, ES: 00/50 | BestVal=0.7774@E140\n",
      "Epoch: 150, Time: 0.0105, Loss: 0.5712, TrainAcc: 0.8627, ValAcc: 0.7766, ES: 02/50 | BestVal=0.7778@E148\n",
      "Epoch: 160, Time: 0.0109, Loss: 0.5513, TrainAcc: 0.8685, ValAcc: 0.7767, ES: 12/50 | BestVal=0.7778@E148\n",
      "Epoch: 170, Time: 0.0111, Loss: 0.5460, TrainAcc: 0.8694, ValAcc: 0.7767, ES: 22/50 | BestVal=0.7778@E148\n",
      "Epoch: 180, Time: 0.0105, Loss: 0.5207, TrainAcc: 0.8746, ValAcc: 0.7773, ES: 01/50 | BestVal=0.7778@E179\n",
      "Epoch: 190, Time: 0.0112, Loss: 0.5084, TrainAcc: 0.8763, ValAcc: 0.7759, ES: 11/50 | BestVal=0.7778@E179\n",
      "Finished running train at 05-22 17:11:59, running time = 2.41s.\n",
      "[MLP + TA] ValAcc: 0.7778, TestAcc: 0.7768\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:12:00\n",
      "Epoch: 0, Time: 0.0144, Loss: 3.8711, TrainAcc: 0.0211, ValAcc: 0.0263, ES: 00/50 | BestVal=0.0263@E0\n",
      "Epoch: 10, Time: 0.0146, Loss: 1.9877, TrainAcc: 0.5742, ValAcc: 0.6032, ES: 00/50 | BestVal=0.6032@E10\n",
      "Epoch: 20, Time: 0.0149, Loss: 1.6506, TrainAcc: 0.6085, ValAcc: 0.6373, ES: 00/50 | BestVal=0.6373@E20\n",
      "Epoch: 30, Time: 0.0147, Loss: 1.5033, TrainAcc: 0.6336, ValAcc: 0.6681, ES: 00/50 | BestVal=0.6681@E30\n",
      "Epoch: 40, Time: 0.0158, Loss: 1.3951, TrainAcc: 0.6612, ValAcc: 0.7060, ES: 00/50 | BestVal=0.7060@E40\n",
      "Epoch: 50, Time: 0.0141, Loss: 1.3141, TrainAcc: 0.6727, ValAcc: 0.7177, ES: 00/50 | BestVal=0.7177@E50\n",
      "Epoch: 60, Time: 0.0147, Loss: 1.2502, TrainAcc: 0.6894, ValAcc: 0.7291, ES: 00/50 | BestVal=0.7291@E60\n",
      "Epoch: 70, Time: 0.0127, Loss: 1.2136, TrainAcc: 0.6951, ValAcc: 0.7346, ES: 03/50 | BestVal=0.7348@E67\n",
      "Epoch: 80, Time: 0.0140, Loss: 1.1641, TrainAcc: 0.7056, ValAcc: 0.7367, ES: 00/50 | BestVal=0.7367@E80\n",
      "Epoch: 90, Time: 0.0139, Loss: 1.1417, TrainAcc: 0.7080, ValAcc: 0.7383, ES: 00/50 | BestVal=0.7383@E90\n",
      "Epoch: 100, Time: 0.0148, Loss: 1.1085, TrainAcc: 0.7116, ValAcc: 0.7412, ES: 00/50 | BestVal=0.7412@E100\n",
      "Epoch: 110, Time: 0.0123, Loss: 1.0822, TrainAcc: 0.7170, ValAcc: 0.7444, ES: 02/50 | BestVal=0.7445@E108\n",
      "Epoch: 120, Time: 0.0127, Loss: 1.0596, TrainAcc: 0.7225, ValAcc: 0.7446, ES: 08/50 | BestVal=0.7456@E112\n",
      "Epoch: 130, Time: 0.0149, Loss: 1.0476, TrainAcc: 0.7227, ValAcc: 0.7477, ES: 00/50 | BestVal=0.7477@E130\n",
      "Epoch: 140, Time: 0.0127, Loss: 1.0323, TrainAcc: 0.7271, ValAcc: 0.7518, ES: 04/50 | BestVal=0.7523@E136\n",
      "Epoch: 150, Time: 0.0127, Loss: 1.0135, TrainAcc: 0.7301, ValAcc: 0.7550, ES: 02/50 | BestVal=0.7551@E148\n",
      "Epoch: 160, Time: 0.0130, Loss: 1.0046, TrainAcc: 0.7334, ValAcc: 0.7553, ES: 01/50 | BestVal=0.7561@E159\n",
      "Epoch: 170, Time: 0.0149, Loss: 0.9965, TrainAcc: 0.7300, ValAcc: 0.7570, ES: 00/50 | BestVal=0.7570@E170\n",
      "Epoch: 180, Time: 0.0130, Loss: 0.9807, TrainAcc: 0.7370, ValAcc: 0.7561, ES: 10/50 | BestVal=0.7570@E170\n",
      "Epoch: 190, Time: 0.0128, Loss: 0.9698, TrainAcc: 0.7399, ValAcc: 0.7567, ES: 20/50 | BestVal=0.7570@E170\n",
      "Finished running train at 05-22 17:12:03, running time = 3.01s.\n",
      "[MLP + P] ValAcc: 0.7587, TestAcc: 0.7604\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:05\n",
      "Epoch: 0, Time: 0.0237, Loss: 3.8825, TrainAcc: 0.0254, ValAcc: 0.3532, ES: 00/50 | BestVal=0.3532@E0\n",
      "Epoch: 10, Time: 0.0104, Loss: 1.7758, TrainAcc: 0.6319, ValAcc: 0.6687, ES: 06/50 | BestVal=0.6803@E4\n",
      "Epoch: 20, Time: 0.0129, Loss: 1.4040, TrainAcc: 0.6838, ValAcc: 0.6885, ES: 00/50 | BestVal=0.6885@E20\n",
      "Epoch: 30, Time: 0.0134, Loss: 1.2394, TrainAcc: 0.7103, ValAcc: 0.7190, ES: 00/50 | BestVal=0.7190@E30\n",
      "Epoch: 40, Time: 0.0253, Loss: 1.1343, TrainAcc: 0.7385, ValAcc: 0.7449, ES: 00/50 | BestVal=0.7449@E40\n",
      "Epoch: 50, Time: 0.0135, Loss: 1.0659, TrainAcc: 0.7540, ValAcc: 0.7500, ES: 00/50 | BestVal=0.7500@E50\n",
      "Epoch: 60, Time: 0.0109, Loss: 1.0051, TrainAcc: 0.7676, ValAcc: 0.7499, ES: 09/50 | BestVal=0.7510@E51\n",
      "Epoch: 70, Time: 0.0104, Loss: 0.9628, TrainAcc: 0.7740, ValAcc: 0.7534, ES: 02/50 | BestVal=0.7535@E68\n",
      "Epoch: 80, Time: 0.0126, Loss: 0.9338, TrainAcc: 0.7764, ValAcc: 0.7545, ES: 00/50 | BestVal=0.7545@E80\n",
      "Epoch: 90, Time: 0.0106, Loss: 0.8996, TrainAcc: 0.7817, ValAcc: 0.7563, ES: 01/50 | BestVal=0.7566@E89\n",
      "Epoch: 100, Time: 0.0128, Loss: 0.8791, TrainAcc: 0.7835, ValAcc: 0.7596, ES: 00/50 | BestVal=0.7596@E100\n",
      "Epoch: 110, Time: 0.0117, Loss: 0.8588, TrainAcc: 0.7887, ValAcc: 0.7616, ES: 01/50 | BestVal=0.7618@E109\n",
      "Epoch: 120, Time: 0.0107, Loss: 0.8275, TrainAcc: 0.7952, ValAcc: 0.7649, ES: 01/50 | BestVal=0.7652@E119\n",
      "Epoch: 130, Time: 0.0123, Loss: 0.8187, TrainAcc: 0.7965, ValAcc: 0.7666, ES: 00/50 | BestVal=0.7666@E130\n",
      "Epoch: 140, Time: 0.0104, Loss: 0.8091, TrainAcc: 0.7987, ValAcc: 0.7687, ES: 03/50 | BestVal=0.7694@E137\n",
      "Epoch: 150, Time: 0.0123, Loss: 0.7853, TrainAcc: 0.8046, ValAcc: 0.7715, ES: 00/50 | BestVal=0.7715@E150\n",
      "Epoch: 160, Time: 0.0111, Loss: 0.7746, TrainAcc: 0.8059, ValAcc: 0.7695, ES: 07/50 | BestVal=0.7718@E153\n",
      "Epoch: 170, Time: 0.0113, Loss: 0.7606, TrainAcc: 0.8095, ValAcc: 0.7699, ES: 17/50 | BestVal=0.7718@E153\n",
      "Epoch: 180, Time: 0.0105, Loss: 0.7413, TrainAcc: 0.8129, ValAcc: 0.7715, ES: 27/50 | BestVal=0.7718@E153\n",
      "Epoch: 190, Time: 0.0109, Loss: 0.7371, TrainAcc: 0.8171, ValAcc: 0.7687, ES: 09/50 | BestVal=0.7721@E181\n",
      "Finished running train at 05-22 17:12:07, running time = 2.47s.\n",
      "[MLP + E] ValAcc: 0.7721, TestAcc: 0.7753\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7981, TestAcc: 0.7978\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:09\n",
      "Epoch: 0, Time: 0.0132, Loss: 3.9222, TrainAcc: 0.0140, ValAcc: 0.2971, ES: 00/50 | BestVal=0.2971@E0\n",
      "Epoch: 10, Time: 0.0127, Loss: 1.7275, TrainAcc: 0.6554, ValAcc: 0.6442, ES: 07/50 | BestVal=0.6553@E3\n",
      "Epoch: 20, Time: 0.0130, Loss: 1.3229, TrainAcc: 0.6968, ValAcc: 0.6908, ES: 00/50 | BestVal=0.6908@E20\n",
      "Epoch: 30, Time: 0.0123, Loss: 1.1359, TrainAcc: 0.7387, ValAcc: 0.7208, ES: 00/50 | BestVal=0.7208@E30\n",
      "Epoch: 40, Time: 0.0128, Loss: 1.0230, TrainAcc: 0.7666, ValAcc: 0.7392, ES: 00/50 | BestVal=0.7392@E40\n",
      "Epoch: 50, Time: 0.0130, Loss: 0.9518, TrainAcc: 0.7825, ValAcc: 0.7453, ES: 00/50 | BestVal=0.7453@E50\n",
      "Epoch: 60, Time: 0.0129, Loss: 0.8887, TrainAcc: 0.7940, ValAcc: 0.7500, ES: 00/50 | BestVal=0.7500@E60\n",
      "Epoch: 70, Time: 0.0105, Loss: 0.8421, TrainAcc: 0.8007, ValAcc: 0.7565, ES: 01/50 | BestVal=0.7568@E69\n",
      "Epoch: 80, Time: 0.0127, Loss: 0.8013, TrainAcc: 0.8092, ValAcc: 0.7611, ES: 00/50 | BestVal=0.7611@E80\n",
      "Epoch: 90, Time: 0.0129, Loss: 0.7766, TrainAcc: 0.8128, ValAcc: 0.7634, ES: 00/50 | BestVal=0.7634@E90\n",
      "Epoch: 100, Time: 0.0123, Loss: 0.7475, TrainAcc: 0.8217, ValAcc: 0.7661, ES: 00/50 | BestVal=0.7661@E100\n",
      "Epoch: 110, Time: 0.0104, Loss: 0.7234, TrainAcc: 0.8255, ValAcc: 0.7674, ES: 05/50 | BestVal=0.7683@E105\n",
      "Epoch: 120, Time: 0.0123, Loss: 0.7025, TrainAcc: 0.8297, ValAcc: 0.7688, ES: 00/50 | BestVal=0.7688@E120\n",
      "Epoch: 130, Time: 0.0110, Loss: 0.6824, TrainAcc: 0.8338, ValAcc: 0.7686, ES: 03/50 | BestVal=0.7694@E127\n",
      "Epoch: 140, Time: 0.0123, Loss: 0.6597, TrainAcc: 0.8380, ValAcc: 0.7696, ES: 00/50 | BestVal=0.7696@E140\n",
      "Epoch: 150, Time: 0.0122, Loss: 0.6519, TrainAcc: 0.8389, ValAcc: 0.7707, ES: 00/50 | BestVal=0.7707@E150\n",
      "Epoch: 160, Time: 0.0111, Loss: 0.6310, TrainAcc: 0.8439, ValAcc: 0.7710, ES: 02/50 | BestVal=0.7719@E158\n",
      "Epoch: 170, Time: 0.0104, Loss: 0.6259, TrainAcc: 0.8467, ValAcc: 0.7710, ES: 12/50 | BestVal=0.7719@E158\n",
      "Epoch: 180, Time: 0.0114, Loss: 0.6017, TrainAcc: 0.8504, ValAcc: 0.7701, ES: 22/50 | BestVal=0.7719@E158\n",
      "Epoch: 190, Time: 0.0105, Loss: 0.5921, TrainAcc: 0.8535, ValAcc: 0.7714, ES: 02/50 | BestVal=0.7724@E188\n",
      "Finished running train at 05-22 17:12:11, running time = 2.40s.\n",
      "[MLP + TA] ValAcc: 0.7724, TestAcc: 0.7767\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:12:13\n",
      "Epoch: 0, Time: 0.0144, Loss: 3.8779, TrainAcc: 0.0197, ValAcc: 0.2132, ES: 00/50 | BestVal=0.2132@E0\n",
      "Epoch: 10, Time: 0.0149, Loss: 1.9837, TrainAcc: 0.5836, ValAcc: 0.6101, ES: 00/50 | BestVal=0.6101@E10\n",
      "Epoch: 20, Time: 0.0144, Loss: 1.6524, TrainAcc: 0.6189, ValAcc: 0.6353, ES: 00/50 | BestVal=0.6353@E20\n",
      "Epoch: 30, Time: 0.0145, Loss: 1.5018, TrainAcc: 0.6421, ValAcc: 0.6611, ES: 00/50 | BestVal=0.6611@E30\n",
      "Epoch: 40, Time: 0.0144, Loss: 1.4002, TrainAcc: 0.6626, ValAcc: 0.6872, ES: 00/50 | BestVal=0.6872@E40\n",
      "Epoch: 50, Time: 0.0141, Loss: 1.3064, TrainAcc: 0.6793, ValAcc: 0.7068, ES: 00/50 | BestVal=0.7068@E50\n",
      "Epoch: 60, Time: 0.0150, Loss: 1.2375, TrainAcc: 0.6956, ValAcc: 0.7215, ES: 00/50 | BestVal=0.7215@E60\n",
      "Epoch: 70, Time: 0.0142, Loss: 1.1850, TrainAcc: 0.7058, ValAcc: 0.7278, ES: 00/50 | BestVal=0.7278@E70\n",
      "Epoch: 80, Time: 0.0125, Loss: 1.1492, TrainAcc: 0.7090, ValAcc: 0.7342, ES: 01/50 | BestVal=0.7346@E79\n",
      "Epoch: 90, Time: 0.0223, Loss: 1.1135, TrainAcc: 0.7180, ValAcc: 0.7364, ES: 00/50 | BestVal=0.7364@E90\n",
      "Epoch: 100, Time: 0.0257, Loss: 1.0803, TrainAcc: 0.7227, ValAcc: 0.7391, ES: 01/50 | BestVal=0.7393@E99\n",
      "Epoch: 110, Time: 0.0124, Loss: 1.0581, TrainAcc: 0.7260, ValAcc: 0.7411, ES: 01/50 | BestVal=0.7421@E109\n",
      "Epoch: 120, Time: 0.0126, Loss: 1.0427, TrainAcc: 0.7277, ValAcc: 0.7417, ES: 11/50 | BestVal=0.7421@E109\n",
      "Epoch: 130, Time: 0.0141, Loss: 1.0240, TrainAcc: 0.7298, ValAcc: 0.7443, ES: 00/50 | BestVal=0.7443@E130\n",
      "Epoch: 140, Time: 0.0142, Loss: 1.0058, TrainAcc: 0.7337, ValAcc: 0.7461, ES: 00/50 | BestVal=0.7461@E140\n",
      "Epoch: 150, Time: 0.0122, Loss: 1.0014, TrainAcc: 0.7365, ValAcc: 0.7471, ES: 04/50 | BestVal=0.7475@E146\n",
      "Epoch: 160, Time: 0.0129, Loss: 0.9809, TrainAcc: 0.7382, ValAcc: 0.7474, ES: 04/50 | BestVal=0.7492@E156\n",
      "Epoch: 170, Time: 0.0154, Loss: 0.9706, TrainAcc: 0.7388, ValAcc: 0.7492, ES: 00/50 | BestVal=0.7492@E170\n",
      "Epoch: 180, Time: 0.0124, Loss: 0.9671, TrainAcc: 0.7428, ValAcc: 0.7490, ES: 09/50 | BestVal=0.7503@E171\n",
      "Epoch: 190, Time: 0.0130, Loss: 0.9516, TrainAcc: 0.7441, ValAcc: 0.7482, ES: 19/50 | BestVal=0.7503@E171\n",
      "Finished running train at 05-22 17:12:16, running time = 3.41s.\n",
      "[MLP + P] ValAcc: 0.7503, TestAcc: 0.7555\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:17\n",
      "Epoch: 0, Time: 0.0136, Loss: 3.9171, TrainAcc: 0.0174, ValAcc: 0.3047, ES: 00/50 | BestVal=0.3047@E0\n",
      "Epoch: 10, Time: 0.0128, Loss: 1.7773, TrainAcc: 0.6542, ValAcc: 0.6722, ES: 00/50 | BestVal=0.6722@E10\n",
      "Epoch: 20, Time: 0.0127, Loss: 1.3743, TrainAcc: 0.6915, ValAcc: 0.6899, ES: 00/50 | BestVal=0.6899@E20\n",
      "Epoch: 30, Time: 0.0123, Loss: 1.2097, TrainAcc: 0.7232, ValAcc: 0.7103, ES: 00/50 | BestVal=0.7103@E30\n",
      "Epoch: 40, Time: 0.0128, Loss: 1.1055, TrainAcc: 0.7492, ValAcc: 0.7406, ES: 00/50 | BestVal=0.7406@E40\n",
      "Epoch: 50, Time: 0.0112, Loss: 1.0416, TrainAcc: 0.7633, ValAcc: 0.7504, ES: 01/50 | BestVal=0.7506@E49\n",
      "Epoch: 60, Time: 0.0105, Loss: 0.9811, TrainAcc: 0.7743, ValAcc: 0.7499, ES: 11/50 | BestVal=0.7506@E49\n",
      "Epoch: 70, Time: 0.0130, Loss: 0.9404, TrainAcc: 0.7809, ValAcc: 0.7537, ES: 00/50 | BestVal=0.7537@E70\n",
      "Epoch: 80, Time: 0.0127, Loss: 0.9025, TrainAcc: 0.7860, ValAcc: 0.7557, ES: 00/50 | BestVal=0.7557@E80\n",
      "Epoch: 90, Time: 0.0109, Loss: 0.8830, TrainAcc: 0.7873, ValAcc: 0.7583, ES: 01/50 | BestVal=0.7587@E89\n",
      "Epoch: 100, Time: 0.0110, Loss: 0.8506, TrainAcc: 0.7963, ValAcc: 0.7623, ES: 01/50 | BestVal=0.7628@E99\n",
      "Epoch: 110, Time: 0.0128, Loss: 0.8365, TrainAcc: 0.7981, ValAcc: 0.7640, ES: 00/50 | BestVal=0.7640@E110\n",
      "Epoch: 120, Time: 0.0110, Loss: 0.8096, TrainAcc: 0.8041, ValAcc: 0.7644, ES: 03/50 | BestVal=0.7648@E117\n",
      "Epoch: 130, Time: 0.0110, Loss: 0.7897, TrainAcc: 0.8055, ValAcc: 0.7654, ES: 01/50 | BestVal=0.7657@E129\n",
      "Epoch: 140, Time: 0.0109, Loss: 0.7739, TrainAcc: 0.8085, ValAcc: 0.7662, ES: 03/50 | BestVal=0.7666@E137\n",
      "Epoch: 150, Time: 0.0112, Loss: 0.7678, TrainAcc: 0.8107, ValAcc: 0.7679, ES: 02/50 | BestVal=0.7686@E148\n",
      "Epoch: 160, Time: 0.0112, Loss: 0.7522, TrainAcc: 0.8166, ValAcc: 0.7686, ES: 05/50 | BestVal=0.7687@E155\n",
      "Epoch: 170, Time: 0.0112, Loss: 0.7338, TrainAcc: 0.8168, ValAcc: 0.7685, ES: 01/50 | BestVal=0.7694@E169\n",
      "Epoch: 180, Time: 0.0115, Loss: 0.7170, TrainAcc: 0.8216, ValAcc: 0.7682, ES: 11/50 | BestVal=0.7694@E169\n",
      "Epoch: 190, Time: 0.0114, Loss: 0.7146, TrainAcc: 0.8213, ValAcc: 0.7680, ES: 21/50 | BestVal=0.7694@E169\n",
      "Finished running train at 05-22 17:12:19, running time = 2.38s.\n",
      "[MLP + E] ValAcc: 0.7694, TestAcc: 0.7721\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7872, TestAcc: 0.7912\n",
      "\n",
      "[TA] ValACC: 0.7768 ± 0.0029, TestAcc: 0.7767 ± 0.0008\n",
      "[P] ValACC: 0.7563 ± 0.0042, TestAcc: 0.7552 ± 0.0043\n",
      "[E] ValACC: 0.7727 ± 0.0036, TestAcc: 0.7729 ± 0.0017\n",
      "[ensemble] ValACC: 0.7942 ± 0.0048, TestAcc: 0.7955 ± 0.0029\n",
      "Running time: 13.08s\n",
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:24\n",
      "Epoch: 0, Time: 0.3794, Loss: 4.0938, TrainAcc: 0.0178, ValAcc: 0.2023, ES: 00/50 | BestVal=0.2023@E0\n",
      "Epoch: 10, Time: 0.0205, Loss: 0.9343, TrainAcc: 0.7942, ValAcc: 0.7272, ES: 00/50 | BestVal=0.7272@E10\n",
      "Epoch: 20, Time: 0.0204, Loss: 0.7909, TrainAcc: 0.8159, ValAcc: 0.7450, ES: 00/50 | BestVal=0.7450@E20\n",
      "Epoch: 30, Time: 0.0618, Loss: 0.7210, TrainAcc: 0.8227, ValAcc: 0.7479, ES: 00/50 | BestVal=0.7479@E30\n",
      "Epoch: 40, Time: 0.0365, Loss: 0.6807, TrainAcc: 0.8281, ValAcc: 0.7504, ES: 01/50 | BestVal=0.7512@E39\n",
      "Epoch: 50, Time: 0.0191, Loss: 0.6490, TrainAcc: 0.8324, ValAcc: 0.7528, ES: 02/50 | BestVal=0.7537@E48\n",
      "Epoch: 60, Time: 0.0204, Loss: 0.6200, TrainAcc: 0.8369, ValAcc: 0.7545, ES: 00/50 | BestVal=0.7545@E60\n",
      "Epoch: 70, Time: 0.0185, Loss: 0.5903, TrainAcc: 0.8419, ValAcc: 0.7543, ES: 03/50 | BestVal=0.7556@E67\n",
      "Epoch: 80, Time: 0.0187, Loss: 0.5981, TrainAcc: 0.8394, ValAcc: 0.7517, ES: 03/50 | BestVal=0.7563@E77\n",
      "Epoch: 90, Time: 0.0184, Loss: 0.5455, TrainAcc: 0.8511, ValAcc: 0.7529, ES: 13/50 | BestVal=0.7563@E77\n",
      "Epoch: 100, Time: 0.0184, Loss: 0.5146, TrainAcc: 0.8571, ValAcc: 0.7525, ES: 03/50 | BestVal=0.7564@E97\n",
      "Epoch: 110, Time: 0.0186, Loss: 0.4999, TrainAcc: 0.8590, ValAcc: 0.7543, ES: 13/50 | BestVal=0.7564@E97\n",
      "Epoch: 120, Time: 0.0186, Loss: 0.5028, TrainAcc: 0.8597, ValAcc: 0.7452, ES: 23/50 | BestVal=0.7564@E97\n",
      "Epoch: 130, Time: 0.0187, Loss: 0.4565, TrainAcc: 0.8702, ValAcc: 0.7459, ES: 33/50 | BestVal=0.7564@E97\n",
      "Epoch: 140, Time: 0.0186, Loss: 0.4149, TrainAcc: 0.8804, ValAcc: 0.7482, ES: 43/50 | BestVal=0.7564@E97\n",
      "Early stopped, loading model from epoch-97\n",
      "Finished running train at 05-22 17:12:28, running time = 4.00s.\n",
      "[GCN + TA] ValAcc: 0.7564, TestAcc: 0.7564\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:12:29\n",
      "Epoch: 0, Time: 0.0317, Loss: 4.0803, TrainAcc: 0.0222, ValAcc: 0.1255, ES: 00/50 | BestVal=0.1255@E0\n",
      "Epoch: 10, Time: 0.0220, Loss: 1.2222, TrainAcc: 0.7089, ValAcc: 0.6933, ES: 00/50 | BestVal=0.6933@E10\n",
      "Epoch: 20, Time: 0.0229, Loss: 1.0325, TrainAcc: 0.7331, ValAcc: 0.7202, ES: 00/50 | BestVal=0.7202@E20\n",
      "Epoch: 30, Time: 0.0228, Loss: 0.9218, TrainAcc: 0.7480, ValAcc: 0.7289, ES: 00/50 | BestVal=0.7289@E30\n",
      "Epoch: 40, Time: 0.0206, Loss: 0.8467, TrainAcc: 0.7620, ValAcc: 0.7302, ES: 01/50 | BestVal=0.7305@E39\n",
      "Epoch: 50, Time: 0.0205, Loss: 0.7795, TrainAcc: 0.7740, ValAcc: 0.7265, ES: 06/50 | BestVal=0.7310@E44\n",
      "Epoch: 60, Time: 0.0201, Loss: 0.7145, TrainAcc: 0.7879, ValAcc: 0.7269, ES: 16/50 | BestVal=0.7310@E44\n",
      "Epoch: 70, Time: 0.0204, Loss: 0.6896, TrainAcc: 0.7906, ValAcc: 0.7201, ES: 26/50 | BestVal=0.7310@E44\n",
      "Epoch: 80, Time: 0.0204, Loss: 0.6195, TrainAcc: 0.8102, ValAcc: 0.7136, ES: 36/50 | BestVal=0.7310@E44\n",
      "Epoch: 90, Time: 0.0204, Loss: 0.5490, TrainAcc: 0.8286, ValAcc: 0.7179, ES: 46/50 | BestVal=0.7310@E44\n",
      "Early stopped, loading model from epoch-44\n",
      "Finished running train at 05-22 17:12:31, running time = 2.02s.\n",
      "[GCN + P] ValAcc: 0.7310, TestAcc: 0.7305\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:32\n",
      "Epoch: 0, Time: 0.0217, Loss: 3.9376, TrainAcc: 0.0178, ValAcc: 0.2273, ES: 00/50 | BestVal=0.2273@E0\n",
      "Epoch: 10, Time: 0.0203, Loss: 1.0077, TrainAcc: 0.7693, ValAcc: 0.7139, ES: 00/50 | BestVal=0.7139@E10\n",
      "Epoch: 20, Time: 0.0203, Loss: 0.8624, TrainAcc: 0.7940, ValAcc: 0.7434, ES: 00/50 | BestVal=0.7434@E20\n",
      "Epoch: 30, Time: 0.0193, Loss: 0.7966, TrainAcc: 0.7999, ValAcc: 0.7466, ES: 02/50 | BestVal=0.7477@E28\n",
      "Epoch: 40, Time: 0.0203, Loss: 0.7562, TrainAcc: 0.8043, ValAcc: 0.7539, ES: 00/50 | BestVal=0.7539@E40\n",
      "Epoch: 50, Time: 0.0188, Loss: 0.7244, TrainAcc: 0.8090, ValAcc: 0.7564, ES: 03/50 | BestVal=0.7565@E47\n",
      "Epoch: 60, Time: 0.0186, Loss: 0.6953, TrainAcc: 0.8143, ValAcc: 0.7562, ES: 08/50 | BestVal=0.7569@E52\n",
      "Epoch: 70, Time: 0.0185, Loss: 0.6695, TrainAcc: 0.8190, ValAcc: 0.7547, ES: 18/50 | BestVal=0.7569@E52\n",
      "Epoch: 80, Time: 0.0185, Loss: 0.6653, TrainAcc: 0.8181, ValAcc: 0.7522, ES: 02/50 | BestVal=0.7571@E78\n",
      "Epoch: 90, Time: 0.0190, Loss: 0.6842, TrainAcc: 0.8117, ValAcc: 0.7490, ES: 12/50 | BestVal=0.7571@E78\n",
      "Epoch: 100, Time: 0.0183, Loss: 0.6275, TrainAcc: 0.8254, ValAcc: 0.7558, ES: 22/50 | BestVal=0.7571@E78\n",
      "Epoch: 110, Time: 0.0186, Loss: 0.5907, TrainAcc: 0.8336, ValAcc: 0.7547, ES: 02/50 | BestVal=0.7573@E108\n",
      "Epoch: 120, Time: 0.0181, Loss: 0.5808, TrainAcc: 0.8353, ValAcc: 0.7550, ES: 12/50 | BestVal=0.7573@E108\n",
      "Epoch: 130, Time: 0.0186, Loss: 0.5644, TrainAcc: 0.8389, ValAcc: 0.7562, ES: 22/50 | BestVal=0.7573@E108\n",
      "Epoch: 140, Time: 0.0192, Loss: 0.5557, TrainAcc: 0.8406, ValAcc: 0.7496, ES: 32/50 | BestVal=0.7573@E108\n",
      "Epoch: 150, Time: 0.0186, Loss: 0.5101, TrainAcc: 0.8500, ValAcc: 0.7551, ES: 42/50 | BestVal=0.7573@E108\n",
      "Early stopped, loading model from epoch-108\n",
      "Finished running train at 05-22 17:12:35, running time = 3.13s.\n",
      "[GCN + E] ValAcc: 0.7573, TestAcc: 0.7478\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7759, TestAcc: 0.7766\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:38\n",
      "Epoch: 0, Time: 0.0397, Loss: 4.2318, TrainAcc: 0.0086, ValAcc: 0.5780, ES: 00/50 | BestVal=0.5780@E0\n",
      "Epoch: 10, Time: 0.0217, Loss: 0.9110, TrainAcc: 0.8033, ValAcc: 0.7129, ES: 00/50 | BestVal=0.7129@E10\n",
      "Epoch: 20, Time: 0.0206, Loss: 0.7677, TrainAcc: 0.8320, ValAcc: 0.7376, ES: 00/50 | BestVal=0.7376@E20\n",
      "Epoch: 30, Time: 0.0186, Loss: 0.6945, TrainAcc: 0.8400, ValAcc: 0.7444, ES: 01/50 | BestVal=0.7447@E29\n",
      "Epoch: 40, Time: 0.0204, Loss: 0.6513, TrainAcc: 0.8437, ValAcc: 0.7460, ES: 00/50 | BestVal=0.7460@E40\n",
      "Epoch: 50, Time: 0.0195, Loss: 0.6216, TrainAcc: 0.8468, ValAcc: 0.7464, ES: 08/50 | BestVal=0.7479@E42\n",
      "Epoch: 60, Time: 0.0210, Loss: 0.5969, TrainAcc: 0.8507, ValAcc: 0.7489, ES: 00/50 | BestVal=0.7489@E60\n",
      "Epoch: 70, Time: 0.0194, Loss: 0.5730, TrainAcc: 0.8542, ValAcc: 0.7492, ES: 06/50 | BestVal=0.7503@E64\n",
      "Epoch: 80, Time: 0.0184, Loss: 0.5850, TrainAcc: 0.8513, ValAcc: 0.7422, ES: 06/50 | BestVal=0.7509@E74\n",
      "Epoch: 90, Time: 0.0186, Loss: 0.5504, TrainAcc: 0.8570, ValAcc: 0.7486, ES: 16/50 | BestVal=0.7509@E74\n",
      "Epoch: 100, Time: 0.0188, Loss: 0.5207, TrainAcc: 0.8634, ValAcc: 0.7489, ES: 03/50 | BestVal=0.7514@E97\n",
      "Epoch: 110, Time: 0.0188, Loss: 0.4933, TrainAcc: 0.8678, ValAcc: 0.7512, ES: 09/50 | BestVal=0.7517@E101\n",
      "Epoch: 120, Time: 0.0186, Loss: 0.5080, TrainAcc: 0.8689, ValAcc: 0.7483, ES: 19/50 | BestVal=0.7517@E101\n",
      "Epoch: 130, Time: 0.0183, Loss: 0.4668, TrainAcc: 0.8724, ValAcc: 0.7469, ES: 29/50 | BestVal=0.7517@E101\n",
      "Epoch: 140, Time: 0.0205, Loss: 0.4312, TrainAcc: 0.8816, ValAcc: 0.7523, ES: 00/50 | BestVal=0.7523@E140\n",
      "Epoch: 150, Time: 0.0187, Loss: 0.4881, TrainAcc: 0.8667, ValAcc: 0.7451, ES: 07/50 | BestVal=0.7536@E143\n",
      "Epoch: 160, Time: 0.0186, Loss: 0.4279, TrainAcc: 0.8815, ValAcc: 0.7474, ES: 17/50 | BestVal=0.7536@E143\n",
      "Epoch: 170, Time: 0.0186, Loss: 0.3790, TrainAcc: 0.8937, ValAcc: 0.7464, ES: 27/50 | BestVal=0.7536@E143\n",
      "Epoch: 180, Time: 0.0186, Loss: 0.3997, TrainAcc: 0.8843, ValAcc: 0.7471, ES: 37/50 | BestVal=0.7536@E143\n",
      "Epoch: 190, Time: 0.0186, Loss: 0.3526, TrainAcc: 0.9012, ValAcc: 0.7413, ES: 47/50 | BestVal=0.7536@E143\n",
      "Early stopped, loading model from epoch-143\n",
      "Finished running train at 05-22 17:12:42, running time = 3.77s.\n",
      "[GCN + TA] ValAcc: 0.7536, TestAcc: 0.7529\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:12:43\n",
      "Epoch: 0, Time: 0.0252, Loss: 3.7326, TrainAcc: 0.0472, ValAcc: 0.3969, ES: 00/50 | BestVal=0.3969@E0\n",
      "Epoch: 10, Time: 0.0221, Loss: 1.1890, TrainAcc: 0.7086, ValAcc: 0.6834, ES: 00/50 | BestVal=0.6834@E10\n",
      "Epoch: 20, Time: 0.0224, Loss: 0.9940, TrainAcc: 0.7357, ValAcc: 0.7102, ES: 00/50 | BestVal=0.7102@E20\n",
      "Epoch: 30, Time: 0.0206, Loss: 0.8830, TrainAcc: 0.7552, ValAcc: 0.7246, ES: 01/50 | BestVal=0.7266@E29\n",
      "Epoch: 40, Time: 0.0201, Loss: 0.8058, TrainAcc: 0.7674, ValAcc: 0.7249, ES: 03/50 | BestVal=0.7280@E37\n",
      "Epoch: 50, Time: 0.0204, Loss: 0.7381, TrainAcc: 0.7809, ValAcc: 0.7251, ES: 13/50 | BestVal=0.7280@E37\n",
      "Epoch: 60, Time: 0.0203, Loss: 0.6768, TrainAcc: 0.7949, ValAcc: 0.7199, ES: 23/50 | BestVal=0.7280@E37\n",
      "Epoch: 70, Time: 0.0201, Loss: 0.6311, TrainAcc: 0.8036, ValAcc: 0.7190, ES: 33/50 | BestVal=0.7280@E37\n",
      "Epoch: 80, Time: 0.0201, Loss: 0.5586, TrainAcc: 0.8218, ValAcc: 0.7136, ES: 43/50 | BestVal=0.7280@E37\n",
      "Early stopped, loading model from epoch-37\n",
      "Finished running train at 05-22 17:12:45, running time = 1.87s.\n",
      "[GCN + P] ValAcc: 0.7280, TestAcc: 0.7312\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:46\n",
      "Epoch: 0, Time: 0.0222, Loss: 4.1389, TrainAcc: 0.0047, ValAcc: 0.5554, ES: 00/50 | BestVal=0.5554@E0\n",
      "Epoch: 10, Time: 0.0202, Loss: 1.0106, TrainAcc: 0.7664, ValAcc: 0.6955, ES: 00/50 | BestVal=0.6955@E10\n",
      "Epoch: 20, Time: 0.0204, Loss: 0.8717, TrainAcc: 0.7920, ValAcc: 0.7324, ES: 00/50 | BestVal=0.7324@E20\n",
      "Epoch: 30, Time: 0.0202, Loss: 0.8112, TrainAcc: 0.7958, ValAcc: 0.7400, ES: 00/50 | BestVal=0.7400@E30\n",
      "Epoch: 40, Time: 0.0203, Loss: 0.7751, TrainAcc: 0.7985, ValAcc: 0.7452, ES: 00/50 | BestVal=0.7452@E40\n",
      "Epoch: 50, Time: 0.0186, Loss: 0.7476, TrainAcc: 0.8018, ValAcc: 0.7440, ES: 10/50 | BestVal=0.7452@E40\n",
      "Epoch: 60, Time: 0.0186, Loss: 0.7236, TrainAcc: 0.8057, ValAcc: 0.7446, ES: 20/50 | BestVal=0.7452@E40\n",
      "Epoch: 70, Time: 0.0180, Loss: 0.7000, TrainAcc: 0.8099, ValAcc: 0.7446, ES: 09/50 | BestVal=0.7455@E61\n",
      "Epoch: 80, Time: 0.0185, Loss: 0.6924, TrainAcc: 0.8122, ValAcc: 0.7446, ES: 07/50 | BestVal=0.7468@E73\n",
      "Epoch: 90, Time: 0.0187, Loss: 0.6603, TrainAcc: 0.8164, ValAcc: 0.7465, ES: 17/50 | BestVal=0.7468@E73\n",
      "Epoch: 100, Time: 0.0608, Loss: 0.6426, TrainAcc: 0.8203, ValAcc: 0.7471, ES: 00/50 | BestVal=0.7471@E100\n",
      "Epoch: 110, Time: 0.0340, Loss: 0.6215, TrainAcc: 0.8234, ValAcc: 0.7408, ES: 06/50 | BestVal=0.7479@E104\n",
      "Epoch: 120, Time: 0.0212, Loss: 0.5946, TrainAcc: 0.8316, ValAcc: 0.7490, ES: 00/50 | BestVal=0.7490@E120\n",
      "Epoch: 130, Time: 0.0184, Loss: 0.5794, TrainAcc: 0.8322, ValAcc: 0.7427, ES: 10/50 | BestVal=0.7490@E120\n",
      "Epoch: 140, Time: 0.0189, Loss: 0.5951, TrainAcc: 0.8312, ValAcc: 0.7402, ES: 20/50 | BestVal=0.7490@E120\n",
      "Epoch: 150, Time: 0.0193, Loss: 0.5447, TrainAcc: 0.8405, ValAcc: 0.7435, ES: 30/50 | BestVal=0.7490@E120\n",
      "Epoch: 160, Time: 0.0193, Loss: 0.5514, TrainAcc: 0.8458, ValAcc: 0.7411, ES: 40/50 | BestVal=0.7490@E120\n",
      "Early stopped, loading model from epoch-120\n",
      "Finished running train at 05-22 17:12:50, running time = 3.93s.\n",
      "[GCN + E] ValAcc: 0.7490, TestAcc: 0.7487\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7696, TestAcc: 0.7754\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:12:52\n",
      "Epoch: 0, Time: 0.0252, Loss: 4.2257, TrainAcc: 0.0139, ValAcc: 0.2814, ES: 00/50 | BestVal=0.2814@E0\n",
      "Epoch: 10, Time: 0.0220, Loss: 0.9141, TrainAcc: 0.8026, ValAcc: 0.7237, ES: 00/50 | BestVal=0.7237@E10\n",
      "Epoch: 20, Time: 0.0209, Loss: 0.7469, TrainAcc: 0.8331, ValAcc: 0.7449, ES: 00/50 | BestVal=0.7449@E20\n",
      "Epoch: 30, Time: 0.0207, Loss: 0.6828, TrainAcc: 0.8380, ValAcc: 0.7521, ES: 00/50 | BestVal=0.7521@E30\n",
      "Epoch: 40, Time: 0.0187, Loss: 0.6430, TrainAcc: 0.8414, ValAcc: 0.7532, ES: 02/50 | BestVal=0.7536@E38\n",
      "Epoch: 50, Time: 0.0207, Loss: 0.6136, TrainAcc: 0.8453, ValAcc: 0.7552, ES: 00/50 | BestVal=0.7552@E50\n",
      "Epoch: 60, Time: 0.0186, Loss: 0.5878, TrainAcc: 0.8505, ValAcc: 0.7556, ES: 04/50 | BestVal=0.7558@E56\n",
      "Epoch: 70, Time: 0.0187, Loss: 0.5626, TrainAcc: 0.8543, ValAcc: 0.7558, ES: 09/50 | BestVal=0.7565@E61\n",
      "Epoch: 80, Time: 0.0202, Loss: 0.5741, TrainAcc: 0.8518, ValAcc: 0.7579, ES: 00/50 | BestVal=0.7579@E80\n",
      "Epoch: 90, Time: 0.0190, Loss: 0.5377, TrainAcc: 0.8566, ValAcc: 0.7556, ES: 09/50 | BestVal=0.7582@E81\n",
      "Epoch: 100, Time: 0.0183, Loss: 0.5038, TrainAcc: 0.8637, ValAcc: 0.7547, ES: 19/50 | BestVal=0.7582@E81\n",
      "Epoch: 110, Time: 0.0186, Loss: 0.5328, TrainAcc: 0.8590, ValAcc: 0.7500, ES: 07/50 | BestVal=0.7592@E103\n",
      "Epoch: 120, Time: 0.0181, Loss: 0.4837, TrainAcc: 0.8687, ValAcc: 0.7595, ES: 02/50 | BestVal=0.7604@E118\n",
      "Epoch: 130, Time: 0.0181, Loss: 0.4456, TrainAcc: 0.8781, ValAcc: 0.7571, ES: 12/50 | BestVal=0.7604@E118\n",
      "Epoch: 140, Time: 0.0184, Loss: 0.4217, TrainAcc: 0.8807, ValAcc: 0.7534, ES: 22/50 | BestVal=0.7604@E118\n",
      "Epoch: 150, Time: 0.0186, Loss: 0.4375, TrainAcc: 0.8771, ValAcc: 0.7403, ES: 32/50 | BestVal=0.7604@E118\n",
      "Epoch: 160, Time: 0.0185, Loss: 0.4027, TrainAcc: 0.8866, ValAcc: 0.7464, ES: 42/50 | BestVal=0.7604@E118\n",
      "Early stopped, loading model from epoch-118\n",
      "Finished running train at 05-22 17:12:56, running time = 3.26s.\n",
      "[GCN + TA] ValAcc: 0.7604, TestAcc: 0.7548\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:12:57\n",
      "Epoch: 0, Time: 0.0238, Loss: 3.8631, TrainAcc: 0.0399, ValAcc: 0.2611, ES: 00/50 | BestVal=0.2611@E0\n",
      "Epoch: 10, Time: 0.0220, Loss: 1.2404, TrainAcc: 0.7071, ValAcc: 0.6926, ES: 00/50 | BestVal=0.6926@E10\n",
      "Epoch: 20, Time: 0.0219, Loss: 1.0385, TrainAcc: 0.7291, ValAcc: 0.7223, ES: 00/50 | BestVal=0.7223@E20\n",
      "Epoch: 30, Time: 0.0222, Loss: 0.9254, TrainAcc: 0.7453, ValAcc: 0.7326, ES: 00/50 | BestVal=0.7326@E30\n",
      "Epoch: 40, Time: 0.0209, Loss: 0.8487, TrainAcc: 0.7598, ValAcc: 0.7319, ES: 03/50 | BestVal=0.7346@E37\n",
      "Epoch: 50, Time: 0.0208, Loss: 0.7828, TrainAcc: 0.7717, ValAcc: 0.7338, ES: 02/50 | BestVal=0.7347@E48\n",
      "Epoch: 60, Time: 0.0204, Loss: 0.7183, TrainAcc: 0.7853, ValAcc: 0.7306, ES: 12/50 | BestVal=0.7347@E48\n",
      "Epoch: 70, Time: 0.0210, Loss: 0.6814, TrainAcc: 0.7940, ValAcc: 0.7260, ES: 22/50 | BestVal=0.7347@E48\n",
      "Epoch: 80, Time: 0.0261, Loss: 0.6156, TrainAcc: 0.8098, ValAcc: 0.7266, ES: 32/50 | BestVal=0.7347@E48\n",
      "Epoch: 90, Time: 0.0206, Loss: 0.5591, TrainAcc: 0.8272, ValAcc: 0.7198, ES: 42/50 | BestVal=0.7347@E48\n",
      "Early stopped, loading model from epoch-48\n",
      "Finished running train at 05-22 17:12:59, running time = 2.34s.\n",
      "[GCN + P] ValAcc: 0.7347, TestAcc: 0.7313\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:13:01\n",
      "Epoch: 0, Time: 0.0308, Loss: 4.3320, TrainAcc: 0.0228, ValAcc: 0.1525, ES: 00/50 | BestVal=0.1525@E0\n",
      "Epoch: 10, Time: 0.0207, Loss: 1.0371, TrainAcc: 0.7667, ValAcc: 0.7166, ES: 00/50 | BestVal=0.7166@E10\n",
      "Epoch: 20, Time: 0.0203, Loss: 0.8907, TrainAcc: 0.7881, ValAcc: 0.7377, ES: 00/50 | BestVal=0.7377@E20\n",
      "Epoch: 30, Time: 0.0186, Loss: 0.8245, TrainAcc: 0.7925, ValAcc: 0.7435, ES: 05/50 | BestVal=0.7447@E25\n",
      "Epoch: 40, Time: 0.0207, Loss: 0.7835, TrainAcc: 0.7965, ValAcc: 0.7472, ES: 00/50 | BestVal=0.7472@E40\n",
      "Epoch: 50, Time: 0.0186, Loss: 0.7527, TrainAcc: 0.8012, ValAcc: 0.7485, ES: 07/50 | BestVal=0.7494@E43\n",
      "Epoch: 60, Time: 0.0187, Loss: 0.7263, TrainAcc: 0.8048, ValAcc: 0.7499, ES: 06/50 | BestVal=0.7502@E54\n",
      "Epoch: 70, Time: 0.0204, Loss: 0.7031, TrainAcc: 0.8083, ValAcc: 0.7508, ES: 00/50 | BestVal=0.7508@E70\n",
      "Epoch: 80, Time: 0.0186, Loss: 0.6993, TrainAcc: 0.8110, ValAcc: 0.7475, ES: 07/50 | BestVal=0.7523@E73\n",
      "Epoch: 90, Time: 0.0192, Loss: 0.6658, TrainAcc: 0.8159, ValAcc: 0.7517, ES: 17/50 | BestVal=0.7523@E73\n",
      "Epoch: 100, Time: 0.0186, Loss: 0.6461, TrainAcc: 0.8196, ValAcc: 0.7501, ES: 04/50 | BestVal=0.7529@E96\n",
      "Epoch: 110, Time: 0.0185, Loss: 0.6089, TrainAcc: 0.8244, ValAcc: 0.7510, ES: 14/50 | BestVal=0.7529@E96\n",
      "Epoch: 120, Time: 0.0184, Loss: 0.6102, TrainAcc: 0.8221, ValAcc: 0.7446, ES: 24/50 | BestVal=0.7529@E96\n",
      "Epoch: 130, Time: 0.0186, Loss: 0.5739, TrainAcc: 0.8320, ValAcc: 0.7425, ES: 34/50 | BestVal=0.7529@E96\n",
      "Epoch: 140, Time: 0.0186, Loss: 0.5512, TrainAcc: 0.8378, ValAcc: 0.7463, ES: 44/50 | BestVal=0.7529@E96\n",
      "Early stopped, loading model from epoch-96\n",
      "Finished running train at 05-22 17:13:04, running time = 3.06s.\n",
      "[GCN + E] ValAcc: 0.7529, TestAcc: 0.7536\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7775, TestAcc: 0.7751\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:13:06\n",
      "Epoch: 0, Time: 0.0349, Loss: 4.1931, TrainAcc: 0.0365, ValAcc: 0.1224, ES: 00/50 | BestVal=0.1224@E0\n",
      "Epoch: 10, Time: 0.0223, Loss: 0.9766, TrainAcc: 0.7847, ValAcc: 0.7089, ES: 00/50 | BestVal=0.7089@E10\n",
      "Epoch: 20, Time: 0.0186, Loss: 0.8302, TrainAcc: 0.8071, ValAcc: 0.7210, ES: 02/50 | BestVal=0.7224@E18\n",
      "Epoch: 30, Time: 0.0212, Loss: 0.7571, TrainAcc: 0.8168, ValAcc: 0.7434, ES: 00/50 | BestVal=0.7434@E30\n",
      "Epoch: 40, Time: 0.0187, Loss: 0.7130, TrainAcc: 0.8214, ValAcc: 0.7448, ES: 03/50 | BestVal=0.7458@E37\n",
      "Epoch: 50, Time: 0.0184, Loss: 0.6825, TrainAcc: 0.8254, ValAcc: 0.7458, ES: 06/50 | BestVal=0.7473@E44\n",
      "Epoch: 60, Time: 0.0203, Loss: 0.6554, TrainAcc: 0.8289, ValAcc: 0.7477, ES: 00/50 | BestVal=0.7477@E60\n",
      "Epoch: 70, Time: 0.0186, Loss: 0.6300, TrainAcc: 0.8334, ValAcc: 0.7470, ES: 10/50 | BestVal=0.7477@E60\n",
      "Epoch: 80, Time: 0.0186, Loss: 0.6120, TrainAcc: 0.8339, ValAcc: 0.7468, ES: 02/50 | BestVal=0.7477@E78\n",
      "Epoch: 90, Time: 0.0192, Loss: 0.5900, TrainAcc: 0.8384, ValAcc: 0.7404, ES: 03/50 | BestVal=0.7477@E87\n",
      "Epoch: 100, Time: 0.0191, Loss: 0.5616, TrainAcc: 0.8461, ValAcc: 0.7453, ES: 13/50 | BestVal=0.7477@E87\n",
      "Epoch: 110, Time: 0.0186, Loss: 0.5641, TrainAcc: 0.8423, ValAcc: 0.7364, ES: 23/50 | BestVal=0.7477@E87\n",
      "Epoch: 120, Time: 0.0187, Loss: 0.5393, TrainAcc: 0.8506, ValAcc: 0.7470, ES: 01/50 | BestVal=0.7481@E119\n",
      "Epoch: 130, Time: 0.0186, Loss: 0.4948, TrainAcc: 0.8580, ValAcc: 0.7425, ES: 11/50 | BestVal=0.7481@E119\n",
      "Epoch: 140, Time: 0.0186, Loss: 0.5099, TrainAcc: 0.8593, ValAcc: 0.7424, ES: 21/50 | BestVal=0.7481@E119\n",
      "Epoch: 150, Time: 0.0185, Loss: 0.4526, TrainAcc: 0.8695, ValAcc: 0.7436, ES: 31/50 | BestVal=0.7481@E119\n",
      "Epoch: 160, Time: 0.0183, Loss: 0.4551, TrainAcc: 0.8719, ValAcc: 0.7381, ES: 41/50 | BestVal=0.7481@E119\n",
      "Early stopped, loading model from epoch-119\n",
      "Finished running train at 05-22 17:13:09, running time = 3.29s.\n",
      "[GCN + TA] ValAcc: 0.7481, TestAcc: 0.7569\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:13:11\n",
      "Epoch: 0, Time: 0.0230, Loss: 4.1960, TrainAcc: 0.0209, ValAcc: 0.3084, ES: 00/50 | BestVal=0.3084@E0\n",
      "Epoch: 10, Time: 0.0229, Loss: 1.2251, TrainAcc: 0.7044, ValAcc: 0.6890, ES: 00/50 | BestVal=0.6890@E10\n",
      "Epoch: 20, Time: 0.0224, Loss: 1.0264, TrainAcc: 0.7326, ValAcc: 0.7045, ES: 00/50 | BestVal=0.7045@E20\n",
      "Epoch: 30, Time: 0.0205, Loss: 0.9172, TrainAcc: 0.7519, ValAcc: 0.7180, ES: 01/50 | BestVal=0.7184@E29\n",
      "Epoch: 40, Time: 0.0223, Loss: 0.8394, TrainAcc: 0.7631, ValAcc: 0.7223, ES: 00/50 | BestVal=0.7223@E40\n",
      "Epoch: 50, Time: 0.0204, Loss: 0.7740, TrainAcc: 0.7756, ValAcc: 0.7215, ES: 10/50 | BestVal=0.7223@E40\n",
      "Epoch: 60, Time: 0.0205, Loss: 0.7278, TrainAcc: 0.7854, ValAcc: 0.7149, ES: 20/50 | BestVal=0.7223@E40\n",
      "Epoch: 70, Time: 0.0207, Loss: 0.6688, TrainAcc: 0.7961, ValAcc: 0.7213, ES: 05/50 | BestVal=0.7262@E65\n",
      "Epoch: 80, Time: 0.0204, Loss: 0.6023, TrainAcc: 0.8139, ValAcc: 0.7160, ES: 15/50 | BestVal=0.7262@E65\n",
      "Epoch: 90, Time: 0.0205, Loss: 0.5539, TrainAcc: 0.8259, ValAcc: 0.7175, ES: 25/50 | BestVal=0.7262@E65\n",
      "Epoch: 100, Time: 0.0200, Loss: 0.5443, TrainAcc: 0.8285, ValAcc: 0.7094, ES: 35/50 | BestVal=0.7262@E65\n",
      "Epoch: 110, Time: 0.0201, Loss: 0.4717, TrainAcc: 0.8467, ValAcc: 0.7088, ES: 45/50 | BestVal=0.7262@E65\n",
      "Early stopped, loading model from epoch-65\n",
      "Finished running train at 05-22 17:13:14, running time = 2.45s.\n",
      "[GCN + P] ValAcc: 0.7262, TestAcc: 0.7317\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:13:15\n",
      "Epoch: 0, Time: 0.0210, Loss: 4.1531, TrainAcc: 0.0180, ValAcc: 0.2173, ES: 00/50 | BestVal=0.2173@E0\n",
      "Epoch: 10, Time: 0.0208, Loss: 1.0490, TrainAcc: 0.7694, ValAcc: 0.7192, ES: 00/50 | BestVal=0.7192@E10\n",
      "Epoch: 20, Time: 0.0205, Loss: 0.9061, TrainAcc: 0.7860, ValAcc: 0.7347, ES: 00/50 | BestVal=0.7347@E20\n",
      "Epoch: 30, Time: 0.0187, Loss: 0.8317, TrainAcc: 0.7949, ValAcc: 0.7430, ES: 01/50 | BestVal=0.7447@E29\n",
      "Epoch: 40, Time: 0.0184, Loss: 0.7826, TrainAcc: 0.8014, ValAcc: 0.7445, ES: 05/50 | BestVal=0.7464@E35\n",
      "Epoch: 50, Time: 0.0186, Loss: 0.7499, TrainAcc: 0.8047, ValAcc: 0.7442, ES: 15/50 | BestVal=0.7464@E35\n",
      "Epoch: 60, Time: 0.0186, Loss: 0.7237, TrainAcc: 0.8078, ValAcc: 0.7446, ES: 25/50 | BestVal=0.7464@E35\n",
      "Epoch: 70, Time: 0.0188, Loss: 0.6981, TrainAcc: 0.8121, ValAcc: 0.7472, ES: 01/50 | BestVal=0.7474@E69\n",
      "Epoch: 80, Time: 0.0186, Loss: 0.6965, TrainAcc: 0.8145, ValAcc: 0.7456, ES: 07/50 | BestVal=0.7487@E73\n",
      "Epoch: 90, Time: 0.0186, Loss: 0.6577, TrainAcc: 0.8195, ValAcc: 0.7475, ES: 17/50 | BestVal=0.7487@E73\n",
      "Epoch: 100, Time: 0.0185, Loss: 0.6618, TrainAcc: 0.8212, ValAcc: 0.7462, ES: 06/50 | BestVal=0.7510@E94\n",
      "Epoch: 110, Time: 0.0185, Loss: 0.6259, TrainAcc: 0.8238, ValAcc: 0.7456, ES: 16/50 | BestVal=0.7510@E94\n",
      "Epoch: 120, Time: 0.0187, Loss: 0.5917, TrainAcc: 0.8321, ValAcc: 0.7430, ES: 26/50 | BestVal=0.7510@E94\n",
      "Epoch: 130, Time: 0.0185, Loss: 0.5785, TrainAcc: 0.8332, ValAcc: 0.7444, ES: 36/50 | BestVal=0.7510@E94\n",
      "Epoch: 140, Time: 0.0185, Loss: 0.5600, TrainAcc: 0.8385, ValAcc: 0.7329, ES: 46/50 | BestVal=0.7510@E94\n",
      "Early stopped, loading model from epoch-94\n",
      "Finished running train at 05-22 17:13:18, running time = 2.78s.\n",
      "[GCN + E] ValAcc: 0.7510, TestAcc: 0.7540\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7629, TestAcc: 0.7742\n",
      "\n",
      "[TA] ValACC: 0.7546 ± 0.0052, TestAcc: 0.7552 ± 0.0018\n",
      "[P] ValACC: 0.7300 ± 0.0037, TestAcc: 0.7312 ± 0.0005\n",
      "[E] ValACC: 0.7525 ± 0.0035, TestAcc: 0.7510 ± 0.0032\n",
      "[ensemble] ValACC: 0.7715 ± 0.0067, TestAcc: 0.7754 ± 0.0010\n",
      "Running time: 14.18s\n",
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:13:23\n",
      "Epoch: 0, Time: 0.3763, Loss: 3.7263, TrainAcc: 0.0749, ValAcc: 0.5109, ES: 00/50 | BestVal=0.5109@E0\n",
      "Epoch: 10, Time: 0.0283, Loss: 0.9457, TrainAcc: 0.7788, ValAcc: 0.7142, ES: 00/50 | BestVal=0.7142@E10\n",
      "Epoch: 20, Time: 0.0278, Loss: 0.6963, TrainAcc: 0.8237, ValAcc: 0.7432, ES: 00/50 | BestVal=0.7432@E20\n",
      "Epoch: 30, Time: 0.0295, Loss: 0.5774, TrainAcc: 0.8478, ValAcc: 0.7623, ES: 00/50 | BestVal=0.7623@E30\n",
      "Epoch: 40, Time: 0.0279, Loss: 0.5077, TrainAcc: 0.8630, ValAcc: 0.7714, ES: 00/50 | BestVal=0.7714@E40\n",
      "Epoch: 50, Time: 0.0280, Loss: 0.4624, TrainAcc: 0.8714, ValAcc: 0.7773, ES: 00/50 | BestVal=0.7773@E50\n",
      "Epoch: 60, Time: 0.0266, Loss: 0.4299, TrainAcc: 0.8771, ValAcc: 0.7754, ES: 10/50 | BestVal=0.7773@E50\n",
      "Epoch: 70, Time: 0.0246, Loss: 0.4034, TrainAcc: 0.8831, ValAcc: 0.7736, ES: 20/50 | BestVal=0.7773@E50\n",
      "Epoch: 80, Time: 0.0247, Loss: 0.3784, TrainAcc: 0.8891, ValAcc: 0.7715, ES: 30/50 | BestVal=0.7773@E50\n",
      "Epoch: 90, Time: 0.0253, Loss: 0.3640, TrainAcc: 0.8916, ValAcc: 0.7720, ES: 40/50 | BestVal=0.7773@E50\n",
      "Early stopped, loading model from epoch-50\n",
      "Finished running train at 05-22 17:13:26, running time = 3.08s.\n",
      "[SAGE + TA] ValAcc: 0.7773, TestAcc: 0.7753\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 246056\n",
      "Start running train at 05-22 17:13:27\n",
      "Epoch: 0, Time: 0.0327, Loss: 3.7244, TrainAcc: 0.0276, ValAcc: 0.4328, ES: 00/50 | BestVal=0.4328@E0\n",
      "Epoch: 10, Time: 0.0318, Loss: 1.3093, TrainAcc: 0.6824, ValAcc: 0.6552, ES: 00/50 | BestVal=0.6552@E10\n",
      "Epoch: 20, Time: 0.0325, Loss: 1.0147, TrainAcc: 0.7358, ValAcc: 0.7236, ES: 00/50 | BestVal=0.7236@E20\n",
      "Epoch: 30, Time: 0.0316, Loss: 0.8595, TrainAcc: 0.7607, ValAcc: 0.7390, ES: 00/50 | BestVal=0.7390@E30\n",
      "Epoch: 40, Time: 0.0318, Loss: 0.7514, TrainAcc: 0.7819, ValAcc: 0.7490, ES: 00/50 | BestVal=0.7490@E40\n",
      "Epoch: 50, Time: 0.0323, Loss: 0.6689, TrainAcc: 0.8011, ValAcc: 0.7526, ES: 00/50 | BestVal=0.7526@E50\n",
      "Epoch: 60, Time: 0.0297, Loss: 0.5924, TrainAcc: 0.8222, ValAcc: 0.7486, ES: 08/50 | BestVal=0.7528@E52\n",
      "Epoch: 70, Time: 0.0294, Loss: 0.5519, TrainAcc: 0.8275, ValAcc: 0.7352, ES: 18/50 | BestVal=0.7528@E52\n",
      "Epoch: 80, Time: 0.0291, Loss: 0.4709, TrainAcc: 0.8532, ValAcc: 0.7299, ES: 28/50 | BestVal=0.7528@E52\n",
      "Epoch: 90, Time: 0.0297, Loss: 0.4207, TrainAcc: 0.8662, ValAcc: 0.7314, ES: 38/50 | BestVal=0.7528@E52\n",
      "Epoch: 100, Time: 0.0291, Loss: 0.3959, TrainAcc: 0.8684, ValAcc: 0.7239, ES: 48/50 | BestVal=0.7528@E52\n",
      "Early stopped, loading model from epoch-52\n",
      "Finished running train at 05-22 17:13:30, running time = 3.18s.\n",
      "[SAGE + P] ValAcc: 0.7528, TestAcc: 0.7430\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:13:32\n",
      "Epoch: 0, Time: 0.0966, Loss: 3.7691, TrainAcc: 0.0159, ValAcc: 0.5970, ES: 00/50 | BestVal=0.5970@E0\n",
      "Epoch: 10, Time: 0.0398, Loss: 1.0415, TrainAcc: 0.7608, ValAcc: 0.7229, ES: 00/50 | BestVal=0.7229@E10\n",
      "Epoch: 20, Time: 0.0439, Loss: 0.7930, TrainAcc: 0.8023, ValAcc: 0.7535, ES: 00/50 | BestVal=0.7535@E20\n",
      "Epoch: 30, Time: 0.0255, Loss: 0.6772, TrainAcc: 0.8199, ValAcc: 0.7605, ES: 01/50 | BestVal=0.7611@E29\n",
      "Epoch: 40, Time: 0.0284, Loss: 0.6097, TrainAcc: 0.8337, ValAcc: 0.7712, ES: 00/50 | BestVal=0.7712@E40\n",
      "Epoch: 50, Time: 0.0285, Loss: 0.5608, TrainAcc: 0.8419, ValAcc: 0.7780, ES: 00/50 | BestVal=0.7780@E50\n",
      "Epoch: 60, Time: 0.0251, Loss: 0.5263, TrainAcc: 0.8489, ValAcc: 0.7790, ES: 02/50 | BestVal=0.7799@E58\n",
      "Epoch: 70, Time: 0.0256, Loss: 0.4956, TrainAcc: 0.8550, ValAcc: 0.7788, ES: 02/50 | BestVal=0.7804@E68\n",
      "Epoch: 80, Time: 0.0264, Loss: 0.4765, TrainAcc: 0.8589, ValAcc: 0.7760, ES: 12/50 | BestVal=0.7804@E68\n",
      "Epoch: 90, Time: 0.0251, Loss: 0.4450, TrainAcc: 0.8690, ValAcc: 0.7767, ES: 22/50 | BestVal=0.7804@E68\n",
      "Epoch: 100, Time: 0.0252, Loss: 0.4274, TrainAcc: 0.8707, ValAcc: 0.7672, ES: 32/50 | BestVal=0.7804@E68\n",
      "Epoch: 110, Time: 0.0253, Loss: 0.4000, TrainAcc: 0.8796, ValAcc: 0.7741, ES: 42/50 | BestVal=0.7804@E68\n",
      "Early stopped, loading model from epoch-68\n",
      "Finished running train at 05-22 17:13:36, running time = 3.90s.\n",
      "[SAGE + E] ValAcc: 0.7804, TestAcc: 0.7727\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7999, TestAcc: 0.8004\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:13:38\n",
      "Epoch: 0, Time: 0.0402, Loss: 3.8531, TrainAcc: 0.0148, ValAcc: 0.5896, ES: 00/50 | BestVal=0.5896@E0\n",
      "Epoch: 10, Time: 0.0279, Loss: 0.9481, TrainAcc: 0.7874, ValAcc: 0.7118, ES: 00/50 | BestVal=0.7118@E10\n",
      "Epoch: 20, Time: 0.0260, Loss: 0.6658, TrainAcc: 0.8405, ValAcc: 0.7451, ES: 01/50 | BestVal=0.7455@E19\n",
      "Epoch: 30, Time: 0.0277, Loss: 0.5322, TrainAcc: 0.8687, ValAcc: 0.7621, ES: 00/50 | BestVal=0.7621@E30\n",
      "Epoch: 40, Time: 0.0285, Loss: 0.4542, TrainAcc: 0.8819, ValAcc: 0.7724, ES: 00/50 | BestVal=0.7724@E40\n",
      "Epoch: 50, Time: 0.0284, Loss: 0.4093, TrainAcc: 0.8896, ValAcc: 0.7750, ES: 00/50 | BestVal=0.7750@E50\n",
      "Epoch: 60, Time: 0.0284, Loss: 0.3790, TrainAcc: 0.8958, ValAcc: 0.7761, ES: 00/50 | BestVal=0.7761@E60\n",
      "Epoch: 70, Time: 0.0278, Loss: 0.3554, TrainAcc: 0.9005, ValAcc: 0.7763, ES: 00/50 | BestVal=0.7763@E70\n",
      "Epoch: 80, Time: 0.0250, Loss: 0.3343, TrainAcc: 0.9052, ValAcc: 0.7751, ES: 10/50 | BestVal=0.7763@E70\n",
      "Epoch: 90, Time: 0.0255, Loss: 0.3268, TrainAcc: 0.9074, ValAcc: 0.7714, ES: 20/50 | BestVal=0.7763@E70\n",
      "Epoch: 100, Time: 0.0256, Loss: 0.3094, TrainAcc: 0.9103, ValAcc: 0.7741, ES: 30/50 | BestVal=0.7763@E70\n",
      "Epoch: 110, Time: 0.0256, Loss: 0.2835, TrainAcc: 0.9170, ValAcc: 0.7723, ES: 40/50 | BestVal=0.7763@E70\n",
      "Early stopped, loading model from epoch-70\n",
      "Finished running train at 05-22 17:13:41, running time = 3.26s.\n",
      "[SAGE + TA] ValAcc: 0.7763, TestAcc: 0.7758\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 246056\n",
      "Start running train at 05-22 17:13:42\n",
      "Epoch: 0, Time: 0.0321, Loss: 3.7243, TrainAcc: 0.0390, ValAcc: 0.5043, ES: 00/50 | BestVal=0.5043@E0\n",
      "Epoch: 10, Time: 0.0721, Loss: 1.2870, TrainAcc: 0.6813, ValAcc: 0.6571, ES: 00/50 | BestVal=0.6571@E10\n",
      "Epoch: 20, Time: 0.0383, Loss: 1.0028, TrainAcc: 0.7325, ValAcc: 0.7192, ES: 00/50 | BestVal=0.7192@E20\n",
      "Epoch: 30, Time: 0.0340, Loss: 0.8476, TrainAcc: 0.7594, ValAcc: 0.7327, ES: 00/50 | BestVal=0.7327@E30\n",
      "Epoch: 40, Time: 0.0320, Loss: 0.7443, TrainAcc: 0.7823, ValAcc: 0.7442, ES: 00/50 | BestVal=0.7442@E40\n",
      "Epoch: 50, Time: 0.0294, Loss: 0.6556, TrainAcc: 0.8045, ValAcc: 0.7462, ES: 01/50 | BestVal=0.7465@E49\n",
      "Epoch: 60, Time: 0.0294, Loss: 0.5892, TrainAcc: 0.8215, ValAcc: 0.7407, ES: 11/50 | BestVal=0.7465@E49\n",
      "Epoch: 70, Time: 0.0298, Loss: 0.5113, TrainAcc: 0.8413, ValAcc: 0.7300, ES: 21/50 | BestVal=0.7465@E49\n",
      "Epoch: 80, Time: 0.0296, Loss: 0.4757, TrainAcc: 0.8486, ValAcc: 0.7288, ES: 31/50 | BestVal=0.7465@E49\n",
      "Epoch: 90, Time: 0.0298, Loss: 0.3972, TrainAcc: 0.8730, ValAcc: 0.7218, ES: 41/50 | BestVal=0.7465@E49\n",
      "Early stopped, loading model from epoch-49\n",
      "Finished running train at 05-22 17:13:46, running time = 3.74s.\n",
      "[SAGE + P] ValAcc: 0.7465, TestAcc: 0.7440\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:13:47\n",
      "Epoch: 0, Time: 0.0281, Loss: 3.8172, TrainAcc: 0.0190, ValAcc: 0.5383, ES: 00/50 | BestVal=0.5383@E0\n",
      "Epoch: 10, Time: 0.0285, Loss: 1.0665, TrainAcc: 0.7517, ValAcc: 0.7142, ES: 00/50 | BestVal=0.7142@E10\n",
      "Epoch: 20, Time: 0.0278, Loss: 0.8078, TrainAcc: 0.7978, ValAcc: 0.7485, ES: 00/50 | BestVal=0.7485@E20\n",
      "Epoch: 30, Time: 0.0289, Loss: 0.6898, TrainAcc: 0.8186, ValAcc: 0.7616, ES: 00/50 | BestVal=0.7616@E30\n",
      "Epoch: 40, Time: 0.0276, Loss: 0.6205, TrainAcc: 0.8314, ValAcc: 0.7690, ES: 00/50 | BestVal=0.7690@E40\n",
      "Epoch: 50, Time: 0.0286, Loss: 0.5758, TrainAcc: 0.8399, ValAcc: 0.7707, ES: 00/50 | BestVal=0.7707@E50\n",
      "Epoch: 60, Time: 0.0265, Loss: 0.5427, TrainAcc: 0.8456, ValAcc: 0.7722, ES: 04/50 | BestVal=0.7728@E56\n",
      "Epoch: 70, Time: 0.0249, Loss: 0.5156, TrainAcc: 0.8504, ValAcc: 0.7700, ES: 14/50 | BestVal=0.7728@E56\n",
      "Epoch: 80, Time: 0.0253, Loss: 0.4984, TrainAcc: 0.8542, ValAcc: 0.7674, ES: 24/50 | BestVal=0.7728@E56\n",
      "Epoch: 90, Time: 0.0249, Loss: 0.4727, TrainAcc: 0.8610, ValAcc: 0.7681, ES: 34/50 | BestVal=0.7728@E56\n",
      "Epoch: 100, Time: 0.0253, Loss: 0.4565, TrainAcc: 0.8647, ValAcc: 0.7667, ES: 44/50 | BestVal=0.7728@E56\n",
      "Early stopped, loading model from epoch-56\n",
      "Finished running train at 05-22 17:13:50, running time = 2.85s.\n",
      "[SAGE + E] ValAcc: 0.7728, TestAcc: 0.7711\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7946, TestAcc: 0.7963\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:13:52\n",
      "Epoch: 0, Time: 0.0462, Loss: 3.6879, TrainAcc: 0.0510, ValAcc: 0.5896, ES: 00/50 | BestVal=0.5896@E0\n",
      "Epoch: 10, Time: 0.0285, Loss: 0.8771, TrainAcc: 0.7959, ValAcc: 0.7187, ES: 00/50 | BestVal=0.7187@E10\n",
      "Epoch: 20, Time: 0.0284, Loss: 0.6430, TrainAcc: 0.8429, ValAcc: 0.7529, ES: 00/50 | BestVal=0.7529@E20\n",
      "Epoch: 30, Time: 0.0278, Loss: 0.5243, TrainAcc: 0.8644, ValAcc: 0.7646, ES: 00/50 | BestVal=0.7646@E30\n",
      "Epoch: 40, Time: 0.0259, Loss: 0.4514, TrainAcc: 0.8811, ValAcc: 0.7703, ES: 01/50 | BestVal=0.7705@E39\n",
      "Epoch: 50, Time: 0.1151, Loss: 0.4053, TrainAcc: 0.8886, ValAcc: 0.7727, ES: 00/50 | BestVal=0.7727@E50\n",
      "Epoch: 60, Time: 0.0246, Loss: 0.3737, TrainAcc: 0.8948, ValAcc: 0.7739, ES: 07/50 | BestVal=0.7745@E53\n",
      "Epoch: 70, Time: 0.0389, Loss: 0.3486, TrainAcc: 0.9006, ValAcc: 0.7726, ES: 17/50 | BestVal=0.7745@E53\n",
      "Epoch: 80, Time: 0.0451, Loss: 0.3260, TrainAcc: 0.9058, ValAcc: 0.7746, ES: 00/50 | BestVal=0.7746@E80\n",
      "Epoch: 90, Time: 0.0265, Loss: 0.3082, TrainAcc: 0.9114, ValAcc: 0.7732, ES: 10/50 | BestVal=0.7746@E80\n",
      "Epoch: 100, Time: 0.0252, Loss: 0.2914, TrainAcc: 0.9158, ValAcc: 0.7687, ES: 20/50 | BestVal=0.7746@E80\n",
      "Epoch: 110, Time: 0.0254, Loss: 0.2663, TrainAcc: 0.9224, ValAcc: 0.7677, ES: 30/50 | BestVal=0.7746@E80\n",
      "Epoch: 120, Time: 0.0254, Loss: 0.2718, TrainAcc: 0.9180, ValAcc: 0.7710, ES: 40/50 | BestVal=0.7746@E80\n",
      "Early stopped, loading model from epoch-80\n",
      "Finished running train at 05-22 17:13:56, running time = 4.11s.\n",
      "[SAGE + TA] ValAcc: 0.7746, TestAcc: 0.7731\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 246056\n",
      "Start running train at 05-22 17:13:58\n",
      "Epoch: 0, Time: 0.0342, Loss: 3.8292, TrainAcc: 0.0133, ValAcc: 0.3501, ES: 00/50 | BestVal=0.3501@E0\n",
      "Epoch: 10, Time: 0.0321, Loss: 1.3838, TrainAcc: 0.6588, ValAcc: 0.6452, ES: 00/50 | BestVal=0.6452@E10\n",
      "Epoch: 20, Time: 0.0324, Loss: 1.0900, TrainAcc: 0.7183, ValAcc: 0.7091, ES: 00/50 | BestVal=0.7091@E20\n",
      "Epoch: 30, Time: 0.0323, Loss: 0.9213, TrainAcc: 0.7457, ValAcc: 0.7303, ES: 00/50 | BestVal=0.7303@E30\n",
      "Epoch: 40, Time: 0.0329, Loss: 0.8091, TrainAcc: 0.7681, ValAcc: 0.7474, ES: 00/50 | BestVal=0.7474@E40\n",
      "Epoch: 50, Time: 0.0300, Loss: 0.7180, TrainAcc: 0.7898, ValAcc: 0.7510, ES: 01/50 | BestVal=0.7519@E49\n",
      "Epoch: 60, Time: 0.0301, Loss: 0.6395, TrainAcc: 0.8084, ValAcc: 0.7435, ES: 11/50 | BestVal=0.7519@E49\n",
      "Epoch: 70, Time: 0.0300, Loss: 0.5781, TrainAcc: 0.8229, ValAcc: 0.7429, ES: 21/50 | BestVal=0.7519@E49\n",
      "Epoch: 80, Time: 0.0299, Loss: 0.5076, TrainAcc: 0.8448, ValAcc: 0.7333, ES: 31/50 | BestVal=0.7519@E49\n",
      "Epoch: 90, Time: 0.0298, Loss: 0.4612, TrainAcc: 0.8536, ValAcc: 0.7331, ES: 41/50 | BestVal=0.7519@E49\n",
      "Early stopped, loading model from epoch-49\n",
      "Finished running train at 05-22 17:14:01, running time = 3.10s.\n",
      "[SAGE + P] ValAcc: 0.7519, TestAcc: 0.7528\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:14:02\n",
      "Epoch: 0, Time: 0.0272, Loss: 3.6542, TrainAcc: 0.0222, ValAcc: 0.5747, ES: 00/50 | BestVal=0.5747@E0\n",
      "Epoch: 10, Time: 0.0284, Loss: 1.0465, TrainAcc: 0.7623, ValAcc: 0.7238, ES: 00/50 | BestVal=0.7238@E10\n",
      "Epoch: 20, Time: 0.0277, Loss: 0.8181, TrainAcc: 0.7938, ValAcc: 0.7502, ES: 00/50 | BestVal=0.7502@E20\n",
      "Epoch: 30, Time: 0.0256, Loss: 0.7038, TrainAcc: 0.8145, ValAcc: 0.7637, ES: 01/50 | BestVal=0.7642@E29\n",
      "Epoch: 40, Time: 0.0284, Loss: 0.6333, TrainAcc: 0.8270, ValAcc: 0.7682, ES: 00/50 | BestVal=0.7682@E40\n",
      "Epoch: 50, Time: 0.0283, Loss: 0.5851, TrainAcc: 0.8346, ValAcc: 0.7705, ES: 00/50 | BestVal=0.7705@E50\n",
      "Epoch: 60, Time: 0.0259, Loss: 0.5507, TrainAcc: 0.8413, ValAcc: 0.7728, ES: 01/50 | BestVal=0.7729@E59\n",
      "Epoch: 70, Time: 0.0249, Loss: 0.5217, TrainAcc: 0.8464, ValAcc: 0.7713, ES: 11/50 | BestVal=0.7729@E59\n",
      "Epoch: 80, Time: 0.0256, Loss: 0.4986, TrainAcc: 0.8528, ValAcc: 0.7660, ES: 21/50 | BestVal=0.7729@E59\n",
      "Epoch: 90, Time: 0.0250, Loss: 0.4806, TrainAcc: 0.8576, ValAcc: 0.7702, ES: 31/50 | BestVal=0.7729@E59\n",
      "Epoch: 100, Time: 0.0511, Loss: 0.4690, TrainAcc: 0.8625, ValAcc: 0.7694, ES: 41/50 | BestVal=0.7729@E59\n",
      "Early stopped, loading model from epoch-59\n",
      "Finished running train at 05-22 17:14:05, running time = 3.34s.\n",
      "[SAGE + E] ValAcc: 0.7729, TestAcc: 0.7792\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7963, TestAcc: 0.8001\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:14:07\n",
      "Epoch: 0, Time: 0.0341, Loss: 3.7245, TrainAcc: 0.0680, ValAcc: 0.5881, ES: 00/50 | BestVal=0.5881@E0\n",
      "Epoch: 10, Time: 0.0285, Loss: 0.9634, TrainAcc: 0.7751, ValAcc: 0.7136, ES: 00/50 | BestVal=0.7136@E10\n",
      "Epoch: 20, Time: 0.0250, Loss: 0.7267, TrainAcc: 0.8185, ValAcc: 0.7442, ES: 01/50 | BestVal=0.7450@E19\n",
      "Epoch: 30, Time: 0.0283, Loss: 0.6193, TrainAcc: 0.8366, ValAcc: 0.7532, ES: 00/50 | BestVal=0.7532@E30\n",
      "Epoch: 40, Time: 0.0262, Loss: 0.5503, TrainAcc: 0.8521, ValAcc: 0.7597, ES: 04/50 | BestVal=0.7601@E36\n",
      "Epoch: 50, Time: 0.0260, Loss: 0.4992, TrainAcc: 0.8615, ValAcc: 0.7666, ES: 03/50 | BestVal=0.7668@E47\n",
      "Epoch: 60, Time: 0.0260, Loss: 0.4627, TrainAcc: 0.8697, ValAcc: 0.7682, ES: 01/50 | BestVal=0.7684@E59\n",
      "Epoch: 70, Time: 0.0256, Loss: 0.4341, TrainAcc: 0.8754, ValAcc: 0.7688, ES: 05/50 | BestVal=0.7697@E65\n",
      "Epoch: 80, Time: 0.0258, Loss: 0.4078, TrainAcc: 0.8815, ValAcc: 0.7694, ES: 04/50 | BestVal=0.7706@E76\n",
      "Epoch: 90, Time: 0.0258, Loss: 0.3984, TrainAcc: 0.8829, ValAcc: 0.7689, ES: 14/50 | BestVal=0.7706@E76\n",
      "Epoch: 100, Time: 0.0260, Loss: 0.3637, TrainAcc: 0.8925, ValAcc: 0.7666, ES: 24/50 | BestVal=0.7706@E76\n",
      "Epoch: 110, Time: 0.0261, Loss: 0.3598, TrainAcc: 0.8931, ValAcc: 0.7674, ES: 01/50 | BestVal=0.7706@E109\n",
      "Epoch: 120, Time: 0.0251, Loss: 0.3324, TrainAcc: 0.9001, ValAcc: 0.7686, ES: 11/50 | BestVal=0.7706@E109\n",
      "Epoch: 130, Time: 0.0250, Loss: 0.3058, TrainAcc: 0.9080, ValAcc: 0.7598, ES: 21/50 | BestVal=0.7706@E109\n",
      "Epoch: 140, Time: 0.0254, Loss: 0.2956, TrainAcc: 0.9130, ValAcc: 0.7579, ES: 31/50 | BestVal=0.7706@E109\n",
      "Epoch: 150, Time: 0.0258, Loss: 0.2674, TrainAcc: 0.9184, ValAcc: 0.7560, ES: 41/50 | BestVal=0.7706@E109\n",
      "Early stopped, loading model from epoch-109\n",
      "Finished running train at 05-22 17:14:12, running time = 4.26s.\n",
      "[SAGE + TA] ValAcc: 0.7706, TestAcc: 0.7725\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 246056\n",
      "Start running train at 05-22 17:14:13\n",
      "Epoch: 0, Time: 0.0398, Loss: 3.9709, TrainAcc: 0.0148, ValAcc: 0.5160, ES: 00/50 | BestVal=0.5160@E0\n",
      "Epoch: 10, Time: 0.0322, Loss: 1.2651, TrainAcc: 0.6933, ValAcc: 0.6773, ES: 00/50 | BestVal=0.6773@E10\n",
      "Epoch: 20, Time: 0.0322, Loss: 1.0106, TrainAcc: 0.7372, ValAcc: 0.7142, ES: 00/50 | BestVal=0.7142@E20\n",
      "Epoch: 30, Time: 0.0325, Loss: 0.8725, TrainAcc: 0.7540, ValAcc: 0.7305, ES: 00/50 | BestVal=0.7305@E30\n",
      "Epoch: 40, Time: 0.0324, Loss: 0.7741, TrainAcc: 0.7809, ValAcc: 0.7438, ES: 00/50 | BestVal=0.7438@E40\n",
      "Epoch: 50, Time: 0.0295, Loss: 0.6910, TrainAcc: 0.7991, ValAcc: 0.7446, ES: 04/50 | BestVal=0.7448@E46\n",
      "Epoch: 60, Time: 0.0299, Loss: 0.6162, TrainAcc: 0.8166, ValAcc: 0.7394, ES: 14/50 | BestVal=0.7448@E46\n",
      "Epoch: 70, Time: 0.0533, Loss: 0.5885, TrainAcc: 0.8249, ValAcc: 0.7315, ES: 24/50 | BestVal=0.7448@E46\n",
      "Epoch: 80, Time: 0.0529, Loss: 0.5108, TrainAcc: 0.8418, ValAcc: 0.7284, ES: 34/50 | BestVal=0.7448@E46\n",
      "Epoch: 90, Time: 0.0404, Loss: 0.4399, TrainAcc: 0.8625, ValAcc: 0.7240, ES: 44/50 | BestVal=0.7448@E46\n",
      "Early stopped, loading model from epoch-46\n",
      "Finished running train at 05-22 17:14:17, running time = 3.66s.\n",
      "[SAGE + P] ValAcc: 0.7448, TestAcc: 0.7548\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:14:18\n",
      "Epoch: 0, Time: 0.0281, Loss: 3.7624, TrainAcc: 0.0145, ValAcc: 0.6224, ES: 00/50 | BestVal=0.6224@E0\n",
      "Epoch: 10, Time: 0.0291, Loss: 1.0267, TrainAcc: 0.7685, ValAcc: 0.7173, ES: 00/50 | BestVal=0.7173@E10\n",
      "Epoch: 20, Time: 0.0285, Loss: 0.8132, TrainAcc: 0.7957, ValAcc: 0.7500, ES: 00/50 | BestVal=0.7500@E20\n",
      "Epoch: 30, Time: 0.0281, Loss: 0.7009, TrainAcc: 0.8191, ValAcc: 0.7643, ES: 00/50 | BestVal=0.7643@E30\n",
      "Epoch: 40, Time: 0.0260, Loss: 0.6263, TrainAcc: 0.8330, ValAcc: 0.7647, ES: 05/50 | BestVal=0.7649@E35\n",
      "Epoch: 50, Time: 0.0260, Loss: 0.5758, TrainAcc: 0.8397, ValAcc: 0.7659, ES: 01/50 | BestVal=0.7666@E49\n",
      "Epoch: 60, Time: 0.0252, Loss: 0.5405, TrainAcc: 0.8476, ValAcc: 0.7669, ES: 02/50 | BestVal=0.7674@E58\n",
      "Epoch: 70, Time: 0.0251, Loss: 0.5172, TrainAcc: 0.8515, ValAcc: 0.7644, ES: 12/50 | BestVal=0.7674@E58\n",
      "Epoch: 80, Time: 0.0252, Loss: 0.4925, TrainAcc: 0.8572, ValAcc: 0.7648, ES: 22/50 | BestVal=0.7674@E58\n",
      "Epoch: 90, Time: 0.0252, Loss: 0.4648, TrainAcc: 0.8645, ValAcc: 0.7654, ES: 32/50 | BestVal=0.7674@E58\n",
      "Epoch: 100, Time: 0.0254, Loss: 0.4450, TrainAcc: 0.8682, ValAcc: 0.7580, ES: 08/50 | BestVal=0.7680@E92\n",
      "Epoch: 110, Time: 0.0252, Loss: 0.4323, TrainAcc: 0.8713, ValAcc: 0.7623, ES: 18/50 | BestVal=0.7680@E92\n",
      "Epoch: 120, Time: 0.0259, Loss: 0.4002, TrainAcc: 0.8815, ValAcc: 0.7593, ES: 28/50 | BestVal=0.7680@E92\n",
      "Epoch: 130, Time: 0.0251, Loss: 0.4417, TrainAcc: 0.8688, ValAcc: 0.7600, ES: 38/50 | BestVal=0.7680@E92\n",
      "Epoch: 140, Time: 0.0266, Loss: 0.3844, TrainAcc: 0.8838, ValAcc: 0.7609, ES: 48/50 | BestVal=0.7680@E92\n",
      "Early stopped, loading model from epoch-92\n",
      "Finished running train at 05-22 17:14:22, running time = 3.79s.\n",
      "[SAGE + E] ValAcc: 0.7680, TestAcc: 0.7702\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7889, TestAcc: 0.7968\n",
      "\n",
      "[TA] ValACC: 0.7747 ± 0.0030, TestAcc: 0.7742 ± 0.0016\n",
      "[P] ValACC: 0.7490 ± 0.0040, TestAcc: 0.7486 ± 0.0060\n",
      "[E] ValACC: 0.7735 ± 0.0051, TestAcc: 0.7733 ± 0.0041\n",
      "[ensemble] ValACC: 0.7949 ± 0.0046, TestAcc: 0.7984 ± 0.0022\n",
      "Running time: 15.63s\n",
      "An import exception occurred\n",
      "/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.\n",
      "  dgl_warning(\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:14:26\n",
      "Epoch: 0, Time: 0.6859, Loss: 5.3959, TrainAcc: 0.0230, ValAcc: 0.0096, ES: 00/50 | BestVal=0.0096@E0\n",
      "Epoch: 10, Time: 0.1842, Loss: 1.3685, TrainAcc: 0.7062, ValAcc: 0.7521, ES: 00/50 | BestVal=0.7521@E10\n",
      "Epoch: 20, Time: 0.2408, Loss: 0.8421, TrainAcc: 0.8098, ValAcc: 0.7732, ES: 00/50 | BestVal=0.7732@E20\n",
      "Epoch: 30, Time: 0.1084, Loss: 0.7008, TrainAcc: 0.8362, ValAcc: 0.7784, ES: 01/50 | BestVal=0.7787@E29\n",
      "Epoch: 40, Time: 0.1085, Loss: 0.6196, TrainAcc: 0.8459, ValAcc: 0.7785, ES: 11/50 | BestVal=0.7787@E29\n",
      "Epoch: 50, Time: 0.1549, Loss: 0.5765, TrainAcc: 0.8510, ValAcc: 0.7785, ES: 21/50 | BestVal=0.7787@E29\n",
      "Epoch: 60, Time: 0.1521, Loss: 0.5446, TrainAcc: 0.8567, ValAcc: 0.7779, ES: 31/50 | BestVal=0.7787@E29\n",
      "Epoch: 70, Time: 0.2527, Loss: 0.5194, TrainAcc: 0.8584, ValAcc: 0.7775, ES: 41/50 | BestVal=0.7787@E29\n",
      "Epoch: 80, Time: 0.2353, Loss: 0.4981, TrainAcc: 0.8622, ValAcc: 0.7778, ES: 08/50 | BestVal=0.7788@E72\n",
      "Epoch: 90, Time: 0.2112, Loss: 0.4792, TrainAcc: 0.8657, ValAcc: 0.7790, ES: 08/50 | BestVal=0.7793@E82\n",
      "Epoch: 100, Time: 0.1536, Loss: 0.4683, TrainAcc: 0.8678, ValAcc: 0.7786, ES: 18/50 | BestVal=0.7793@E82\n",
      "Epoch: 110, Time: 0.1515, Loss: 0.4536, TrainAcc: 0.8698, ValAcc: 0.7799, ES: 06/50 | BestVal=0.7802@E104\n",
      "Epoch: 120, Time: 0.1520, Loss: 0.4460, TrainAcc: 0.8707, ValAcc: 0.7789, ES: 16/50 | BestVal=0.7802@E104\n",
      "Epoch: 130, Time: 0.1826, Loss: 0.4385, TrainAcc: 0.8726, ValAcc: 0.7802, ES: 06/50 | BestVal=0.7806@E124\n",
      "Epoch: 140, Time: 0.2375, Loss: 0.4280, TrainAcc: 0.8751, ValAcc: 0.7804, ES: 02/50 | BestVal=0.7806@E138\n",
      "Epoch: 150, Time: 0.1608, Loss: 0.4164, TrainAcc: 0.8786, ValAcc: 0.7801, ES: 12/50 | BestVal=0.7806@E138\n",
      "Epoch: 160, Time: 0.2338, Loss: 0.4175, TrainAcc: 0.8783, ValAcc: 0.7815, ES: 02/50 | BestVal=0.7826@E158\n",
      "Epoch: 170, Time: 0.1943, Loss: 0.4060, TrainAcc: 0.8803, ValAcc: 0.7800, ES: 12/50 | BestVal=0.7826@E158\n",
      "Epoch: 180, Time: 0.2048, Loss: 0.4058, TrainAcc: 0.8812, ValAcc: 0.7805, ES: 22/50 | BestVal=0.7826@E158\n",
      "Epoch: 190, Time: 0.1620, Loss: 0.3931, TrainAcc: 0.8820, ValAcc: 0.7816, ES: 32/50 | BestVal=0.7826@E158\n",
      "Finished running train at 05-22 17:15:03, running time = 36.78s.\n",
      "[RevGAT + TA] ValAcc: 0.7826, TestAcc: 0.7847\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 827216\n",
      "Start running train at 05-22 17:15:05\n",
      "Epoch: 0, Time: 0.2292, Loss: 5.3537, TrainAcc: 0.0222, ValAcc: 0.0106, ES: 00/50 | BestVal=0.0106@E0\n",
      "Epoch: 10, Time: 0.1823, Loss: 2.4404, TrainAcc: 0.4883, ValAcc: 0.6584, ES: 00/50 | BestVal=0.6584@E10\n",
      "Epoch: 20, Time: 0.1167, Loss: 1.5266, TrainAcc: 0.6586, ValAcc: 0.7379, ES: 00/50 | BestVal=0.7379@E20\n",
      "Epoch: 30, Time: 0.1127, Loss: 1.2403, TrainAcc: 0.7024, ValAcc: 0.7538, ES: 00/50 | BestVal=0.7538@E30\n",
      "Epoch: 40, Time: 0.1391, Loss: 1.0837, TrainAcc: 0.7258, ValAcc: 0.7589, ES: 01/50 | BestVal=0.7604@E39\n",
      "Epoch: 50, Time: 0.1033, Loss: 1.0242, TrainAcc: 0.7316, ValAcc: 0.7557, ES: 03/50 | BestVal=0.7614@E47\n",
      "Epoch: 60, Time: 0.1031, Loss: 0.9353, TrainAcc: 0.7415, ValAcc: 0.7601, ES: 07/50 | BestVal=0.7632@E53\n",
      "Epoch: 70, Time: 0.2419, Loss: 0.8968, TrainAcc: 0.7487, ValAcc: 0.7634, ES: 03/50 | BestVal=0.7639@E67\n",
      "Epoch: 80, Time: 0.2120, Loss: 0.8592, TrainAcc: 0.7568, ValAcc: 0.7648, ES: 07/50 | BestVal=0.7649@E73\n",
      "Epoch: 90, Time: 0.1831, Loss: 0.8357, TrainAcc: 0.7578, ValAcc: 0.7656, ES: 00/50 | BestVal=0.7656@E90\n",
      "Epoch: 100, Time: 0.1100, Loss: 0.8133, TrainAcc: 0.7632, ValAcc: 0.7660, ES: 07/50 | BestVal=0.7665@E93\n",
      "Epoch: 110, Time: 0.1123, Loss: 0.7983, TrainAcc: 0.7655, ValAcc: 0.7665, ES: 08/50 | BestVal=0.7671@E102\n",
      "Epoch: 120, Time: 0.1876, Loss: 0.7749, TrainAcc: 0.7678, ValAcc: 0.7669, ES: 06/50 | BestVal=0.7680@E114\n",
      "Epoch: 130, Time: 0.1673, Loss: 0.7622, TrainAcc: 0.7722, ValAcc: 0.7658, ES: 06/50 | BestVal=0.7681@E124\n",
      "Epoch: 140, Time: 0.2266, Loss: 0.7472, TrainAcc: 0.7749, ValAcc: 0.7674, ES: 16/50 | BestVal=0.7681@E124\n",
      "Epoch: 150, Time: 0.1420, Loss: 0.7335, TrainAcc: 0.7799, ValAcc: 0.7670, ES: 26/50 | BestVal=0.7681@E124\n",
      "Epoch: 160, Time: 0.1512, Loss: 0.7250, TrainAcc: 0.7800, ValAcc: 0.7671, ES: 04/50 | BestVal=0.7684@E156\n",
      "Epoch: 170, Time: 0.1418, Loss: 0.7158, TrainAcc: 0.7792, ValAcc: 0.7674, ES: 14/50 | BestVal=0.7684@E156\n",
      "Epoch: 180, Time: 0.1423, Loss: 0.7017, TrainAcc: 0.7837, ValAcc: 0.7667, ES: 24/50 | BestVal=0.7684@E156\n",
      "Epoch: 190, Time: 0.1399, Loss: 0.6964, TrainAcc: 0.7858, ValAcc: 0.7656, ES: 34/50 | BestVal=0.7684@E156\n",
      "Finished running train at 05-22 17:15:37, running time = 32.88s.\n",
      "[RevGAT + P] ValAcc: 0.7684, TestAcc: 0.7580\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:15:39\n",
      "Epoch: 0, Time: 0.2252, Loss: 5.4607, TrainAcc: 0.0174, ValAcc: 0.0113, ES: 00/50 | BestVal=0.0113@E0\n",
      "Epoch: 10, Time: 0.1966, Loss: 1.4583, TrainAcc: 0.6931, ValAcc: 0.7626, ES: 00/50 | BestVal=0.7626@E10\n",
      "Epoch: 20, Time: 0.2269, Loss: 0.9745, TrainAcc: 0.7883, ValAcc: 0.7798, ES: 00/50 | BestVal=0.7798@E20\n",
      "Epoch: 30, Time: 0.1688, Loss: 0.8330, TrainAcc: 0.8095, ValAcc: 0.7823, ES: 02/50 | BestVal=0.7837@E28\n",
      "Epoch: 40, Time: 0.1577, Loss: 0.7597, TrainAcc: 0.8180, ValAcc: 0.7801, ES: 08/50 | BestVal=0.7838@E32\n",
      "Epoch: 50, Time: 0.2043, Loss: 0.7141, TrainAcc: 0.8220, ValAcc: 0.7805, ES: 18/50 | BestVal=0.7838@E32\n",
      "Epoch: 60, Time: 0.1479, Loss: 0.6607, TrainAcc: 0.8278, ValAcc: 0.7808, ES: 28/50 | BestVal=0.7838@E32\n",
      "Epoch: 70, Time: 0.3019, Loss: 0.6425, TrainAcc: 0.8279, ValAcc: 0.7828, ES: 38/50 | BestVal=0.7838@E32\n",
      "Epoch: 80, Time: 0.1989, Loss: 0.6229, TrainAcc: 0.8318, ValAcc: 0.7829, ES: 48/50 | BestVal=0.7838@E32\n",
      "Epoch: 90, Time: 0.1948, Loss: 0.6034, TrainAcc: 0.8319, ValAcc: 0.7821, ES: 08/50 | BestVal=0.7841@E82\n",
      "Epoch: 100, Time: 0.1987, Loss: 0.5881, TrainAcc: 0.8357, ValAcc: 0.7804, ES: 07/50 | BestVal=0.7845@E93\n",
      "Epoch: 110, Time: 0.2190, Loss: 0.5814, TrainAcc: 0.8377, ValAcc: 0.7811, ES: 17/50 | BestVal=0.7845@E93\n",
      "Epoch: 120, Time: 0.1591, Loss: 0.5648, TrainAcc: 0.8402, ValAcc: 0.7811, ES: 27/50 | BestVal=0.7845@E93\n",
      "Epoch: 130, Time: 0.1939, Loss: 0.5622, TrainAcc: 0.8404, ValAcc: 0.7813, ES: 37/50 | BestVal=0.7845@E93\n",
      "Epoch: 140, Time: 0.2601, Loss: 0.5489, TrainAcc: 0.8422, ValAcc: 0.7820, ES: 47/50 | BestVal=0.7845@E93\n",
      "Early stopped, loading model from epoch-93\n",
      "Finished running train at 05-22 17:16:08, running time = 29.18s.\n",
      "[RevGAT + E] ValAcc: 0.7845, TestAcc: 0.7792\n",
      "\n",
      "(TA_P_E) ValAcc: 0.8049, TestAcc: 0.8040\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:16:10\n",
      "Epoch: 0, Time: 0.2036, Loss: 5.3159, TrainAcc: 0.0287, ValAcc: 0.0062, ES: 00/50 | BestVal=0.0062@E0\n",
      "Epoch: 10, Time: 0.2136, Loss: 1.2478, TrainAcc: 0.7362, ValAcc: 0.7550, ES: 00/50 | BestVal=0.7550@E10\n",
      "Epoch: 20, Time: 0.1646, Loss: 0.7480, TrainAcc: 0.8410, ValAcc: 0.7761, ES: 00/50 | BestVal=0.7761@E20\n",
      "Epoch: 30, Time: 0.2069, Loss: 0.6291, TrainAcc: 0.8575, ValAcc: 0.7781, ES: 04/50 | BestVal=0.7788@E26\n",
      "Epoch: 40, Time: 0.2293, Loss: 0.5532, TrainAcc: 0.8702, ValAcc: 0.7789, ES: 05/50 | BestVal=0.7793@E35\n",
      "Epoch: 50, Time: 0.1922, Loss: 0.5151, TrainAcc: 0.8754, ValAcc: 0.7825, ES: 00/50 | BestVal=0.7825@E50\n",
      "Epoch: 60, Time: 0.1798, Loss: 0.4833, TrainAcc: 0.8785, ValAcc: 0.7812, ES: 10/50 | BestVal=0.7825@E50\n",
      "Epoch: 70, Time: 0.2078, Loss: 0.4612, TrainAcc: 0.8815, ValAcc: 0.7812, ES: 20/50 | BestVal=0.7825@E50\n",
      "Epoch: 80, Time: 0.1656, Loss: 0.4450, TrainAcc: 0.8848, ValAcc: 0.7825, ES: 00/50 | BestVal=0.7825@E80\n",
      "Epoch: 90, Time: 0.3637, Loss: 0.4320, TrainAcc: 0.8861, ValAcc: 0.7820, ES: 10/50 | BestVal=0.7825@E80\n",
      "Epoch: 100, Time: 0.2124, Loss: 0.4112, TrainAcc: 0.8896, ValAcc: 0.7817, ES: 20/50 | BestVal=0.7825@E80\n",
      "Epoch: 110, Time: 0.2039, Loss: 0.4066, TrainAcc: 0.8900, ValAcc: 0.7805, ES: 30/50 | BestVal=0.7825@E80\n",
      "Epoch: 120, Time: 0.1089, Loss: 0.4002, TrainAcc: 0.8907, ValAcc: 0.7814, ES: 40/50 | BestVal=0.7825@E80\n",
      "Early stopped, loading model from epoch-80\n",
      "Finished running train at 05-22 17:16:35, running time = 24.91s.\n",
      "[RevGAT + TA] ValAcc: 0.7825, TestAcc: 0.7818\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 827216\n",
      "Start running train at 05-22 17:16:36\n",
      "Epoch: 0, Time: 0.1552, Loss: 5.6309, TrainAcc: 0.0228, ValAcc: 0.0095, ES: 00/50 | BestVal=0.0095@E0\n",
      "Epoch: 10, Time: 0.2441, Loss: 2.5190, TrainAcc: 0.4607, ValAcc: 0.6427, ES: 00/50 | BestVal=0.6427@E10\n",
      "Epoch: 20, Time: 0.1346, Loss: 1.5631, TrainAcc: 0.6487, ValAcc: 0.7288, ES: 00/50 | BestVal=0.7288@E20\n",
      "Epoch: 30, Time: 0.1657, Loss: 1.2512, TrainAcc: 0.6991, ValAcc: 0.7452, ES: 00/50 | BestVal=0.7452@E30\n",
      "Epoch: 40, Time: 0.1758, Loss: 1.1451, TrainAcc: 0.7133, ValAcc: 0.7522, ES: 00/50 | BestVal=0.7522@E40\n",
      "Epoch: 50, Time: 0.1762, Loss: 1.0128, TrainAcc: 0.7295, ValAcc: 0.7536, ES: 02/50 | BestVal=0.7551@E48\n",
      "Epoch: 60, Time: 0.1533, Loss: 0.9415, TrainAcc: 0.7416, ValAcc: 0.7565, ES: 01/50 | BestVal=0.7577@E59\n",
      "Epoch: 70, Time: 0.1383, Loss: 0.8974, TrainAcc: 0.7489, ValAcc: 0.7584, ES: 01/50 | BestVal=0.7590@E69\n",
      "Epoch: 80, Time: 0.2077, Loss: 0.8544, TrainAcc: 0.7541, ValAcc: 0.7603, ES: 01/50 | BestVal=0.7607@E79\n",
      "Epoch: 90, Time: 0.2707, Loss: 0.8348, TrainAcc: 0.7592, ValAcc: 0.7598, ES: 02/50 | BestVal=0.7613@E88\n",
      "Epoch: 100, Time: 0.1818, Loss: 0.8169, TrainAcc: 0.7602, ValAcc: 0.7596, ES: 09/50 | BestVal=0.7614@E91\n",
      "Epoch: 110, Time: 0.1530, Loss: 0.7925, TrainAcc: 0.7646, ValAcc: 0.7595, ES: 19/50 | BestVal=0.7614@E91\n",
      "Epoch: 120, Time: 0.1664, Loss: 0.7819, TrainAcc: 0.7676, ValAcc: 0.7595, ES: 05/50 | BestVal=0.7618@E115\n",
      "Epoch: 130, Time: 0.1415, Loss: 0.7665, TrainAcc: 0.7707, ValAcc: 0.7593, ES: 15/50 | BestVal=0.7618@E115\n",
      "Epoch: 140, Time: 0.1364, Loss: 0.7491, TrainAcc: 0.7726, ValAcc: 0.7580, ES: 25/50 | BestVal=0.7618@E115\n",
      "Epoch: 150, Time: 0.1973, Loss: 0.7384, TrainAcc: 0.7761, ValAcc: 0.7591, ES: 35/50 | BestVal=0.7618@E115\n",
      "Epoch: 160, Time: 0.1613, Loss: 0.7312, TrainAcc: 0.7784, ValAcc: 0.7564, ES: 45/50 | BestVal=0.7618@E115\n",
      "Early stopped, loading model from epoch-115\n",
      "Finished running train at 05-22 17:17:07, running time = 30.86s.\n",
      "[RevGAT + P] ValAcc: 0.7618, TestAcc: 0.7598\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:17:08\n",
      "Epoch: 0, Time: 0.1423, Loss: 5.2505, TrainAcc: 0.0329, ValAcc: 0.0058, ES: 00/50 | BestVal=0.0058@E0\n",
      "Epoch: 10, Time: 0.1856, Loss: 1.4533, TrainAcc: 0.6979, ValAcc: 0.7557, ES: 00/50 | BestVal=0.7557@E10\n",
      "Epoch: 20, Time: 0.1673, Loss: 1.0043, TrainAcc: 0.7861, ValAcc: 0.7709, ES: 00/50 | BestVal=0.7709@E20\n",
      "Epoch: 30, Time: 0.1632, Loss: 0.8549, TrainAcc: 0.8032, ValAcc: 0.7714, ES: 09/50 | BestVal=0.7727@E21\n",
      "Epoch: 40, Time: 0.1723, Loss: 0.7741, TrainAcc: 0.8137, ValAcc: 0.7713, ES: 03/50 | BestVal=0.7739@E37\n",
      "Epoch: 50, Time: 0.1719, Loss: 0.7569, TrainAcc: 0.8158, ValAcc: 0.7693, ES: 09/50 | BestVal=0.7750@E41\n",
      "Epoch: 60, Time: 0.1464, Loss: 0.6847, TrainAcc: 0.8215, ValAcc: 0.7723, ES: 19/50 | BestVal=0.7750@E41\n",
      "Epoch: 70, Time: 0.1581, Loss: 0.6606, TrainAcc: 0.8239, ValAcc: 0.7720, ES: 29/50 | BestVal=0.7750@E41\n",
      "Epoch: 80, Time: 0.1308, Loss: 0.6415, TrainAcc: 0.8263, ValAcc: 0.7707, ES: 39/50 | BestVal=0.7750@E41\n",
      "Epoch: 90, Time: 0.2168, Loss: 0.6272, TrainAcc: 0.8277, ValAcc: 0.7710, ES: 49/50 | BestVal=0.7750@E41\n",
      "Early stopped, loading model from epoch-41\n",
      "Finished running train at 05-22 17:17:24, running time = 15.96s.\n",
      "[RevGAT + E] ValAcc: 0.7750, TestAcc: 0.7765\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7970, TestAcc: 0.8013\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:17:27\n",
      "Epoch: 0, Time: 0.2493, Loss: 5.6402, TrainAcc: 0.0166, ValAcc: 0.0242, ES: 00/50 | BestVal=0.0242@E0\n",
      "Epoch: 10, Time: 0.2166, Loss: 1.2829, TrainAcc: 0.7297, ValAcc: 0.7615, ES: 00/50 | BestVal=0.7615@E10\n",
      "Epoch: 20, Time: 0.1762, Loss: 0.7586, TrainAcc: 0.8403, ValAcc: 0.7794, ES: 00/50 | BestVal=0.7794@E20\n",
      "Epoch: 30, Time: 0.1233, Loss: 0.6231, TrainAcc: 0.8616, ValAcc: 0.7840, ES: 00/50 | BestVal=0.7840@E30\n",
      "Epoch: 40, Time: 0.1522, Loss: 0.5550, TrainAcc: 0.8703, ValAcc: 0.7834, ES: 09/50 | BestVal=0.7847@E31\n",
      "Epoch: 50, Time: 0.1909, Loss: 0.5091, TrainAcc: 0.8745, ValAcc: 0.7804, ES: 19/50 | BestVal=0.7847@E31\n",
      "Epoch: 60, Time: 0.2066, Loss: 0.4784, TrainAcc: 0.8784, ValAcc: 0.7826, ES: 29/50 | BestVal=0.7847@E31\n",
      "Epoch: 70, Time: 0.1448, Loss: 0.4587, TrainAcc: 0.8791, ValAcc: 0.7824, ES: 39/50 | BestVal=0.7847@E31\n",
      "Epoch: 80, Time: 0.1709, Loss: 0.4403, TrainAcc: 0.8826, ValAcc: 0.7820, ES: 49/50 | BestVal=0.7847@E31\n",
      "Early stopped, loading model from epoch-31\n",
      "Finished running train at 05-22 17:17:41, running time = 14.88s.\n",
      "[RevGAT + TA] ValAcc: 0.7847, TestAcc: 0.7791\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 827216\n",
      "Start running train at 05-22 17:17:43\n",
      "Epoch: 0, Time: 0.1101, Loss: 5.3894, TrainAcc: 0.0209, ValAcc: 0.0229, ES: 00/50 | BestVal=0.0229@E0\n",
      "Epoch: 10, Time: 0.1723, Loss: 2.4473, TrainAcc: 0.4789, ValAcc: 0.6530, ES: 00/50 | BestVal=0.6530@E10\n",
      "Epoch: 20, Time: 0.1659, Loss: 1.5647, TrainAcc: 0.6476, ValAcc: 0.7351, ES: 00/50 | BestVal=0.7351@E20\n",
      "Epoch: 30, Time: 0.4583, Loss: 1.2683, TrainAcc: 0.6989, ValAcc: 0.7549, ES: 00/50 | BestVal=0.7549@E30\n",
      "Epoch: 40, Time: 0.1523, Loss: 1.1487, TrainAcc: 0.7085, ValAcc: 0.7553, ES: 05/50 | BestVal=0.7587@E35\n",
      "Epoch: 50, Time: 0.1642, Loss: 1.0467, TrainAcc: 0.7239, ValAcc: 0.7551, ES: 03/50 | BestVal=0.7618@E47\n",
      "Epoch: 60, Time: 0.1572, Loss: 0.9506, TrainAcc: 0.7367, ValAcc: 0.7627, ES: 00/50 | BestVal=0.7627@E60\n",
      "Epoch: 70, Time: 0.1596, Loss: 0.8969, TrainAcc: 0.7497, ValAcc: 0.7653, ES: 05/50 | BestVal=0.7655@E65\n",
      "Epoch: 80, Time: 0.1432, Loss: 0.8734, TrainAcc: 0.7513, ValAcc: 0.7644, ES: 15/50 | BestVal=0.7655@E65\n",
      "Epoch: 90, Time: 0.2054, Loss: 0.8456, TrainAcc: 0.7562, ValAcc: 0.7680, ES: 00/50 | BestVal=0.7680@E90\n",
      "Epoch: 100, Time: 0.2679, Loss: 0.8197, TrainAcc: 0.7593, ValAcc: 0.7647, ES: 10/50 | BestVal=0.7680@E90\n",
      "Epoch: 110, Time: 0.1731, Loss: 0.8020, TrainAcc: 0.7620, ValAcc: 0.7652, ES: 09/50 | BestVal=0.7682@E101\n",
      "Epoch: 120, Time: 0.1636, Loss: 0.7822, TrainAcc: 0.7648, ValAcc: 0.7656, ES: 19/50 | BestVal=0.7682@E101\n",
      "Epoch: 130, Time: 0.1922, Loss: 0.7717, TrainAcc: 0.7692, ValAcc: 0.7643, ES: 29/50 | BestVal=0.7682@E101\n",
      "Epoch: 140, Time: 0.1785, Loss: 0.7583, TrainAcc: 0.7734, ValAcc: 0.7648, ES: 39/50 | BestVal=0.7682@E101\n",
      "Epoch: 150, Time: 0.1401, Loss: 0.7488, TrainAcc: 0.7733, ValAcc: 0.7630, ES: 49/50 | BestVal=0.7682@E101\n",
      "Early stopped, loading model from epoch-101\n",
      "Finished running train at 05-22 17:18:10, running time = 26.90s.\n",
      "[RevGAT + P] ValAcc: 0.7682, TestAcc: 0.7680\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:18:11\n",
      "Epoch: 0, Time: 0.1185, Loss: 5.6472, TrainAcc: 0.0159, ValAcc: 0.0097, ES: 00/50 | BestVal=0.0097@E0\n",
      "Epoch: 10, Time: 0.2660, Loss: 1.4805, TrainAcc: 0.6955, ValAcc: 0.7626, ES: 00/50 | BestVal=0.7626@E10\n",
      "Epoch: 20, Time: 0.2469, Loss: 1.0069, TrainAcc: 0.7892, ValAcc: 0.7792, ES: 00/50 | BestVal=0.7792@E20\n",
      "Epoch: 30, Time: 0.1957, Loss: 0.8556, TrainAcc: 0.8041, ValAcc: 0.7791, ES: 01/50 | BestVal=0.7807@E29\n",
      "Epoch: 40, Time: 0.1767, Loss: 0.7851, TrainAcc: 0.8128, ValAcc: 0.7772, ES: 11/50 | BestVal=0.7807@E29\n",
      "Epoch: 50, Time: 0.1597, Loss: 0.7346, TrainAcc: 0.8164, ValAcc: 0.7746, ES: 21/50 | BestVal=0.7807@E29\n",
      "Epoch: 60, Time: 0.1451, Loss: 0.6894, TrainAcc: 0.8190, ValAcc: 0.7788, ES: 31/50 | BestVal=0.7807@E29\n",
      "Epoch: 70, Time: 0.3236, Loss: 0.6648, TrainAcc: 0.8237, ValAcc: 0.7778, ES: 41/50 | BestVal=0.7807@E29\n",
      "Early stopped, loading model from epoch-29\n",
      "Finished running train at 05-22 17:18:26, running time = 15.60s.\n",
      "[RevGAT + E] ValAcc: 0.7807, TestAcc: 0.7844\n",
      "\n",
      "(TA_P_E) ValAcc: 0.8024, TestAcc: 0.8041\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/arxiv_2023/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:18:29\n",
      "Epoch: 0, Time: 0.1388, Loss: 5.6008, TrainAcc: 0.0159, ValAcc: 0.0106, ES: 00/50 | BestVal=0.0106@E0\n",
      "Epoch: 10, Time: 0.1786, Loss: 1.3918, TrainAcc: 0.7039, ValAcc: 0.7498, ES: 00/50 | BestVal=0.7498@E10\n",
      "Epoch: 20, Time: 0.1946, Loss: 0.8677, TrainAcc: 0.8066, ValAcc: 0.7699, ES: 00/50 | BestVal=0.7699@E20\n",
      "Epoch: 30, Time: 0.1674, Loss: 0.7308, TrainAcc: 0.8295, ValAcc: 0.7708, ES: 01/50 | BestVal=0.7714@E29\n",
      "Epoch: 40, Time: 0.2445, Loss: 0.6576, TrainAcc: 0.8372, ValAcc: 0.7728, ES: 05/50 | BestVal=0.7732@E35\n",
      "Epoch: 50, Time: 0.1540, Loss: 0.6144, TrainAcc: 0.8449, ValAcc: 0.7718, ES: 07/50 | BestVal=0.7746@E43\n",
      "Epoch: 60, Time: 0.1536, Loss: 0.5740, TrainAcc: 0.8489, ValAcc: 0.7728, ES: 17/50 | BestVal=0.7746@E43\n",
      "Epoch: 70, Time: 0.1742, Loss: 0.5513, TrainAcc: 0.8520, ValAcc: 0.7751, ES: 00/50 | BestVal=0.7751@E70\n",
      "Epoch: 80, Time: 0.1712, Loss: 0.5241, TrainAcc: 0.8565, ValAcc: 0.7732, ES: 10/50 | BestVal=0.7751@E70\n",
      "Epoch: 90, Time: 0.1388, Loss: 0.5089, TrainAcc: 0.8597, ValAcc: 0.7747, ES: 20/50 | BestVal=0.7751@E70\n",
      "Epoch: 100, Time: 0.1502, Loss: 0.4960, TrainAcc: 0.8615, ValAcc: 0.7764, ES: 01/50 | BestVal=0.7767@E99\n",
      "Epoch: 110, Time: 0.2160, Loss: 0.4827, TrainAcc: 0.8639, ValAcc: 0.7746, ES: 09/50 | BestVal=0.7771@E101\n",
      "Epoch: 120, Time: 0.2364, Loss: 0.4781, TrainAcc: 0.8629, ValAcc: 0.7732, ES: 19/50 | BestVal=0.7771@E101\n",
      "Epoch: 130, Time: 0.2368, Loss: 0.4707, TrainAcc: 0.8652, ValAcc: 0.7740, ES: 29/50 | BestVal=0.7771@E101\n",
      "Epoch: 140, Time: 0.1068, Loss: 0.4579, TrainAcc: 0.8671, ValAcc: 0.7751, ES: 39/50 | BestVal=0.7771@E101\n",
      "Epoch: 150, Time: 0.1171, Loss: 0.4530, TrainAcc: 0.8679, ValAcc: 0.7759, ES: 49/50 | BestVal=0.7771@E101\n",
      "Early stopped, loading model from epoch-101\n",
      "Finished running train at 05-22 17:18:55, running time = 26.20s.\n",
      "[RevGAT + TA] ValAcc: 0.7771, TestAcc: 0.7801\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/arxiv_2023.csv\n",
      "\n",
      "Number of parameters: 827216\n",
      "Start running train at 05-22 17:18:56\n",
      "Epoch: 0, Time: 0.1597, Loss: 5.3845, TrainAcc: 0.0203, ValAcc: 0.0157, ES: 00/50 | BestVal=0.0157@E0\n",
      "Epoch: 10, Time: 0.1537, Loss: 2.4275, TrainAcc: 0.4812, ValAcc: 0.6540, ES: 00/50 | BestVal=0.6540@E10\n",
      "Epoch: 20, Time: 0.3228, Loss: 1.5448, TrainAcc: 0.6528, ValAcc: 0.7288, ES: 00/50 | BestVal=0.7288@E20\n",
      "Epoch: 30, Time: 0.1126, Loss: 1.2350, TrainAcc: 0.7039, ValAcc: 0.7434, ES: 00/50 | BestVal=0.7434@E30\n",
      "Epoch: 40, Time: 0.1668, Loss: 1.1000, TrainAcc: 0.7228, ValAcc: 0.7495, ES: 00/50 | BestVal=0.7495@E40\n",
      "Epoch: 50, Time: 0.1704, Loss: 1.0157, TrainAcc: 0.7328, ValAcc: 0.7484, ES: 08/50 | BestVal=0.7500@E42\n",
      "Epoch: 60, Time: 0.2000, Loss: 0.9374, TrainAcc: 0.7460, ValAcc: 0.7529, ES: 00/50 | BestVal=0.7529@E60\n",
      "Epoch: 70, Time: 0.1489, Loss: 0.8955, TrainAcc: 0.7526, ValAcc: 0.7527, ES: 01/50 | BestVal=0.7543@E69\n",
      "Epoch: 80, Time: 0.1374, Loss: 0.8592, TrainAcc: 0.7580, ValAcc: 0.7553, ES: 05/50 | BestVal=0.7561@E75\n",
      "Epoch: 90, Time: 0.1861, Loss: 0.8348, TrainAcc: 0.7630, ValAcc: 0.7551, ES: 04/50 | BestVal=0.7564@E86\n",
      "Epoch: 100, Time: 0.1846, Loss: 0.8073, TrainAcc: 0.7676, ValAcc: 0.7556, ES: 09/50 | BestVal=0.7565@E91\n",
      "Epoch: 110, Time: 0.1719, Loss: 0.7908, TrainAcc: 0.7672, ValAcc: 0.7547, ES: 01/50 | BestVal=0.7566@E109\n",
      "Epoch: 120, Time: 0.1869, Loss: 0.7768, TrainAcc: 0.7712, ValAcc: 0.7545, ES: 01/50 | BestVal=0.7574@E119\n",
      "Epoch: 130, Time: 0.1832, Loss: 0.7644, TrainAcc: 0.7724, ValAcc: 0.7515, ES: 11/50 | BestVal=0.7574@E119\n",
      "Epoch: 140, Time: 0.1783, Loss: 0.7611, TrainAcc: 0.7730, ValAcc: 0.7541, ES: 21/50 | BestVal=0.7574@E119\n",
      "Epoch: 150, Time: 0.2606, Loss: 0.7358, TrainAcc: 0.7785, ValAcc: 0.7530, ES: 31/50 | BestVal=0.7574@E119\n",
      "Epoch: 160, Time: 0.1644, Loss: 0.7300, TrainAcc: 0.7794, ValAcc: 0.7503, ES: 41/50 | BestVal=0.7574@E119\n",
      "Early stopped, loading model from epoch-119\n",
      "Finished running train at 05-22 17:19:27, running time = 30.54s.\n",
      "[RevGAT + P] ValAcc: 0.7574, TestAcc: 0.7652\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/arxiv_20232/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 920528\n",
      "Start running train at 05-22 17:19:28\n",
      "Epoch: 0, Time: 0.2169, Loss: 5.4173, TrainAcc: 0.0228, ValAcc: 0.0245, ES: 00/50 | BestVal=0.0245@E0\n",
      "Epoch: 10, Time: 0.1117, Loss: 1.4880, TrainAcc: 0.6917, ValAcc: 0.7555, ES: 00/50 | BestVal=0.7555@E10\n",
      "Epoch: 20, Time: 0.1616, Loss: 0.9904, TrainAcc: 0.7890, ValAcc: 0.7732, ES: 00/50 | BestVal=0.7732@E20\n",
      "Epoch: 30, Time: 0.2213, Loss: 0.8482, TrainAcc: 0.8053, ValAcc: 0.7755, ES: 00/50 | BestVal=0.7755@E30\n",
      "Epoch: 40, Time: 0.1461, Loss: 0.7659, TrainAcc: 0.8128, ValAcc: 0.7753, ES: 10/50 | BestVal=0.7755@E30\n",
      "Epoch: 50, Time: 0.1847, Loss: 0.7210, TrainAcc: 0.8172, ValAcc: 0.7750, ES: 02/50 | BestVal=0.7758@E48\n",
      "Epoch: 60, Time: 0.2052, Loss: 0.6801, TrainAcc: 0.8238, ValAcc: 0.7755, ES: 02/50 | BestVal=0.7764@E58\n",
      "Epoch: 70, Time: 0.1476, Loss: 0.6514, TrainAcc: 0.8286, ValAcc: 0.7751, ES: 12/50 | BestVal=0.7764@E58\n",
      "Epoch: 80, Time: 0.1851, Loss: 0.6278, TrainAcc: 0.8318, ValAcc: 0.7732, ES: 22/50 | BestVal=0.7764@E58\n",
      "Epoch: 90, Time: 0.1807, Loss: 0.6144, TrainAcc: 0.8337, ValAcc: 0.7734, ES: 32/50 | BestVal=0.7764@E58\n",
      "Epoch: 100, Time: 0.3789, Loss: 0.5967, TrainAcc: 0.8363, ValAcc: 0.7744, ES: 42/50 | BestVal=0.7764@E58\n",
      "Early stopped, loading model from epoch-58\n",
      "Finished running train at 05-22 17:19:49, running time = 21.17s.\n",
      "[RevGAT + E] ValAcc: 0.7764, TestAcc: 0.7800\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7934, TestAcc: 0.7996\n",
      "\n",
      "[TA] ValACC: 0.7817 ± 0.0033, TestAcc: 0.7814 ± 0.0025\n",
      "[P] ValACC: 0.7639 ± 0.0053, TestAcc: 0.7627 ± 0.0046\n",
      "[E] ValACC: 0.7792 ± 0.0043, TestAcc: 0.7800 ± 0.0033\n",
      "[ensemble] ValACC: 0.7994 ± 0.0052, TestAcc: 0.8022 ± 0.0022\n",
      "Running time: 81.46s\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name GCN seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name SAGE seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name RevGAT gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "[microsoft/deberta-base+MLP+E] TrainACC: 0.8463 ± 0.0042, ValACC: 0.7727 ± 0.003552795857008879, TestACC: 0.7729 ± 0.0017\n",
      "[microsoft/deberta-base+MLP+E+C] TrainACC: 0.8942 ± 0.0026, ValACC: 0.7754 ± 0.003508007440445362, TestACC: 0.7759 ± 0.0024\n",
      "[microsoft/deberta-base+MLP+E+S] TrainACC: 0.9999 ± 0.0000, ValACC: 0.7769 ± 0.0037171294239928578, TestACC: 0.7774 ± 0.0022\n",
      "[microsoft/deberta-base+MLP+Ensemble] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+C] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+S] TrainACC: 1.0000 ± 0.0000, ValACC: 0.7960 ± 0.005033340239927864, TestACC: 0.7983 ± 0.0025\n",
      "[microsoft/deberta-base+MLP+P] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+C] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+S] TrainACC: 0.9941 ± 0.0005, ValACC: 0.7613 ± 0.005003680329394017, TestACC: 0.7609 ± 0.0040\n",
      "[microsoft/deberta-base+MLP+TA] TrainACC: 0.8992 ± 0.0122, ValACC: 0.7768 ± 0.0029445384979247926, TestACC: 0.7767 ± 0.0008\n",
      "[microsoft/deberta-base+MLP+TA+C] TrainACC: 0.9190 ± 0.0080, ValACC: 0.7779 ± 0.0030984655067618225, TestACC: 0.7777 ± 0.0016\n",
      "[microsoft/deberta-base+MLP+TA+S] TrainACC: 0.9960 ± 0.0003, ValACC: 0.7822 ± 0.003196307234983218, TestACC: 0.7820 ± 0.0026\n",
      "Running time: 8.94s\n",
      "params_dict: {'alpha': 0.2619006279952869, 'A': 1, 'num_propagations': 40, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_GCN_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.6506305925296677, 'A': 2, 'num_propagations': 100, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_SAGE_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.46236078615130993, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_RevGAT_TA_None_seed0.pred'\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"MLP\", \"GCN\", \"SAGE\", \"RevGAT\"]:\n",
    "    !python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\"\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name RevGAT seed $SEED runs $RUNS cas.use_lm_pred True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: ogbn-arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"ogbn-arxiv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Node2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([     0,      0,      0,  ..., 169341, 169342, 169342]),\n",
      "             col=tensor([   411,    640,   1162,  ..., 163274,  27824, 158981]),\n",
      "             size=(169343, 169343), nnz=2315598, density=0.01%)\n",
      "tensor([[     0,      0,      0,  ..., 169341, 169342, 169342],\n",
      "        [   411,    640,   1162,  ..., 163274,  27824, 158981]])\n",
      "Start running train at 05-22 17:43:10\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 35, in <module>\n",
      "    main(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 18, in main\n",
      "    trainer.train()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/utils.py\", line 80, in wrapper\n",
      "    ret = func(*args, **kw)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 113, in train\n",
      "    loss, train_acc = self._train(loader, optimizer)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 70, in _train\n",
      "    loss = self.model.loss(pos_rw.to(self.device), neg_rw.to(self.device))\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch_geometric/nn/models/node2vec.py\", line 148, in loss\n",
      "    h_start = self.embedding(start).view(pos_rw.size(0), 1,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1130, in _call_impl\n",
      "    return forward_call(*input, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/nn/modules/sparse.py\", line 158, in forward\n",
      "    return F.embedding(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/nn/functional.py\", line 2199, in embedding\n",
      "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainNode2Vec dataset $dataset seed $SEED runs $RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP and GNNs on TAPE Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:19:55\n",
      "Epoch: 0, Time: 0.3842, Loss: 3.8923, TrainAcc: 0.0167, ValAcc: 0.0386, ES: 00/50 | BestVal=0.0386@E0\n",
      "Epoch: 10, Time: 0.0352, Loss: 1.9034, TrainAcc: 0.6292, ValAcc: 0.6698, ES: 01/50 | BestVal=0.6699@E9\n",
      "Epoch: 20, Time: 0.0376, Loss: 1.4277, TrainAcc: 0.6903, ValAcc: 0.6796, ES: 00/50 | BestVal=0.6796@E20\n",
      "Epoch: 30, Time: 0.0369, Loss: 1.1897, TrainAcc: 0.7402, ValAcc: 0.7077, ES: 00/50 | BestVal=0.7077@E30\n",
      "Epoch: 40, Time: 0.0370, Loss: 1.0348, TrainAcc: 0.7733, ValAcc: 0.7148, ES: 00/50 | BestVal=0.7148@E40\n",
      "Epoch: 50, Time: 0.0349, Loss: 0.9364, TrainAcc: 0.7922, ValAcc: 0.7256, ES: 01/50 | BestVal=0.7256@E49\n",
      "Epoch: 60, Time: 0.0546, Loss: 0.8687, TrainAcc: 0.8106, ValAcc: 0.7279, ES: 00/50 | BestVal=0.7279@E60\n",
      "Epoch: 70, Time: 0.0735, Loss: 0.8212, TrainAcc: 0.8181, ValAcc: 0.7279, ES: 06/50 | BestVal=0.7290@E64\n",
      "Epoch: 80, Time: 0.0374, Loss: 0.7835, TrainAcc: 0.8227, ValAcc: 0.7301, ES: 00/50 | BestVal=0.7301@E80\n",
      "Epoch: 90, Time: 0.0339, Loss: 0.7571, TrainAcc: 0.8287, ValAcc: 0.7336, ES: 01/50 | BestVal=0.7340@E89\n",
      "Epoch: 100, Time: 0.0369, Loss: 0.7308, TrainAcc: 0.8317, ValAcc: 0.7369, ES: 00/50 | BestVal=0.7369@E100\n",
      "Epoch: 110, Time: 0.0369, Loss: 0.7081, TrainAcc: 0.8367, ValAcc: 0.7397, ES: 00/50 | BestVal=0.7397@E110\n",
      "Epoch: 120, Time: 0.0370, Loss: 0.6904, TrainAcc: 0.8403, ValAcc: 0.7404, ES: 00/50 | BestVal=0.7404@E120\n",
      "Epoch: 130, Time: 0.0352, Loss: 0.6692, TrainAcc: 0.8455, ValAcc: 0.7400, ES: 07/50 | BestVal=0.7405@E123\n",
      "Epoch: 140, Time: 0.0355, Loss: 0.6549, TrainAcc: 0.8492, ValAcc: 0.7409, ES: 01/50 | BestVal=0.7412@E139\n",
      "Epoch: 150, Time: 0.0352, Loss: 0.6388, TrainAcc: 0.8513, ValAcc: 0.7409, ES: 11/50 | BestVal=0.7412@E139\n",
      "Epoch: 160, Time: 0.0350, Loss: 0.6230, TrainAcc: 0.8552, ValAcc: 0.7418, ES: 04/50 | BestVal=0.7421@E156\n",
      "Epoch: 170, Time: 0.0350, Loss: 0.6091, TrainAcc: 0.8583, ValAcc: 0.7424, ES: 01/50 | BestVal=0.7424@E169\n",
      "Epoch: 180, Time: 0.0347, Loss: 0.5969, TrainAcc: 0.8599, ValAcc: 0.7423, ES: 03/50 | BestVal=0.7424@E177\n",
      "Epoch: 190, Time: 0.0350, Loss: 0.5905, TrainAcc: 0.8614, ValAcc: 0.7429, ES: 06/50 | BestVal=0.7434@E184\n",
      "Finished running train at 05-22 17:20:04, running time = 8.22s.\n",
      "[MLP + TA] ValAcc: 0.7434, TestAcc: 0.7244\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/ogbn-arxiv.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:20:06\n",
      "Epoch: 0, Time: 0.0504, Loss: 3.8633, TrainAcc: 0.0232, ValAcc: 0.0695, ES: 00/50 | BestVal=0.0695@E0\n",
      "Epoch: 10, Time: 0.0435, Loss: 2.2470, TrainAcc: 0.5030, ValAcc: 0.6120, ES: 00/50 | BestVal=0.6120@E10\n",
      "Epoch: 20, Time: 0.0425, Loss: 1.8612, TrainAcc: 0.5808, ValAcc: 0.6438, ES: 00/50 | BestVal=0.6438@E20\n",
      "Epoch: 30, Time: 0.0431, Loss: 1.6666, TrainAcc: 0.6076, ValAcc: 0.6776, ES: 00/50 | BestVal=0.6776@E30\n",
      "Epoch: 40, Time: 0.0431, Loss: 1.5231, TrainAcc: 0.6460, ValAcc: 0.7122, ES: 00/50 | BestVal=0.7122@E40\n",
      "Epoch: 50, Time: 0.0423, Loss: 1.4253, TrainAcc: 0.6649, ValAcc: 0.7189, ES: 00/50 | BestVal=0.7189@E50\n",
      "Epoch: 60, Time: 0.0478, Loss: 1.3637, TrainAcc: 0.6710, ValAcc: 0.7242, ES: 00/50 | BestVal=0.7242@E60\n",
      "Epoch: 70, Time: 0.0728, Loss: 1.3210, TrainAcc: 0.6770, ValAcc: 0.7256, ES: 00/50 | BestVal=0.7256@E70\n",
      "Epoch: 80, Time: 0.0579, Loss: 1.2875, TrainAcc: 0.6818, ValAcc: 0.7266, ES: 04/50 | BestVal=0.7266@E76\n",
      "Epoch: 90, Time: 0.0456, Loss: 1.2603, TrainAcc: 0.6849, ValAcc: 0.7282, ES: 00/50 | BestVal=0.7282@E90\n",
      "Epoch: 100, Time: 0.0440, Loss: 1.2366, TrainAcc: 0.6900, ValAcc: 0.7338, ES: 00/50 | BestVal=0.7338@E100\n",
      "Epoch: 110, Time: 0.0435, Loss: 1.2182, TrainAcc: 0.6914, ValAcc: 0.7391, ES: 00/50 | BestVal=0.7391@E110\n",
      "Epoch: 120, Time: 0.0428, Loss: 1.2021, TrainAcc: 0.6953, ValAcc: 0.7408, ES: 00/50 | BestVal=0.7408@E120\n",
      "Epoch: 130, Time: 0.0454, Loss: 1.1813, TrainAcc: 0.6989, ValAcc: 0.7427, ES: 00/50 | BestVal=0.7427@E130\n",
      "Epoch: 140, Time: 0.0417, Loss: 1.1715, TrainAcc: 0.6993, ValAcc: 0.7426, ES: 09/50 | BestVal=0.7430@E131\n",
      "Epoch: 150, Time: 0.0424, Loss: 1.1560, TrainAcc: 0.7010, ValAcc: 0.7423, ES: 06/50 | BestVal=0.7433@E144\n",
      "Epoch: 160, Time: 0.0413, Loss: 1.1457, TrainAcc: 0.7035, ValAcc: 0.7428, ES: 16/50 | BestVal=0.7433@E144\n",
      "Epoch: 170, Time: 0.0413, Loss: 1.1412, TrainAcc: 0.7047, ValAcc: 0.7430, ES: 06/50 | BestVal=0.7433@E164\n",
      "Epoch: 180, Time: 0.0411, Loss: 1.1321, TrainAcc: 0.7049, ValAcc: 0.7440, ES: 02/50 | BestVal=0.7441@E178\n",
      "Epoch: 190, Time: 0.0417, Loss: 1.1273, TrainAcc: 0.7054, ValAcc: 0.7446, ES: 01/50 | BestVal=0.7449@E189\n",
      "Finished running train at 05-22 17:20:15, running time = 9.18s.\n",
      "[MLP + P] ValAcc: 0.7451, TestAcc: 0.7400\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:20:16\n",
      "Epoch: 0, Time: 0.0369, Loss: 3.9017, TrainAcc: 0.0198, ValAcc: 0.1793, ES: 00/50 | BestVal=0.1793@E0\n",
      "Epoch: 10, Time: 0.0384, Loss: 2.0251, TrainAcc: 0.5637, ValAcc: 0.6689, ES: 00/50 | BestVal=0.6689@E10\n",
      "Epoch: 20, Time: 0.0416, Loss: 1.6035, TrainAcc: 0.6310, ValAcc: 0.6989, ES: 00/50 | BestVal=0.6989@E20\n",
      "Epoch: 30, Time: 0.0373, Loss: 1.3822, TrainAcc: 0.6810, ValAcc: 0.7088, ES: 00/50 | BestVal=0.7088@E30\n",
      "Epoch: 40, Time: 0.0374, Loss: 1.2468, TrainAcc: 0.7079, ValAcc: 0.7162, ES: 00/50 | BestVal=0.7162@E40\n",
      "Epoch: 50, Time: 0.0373, Loss: 1.1592, TrainAcc: 0.7262, ValAcc: 0.7236, ES: 00/50 | BestVal=0.7236@E50\n",
      "Epoch: 60, Time: 0.0370, Loss: 1.0969, TrainAcc: 0.7370, ValAcc: 0.7273, ES: 00/50 | BestVal=0.7273@E60\n",
      "Epoch: 70, Time: 0.0374, Loss: 1.0498, TrainAcc: 0.7452, ValAcc: 0.7298, ES: 00/50 | BestVal=0.7298@E70\n",
      "Epoch: 80, Time: 0.0375, Loss: 1.0148, TrainAcc: 0.7506, ValAcc: 0.7335, ES: 00/50 | BestVal=0.7335@E80\n",
      "Epoch: 90, Time: 0.0368, Loss: 0.9893, TrainAcc: 0.7569, ValAcc: 0.7352, ES: 00/50 | BestVal=0.7352@E90\n",
      "Epoch: 100, Time: 0.0359, Loss: 0.9645, TrainAcc: 0.7632, ValAcc: 0.7362, ES: 06/50 | BestVal=0.7364@E94\n",
      "Epoch: 110, Time: 0.0372, Loss: 0.9430, TrainAcc: 0.7661, ValAcc: 0.7371, ES: 03/50 | BestVal=0.7373@E107\n",
      "Epoch: 120, Time: 0.0353, Loss: 0.9269, TrainAcc: 0.7686, ValAcc: 0.7373, ES: 01/50 | BestVal=0.7379@E119\n",
      "Epoch: 130, Time: 0.0370, Loss: 0.9080, TrainAcc: 0.7707, ValAcc: 0.7398, ES: 00/50 | BestVal=0.7398@E130\n",
      "Epoch: 140, Time: 0.0359, Loss: 0.8918, TrainAcc: 0.7763, ValAcc: 0.7400, ES: 08/50 | BestVal=0.7402@E132\n",
      "Epoch: 150, Time: 0.0355, Loss: 0.8812, TrainAcc: 0.7783, ValAcc: 0.7398, ES: 01/50 | BestVal=0.7403@E149\n",
      "Epoch: 160, Time: 0.0364, Loss: 0.8668, TrainAcc: 0.7807, ValAcc: 0.7393, ES: 11/50 | BestVal=0.7403@E149\n",
      "Epoch: 170, Time: 0.0365, Loss: 0.8477, TrainAcc: 0.7852, ValAcc: 0.7392, ES: 02/50 | BestVal=0.7408@E168\n",
      "Epoch: 180, Time: 0.0361, Loss: 0.8383, TrainAcc: 0.7861, ValAcc: 0.7399, ES: 12/50 | BestVal=0.7408@E168\n",
      "Epoch: 190, Time: 0.0355, Loss: 0.8290, TrainAcc: 0.7871, ValAcc: 0.7397, ES: 22/50 | BestVal=0.7408@E168\n",
      "Finished running train at 05-22 17:20:24, running time = 7.76s.\n",
      "[MLP + E] ValAcc: 0.7408, TestAcc: 0.7275\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7657, TestAcc: 0.7555\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:20:25\n",
      "Epoch: 0, Time: 0.0382, Loss: 3.8218, TrainAcc: 0.0257, ValAcc: 0.1329, ES: 00/50 | BestVal=0.1329@E0\n",
      "Epoch: 10, Time: 0.0376, Loss: 1.9144, TrainAcc: 0.6262, ValAcc: 0.6577, ES: 00/50 | BestVal=0.6577@E10\n",
      "Epoch: 20, Time: 0.0370, Loss: 1.4154, TrainAcc: 0.6938, ValAcc: 0.6890, ES: 00/50 | BestVal=0.6890@E20\n",
      "Epoch: 30, Time: 0.0375, Loss: 1.1763, TrainAcc: 0.7414, ValAcc: 0.7050, ES: 00/50 | BestVal=0.7050@E30\n",
      "Epoch: 40, Time: 0.0368, Loss: 1.0318, TrainAcc: 0.7753, ValAcc: 0.7204, ES: 00/50 | BestVal=0.7204@E40\n",
      "Epoch: 50, Time: 0.0370, Loss: 0.9363, TrainAcc: 0.7977, ValAcc: 0.7228, ES: 00/50 | BestVal=0.7228@E50\n",
      "Epoch: 60, Time: 0.0351, Loss: 0.8680, TrainAcc: 0.8108, ValAcc: 0.7240, ES: 03/50 | BestVal=0.7242@E57\n",
      "Epoch: 70, Time: 0.0369, Loss: 0.8281, TrainAcc: 0.8167, ValAcc: 0.7257, ES: 00/50 | BestVal=0.7257@E70\n",
      "Epoch: 80, Time: 0.0372, Loss: 0.7948, TrainAcc: 0.8216, ValAcc: 0.7277, ES: 00/50 | BestVal=0.7277@E80\n",
      "Epoch: 90, Time: 0.0379, Loss: 0.7661, TrainAcc: 0.8267, ValAcc: 0.7319, ES: 00/50 | BestVal=0.7319@E90\n",
      "Epoch: 100, Time: 0.0356, Loss: 0.7371, TrainAcc: 0.8316, ValAcc: 0.7372, ES: 02/50 | BestVal=0.7372@E98\n",
      "Epoch: 110, Time: 0.0373, Loss: 0.7186, TrainAcc: 0.8364, ValAcc: 0.7391, ES: 00/50 | BestVal=0.7391@E110\n",
      "Epoch: 120, Time: 0.0355, Loss: 0.6947, TrainAcc: 0.8410, ValAcc: 0.7388, ES: 03/50 | BestVal=0.7392@E117\n",
      "Epoch: 130, Time: 0.0352, Loss: 0.6809, TrainAcc: 0.8451, ValAcc: 0.7397, ES: 02/50 | BestVal=0.7399@E128\n",
      "Epoch: 140, Time: 0.0370, Loss: 0.6605, TrainAcc: 0.8471, ValAcc: 0.7408, ES: 00/50 | BestVal=0.7408@E140\n",
      "Epoch: 150, Time: 0.0353, Loss: 0.6463, TrainAcc: 0.8496, ValAcc: 0.7407, ES: 09/50 | BestVal=0.7408@E141\n",
      "Epoch: 160, Time: 0.1642, Loss: 0.6345, TrainAcc: 0.8524, ValAcc: 0.7410, ES: 01/50 | BestVal=0.7412@E159\n",
      "Epoch: 170, Time: 0.0352, Loss: 0.6252, TrainAcc: 0.8548, ValAcc: 0.7409, ES: 09/50 | BestVal=0.7414@E161\n",
      "Epoch: 180, Time: 0.0346, Loss: 0.6156, TrainAcc: 0.8565, ValAcc: 0.7409, ES: 19/50 | BestVal=0.7414@E161\n",
      "Epoch: 190, Time: 0.0353, Loss: 0.6088, TrainAcc: 0.8576, ValAcc: 0.7407, ES: 29/50 | BestVal=0.7414@E161\n",
      "Finished running train at 05-22 17:20:33, running time = 7.80s.\n",
      "[MLP + TA] ValAcc: 0.7414, TestAcc: 0.7273\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/ogbn-arxiv.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:20:35\n",
      "Epoch: 0, Time: 0.0497, Loss: 3.9635, TrainAcc: 0.0192, ValAcc: 0.0220, ES: 00/50 | BestVal=0.0220@E0\n",
      "Epoch: 10, Time: 0.0433, Loss: 2.2854, TrainAcc: 0.5135, ValAcc: 0.6070, ES: 00/50 | BestVal=0.6070@E10\n",
      "Epoch: 20, Time: 0.0435, Loss: 1.8680, TrainAcc: 0.5776, ValAcc: 0.6453, ES: 00/50 | BestVal=0.6453@E20\n",
      "Epoch: 30, Time: 0.0432, Loss: 1.6655, TrainAcc: 0.6109, ValAcc: 0.6921, ES: 00/50 | BestVal=0.6921@E30\n",
      "Epoch: 40, Time: 0.0425, Loss: 1.5224, TrainAcc: 0.6457, ValAcc: 0.7065, ES: 00/50 | BestVal=0.7065@E40\n",
      "Epoch: 50, Time: 0.0460, Loss: 1.4305, TrainAcc: 0.6624, ValAcc: 0.7150, ES: 00/50 | BestVal=0.7150@E50\n",
      "Epoch: 60, Time: 0.0448, Loss: 1.3558, TrainAcc: 0.6720, ValAcc: 0.7223, ES: 00/50 | BestVal=0.7223@E60\n",
      "Epoch: 70, Time: 0.0422, Loss: 1.3102, TrainAcc: 0.6747, ValAcc: 0.7282, ES: 00/50 | BestVal=0.7282@E70\n",
      "Epoch: 80, Time: 0.0415, Loss: 1.2836, TrainAcc: 0.6807, ValAcc: 0.7298, ES: 01/50 | BestVal=0.7298@E79\n",
      "Epoch: 90, Time: 0.0430, Loss: 1.2514, TrainAcc: 0.6864, ValAcc: 0.7314, ES: 00/50 | BestVal=0.7314@E90\n",
      "Epoch: 100, Time: 0.0438, Loss: 1.2285, TrainAcc: 0.6906, ValAcc: 0.7344, ES: 00/50 | BestVal=0.7344@E100\n",
      "Epoch: 110, Time: 0.0421, Loss: 1.2105, TrainAcc: 0.6919, ValAcc: 0.7393, ES: 00/50 | BestVal=0.7393@E110\n",
      "Epoch: 120, Time: 0.0412, Loss: 1.1963, TrainAcc: 0.6947, ValAcc: 0.7414, ES: 03/50 | BestVal=0.7419@E117\n",
      "Epoch: 130, Time: 0.0424, Loss: 1.1789, TrainAcc: 0.6975, ValAcc: 0.7428, ES: 00/50 | BestVal=0.7428@E130\n",
      "Epoch: 140, Time: 0.0415, Loss: 1.1665, TrainAcc: 0.7005, ValAcc: 0.7424, ES: 09/50 | BestVal=0.7431@E131\n",
      "Epoch: 150, Time: 0.0956, Loss: 1.1618, TrainAcc: 0.7009, ValAcc: 0.7425, ES: 19/50 | BestVal=0.7431@E131\n",
      "Epoch: 160, Time: 0.0671, Loss: 1.1456, TrainAcc: 0.7025, ValAcc: 0.7427, ES: 02/50 | BestVal=0.7432@E158\n",
      "Epoch: 170, Time: 0.0412, Loss: 1.1418, TrainAcc: 0.7027, ValAcc: 0.7431, ES: 03/50 | BestVal=0.7436@E167\n",
      "Epoch: 180, Time: 0.0408, Loss: 1.1283, TrainAcc: 0.7054, ValAcc: 0.7434, ES: 01/50 | BestVal=0.7437@E179\n",
      "Epoch: 190, Time: 0.0414, Loss: 1.1229, TrainAcc: 0.7056, ValAcc: 0.7435, ES: 11/50 | BestVal=0.7437@E179\n",
      "Finished running train at 05-22 17:20:44, running time = 9.05s.\n",
      "[MLP + P] ValAcc: 0.7449, TestAcc: 0.7388\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed1.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:20:45\n",
      "Epoch: 0, Time: 0.0367, Loss: 3.8883, TrainAcc: 0.0197, ValAcc: 0.1952, ES: 00/50 | BestVal=0.1952@E0\n",
      "Epoch: 10, Time: 0.0369, Loss: 2.0283, TrainAcc: 0.5760, ValAcc: 0.6504, ES: 00/50 | BestVal=0.6504@E10\n",
      "Epoch: 20, Time: 0.0371, Loss: 1.6185, TrainAcc: 0.6280, ValAcc: 0.6617, ES: 00/50 | BestVal=0.6617@E20\n",
      "Epoch: 30, Time: 0.0368, Loss: 1.4109, TrainAcc: 0.6660, ValAcc: 0.7048, ES: 00/50 | BestVal=0.7048@E30\n",
      "Epoch: 40, Time: 0.0370, Loss: 1.2761, TrainAcc: 0.6991, ValAcc: 0.7188, ES: 00/50 | BestVal=0.7188@E40\n",
      "Epoch: 50, Time: 0.0367, Loss: 1.1888, TrainAcc: 0.7179, ValAcc: 0.7272, ES: 00/50 | BestVal=0.7272@E50\n",
      "Epoch: 60, Time: 0.0353, Loss: 1.1411, TrainAcc: 0.7242, ValAcc: 0.7279, ES: 06/50 | BestVal=0.7282@E54\n",
      "Epoch: 70, Time: 0.0352, Loss: 1.0955, TrainAcc: 0.7306, ValAcc: 0.7272, ES: 09/50 | BestVal=0.7285@E61\n",
      "Epoch: 80, Time: 0.0363, Loss: 1.0677, TrainAcc: 0.7362, ValAcc: 0.7280, ES: 19/50 | BestVal=0.7285@E61\n",
      "Epoch: 90, Time: 0.0376, Loss: 1.0410, TrainAcc: 0.7399, ValAcc: 0.7303, ES: 00/50 | BestVal=0.7303@E90\n",
      "Epoch: 100, Time: 0.0375, Loss: 1.0205, TrainAcc: 0.7455, ValAcc: 0.7391, ES: 00/50 | BestVal=0.7391@E100\n",
      "Epoch: 110, Time: 0.0376, Loss: 0.9977, TrainAcc: 0.7485, ValAcc: 0.7416, ES: 00/50 | BestVal=0.7416@E110\n",
      "Epoch: 120, Time: 0.0375, Loss: 0.9770, TrainAcc: 0.7536, ValAcc: 0.7429, ES: 00/50 | BestVal=0.7429@E120\n",
      "Epoch: 130, Time: 0.0356, Loss: 0.9643, TrainAcc: 0.7557, ValAcc: 0.7437, ES: 02/50 | BestVal=0.7440@E128\n",
      "Epoch: 140, Time: 0.0346, Loss: 0.9507, TrainAcc: 0.7564, ValAcc: 0.7442, ES: 05/50 | BestVal=0.7445@E135\n",
      "Epoch: 150, Time: 0.0355, Loss: 0.9387, TrainAcc: 0.7596, ValAcc: 0.7443, ES: 04/50 | BestVal=0.7450@E146\n",
      "Epoch: 160, Time: 0.0356, Loss: 0.9276, TrainAcc: 0.7615, ValAcc: 0.7441, ES: 14/50 | BestVal=0.7450@E146\n",
      "Epoch: 170, Time: 0.0368, Loss: 0.9160, TrainAcc: 0.7653, ValAcc: 0.7455, ES: 00/50 | BestVal=0.7455@E170\n",
      "Epoch: 180, Time: 0.0351, Loss: 0.9055, TrainAcc: 0.7677, ValAcc: 0.7435, ES: 09/50 | BestVal=0.7455@E171\n",
      "Epoch: 190, Time: 0.0350, Loss: 0.8995, TrainAcc: 0.7682, ValAcc: 0.7446, ES: 19/50 | BestVal=0.7455@E171\n",
      "Finished running train at 05-22 17:20:52, running time = 7.27s.\n",
      "[MLP + E] ValAcc: 0.7455, TestAcc: 0.7322\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7641, TestAcc: 0.7574\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:20:55\n",
      "Epoch: 0, Time: 0.0372, Loss: 3.9654, TrainAcc: 0.0163, ValAcc: 0.2500, ES: 00/50 | BestVal=0.2500@E0\n",
      "Epoch: 10, Time: 0.0369, Loss: 1.9327, TrainAcc: 0.6137, ValAcc: 0.6701, ES: 00/50 | BestVal=0.6701@E10\n",
      "Epoch: 20, Time: 0.0372, Loss: 1.4686, TrainAcc: 0.6770, ValAcc: 0.6922, ES: 00/50 | BestVal=0.6922@E20\n",
      "Epoch: 30, Time: 0.0381, Loss: 1.2152, TrainAcc: 0.7342, ValAcc: 0.7067, ES: 00/50 | BestVal=0.7067@E30\n",
      "Epoch: 40, Time: 0.0374, Loss: 1.0427, TrainAcc: 0.7736, ValAcc: 0.7197, ES: 00/50 | BestVal=0.7197@E40\n",
      "Epoch: 50, Time: 0.0378, Loss: 0.9334, TrainAcc: 0.8008, ValAcc: 0.7235, ES: 00/50 | BestVal=0.7235@E50\n",
      "Epoch: 60, Time: 0.0371, Loss: 0.8721, TrainAcc: 0.8093, ValAcc: 0.7248, ES: 00/50 | BestVal=0.7248@E60\n",
      "Epoch: 70, Time: 0.0369, Loss: 0.8213, TrainAcc: 0.8171, ValAcc: 0.7266, ES: 00/50 | BestVal=0.7266@E70\n",
      "Epoch: 80, Time: 0.0369, Loss: 0.7873, TrainAcc: 0.8234, ValAcc: 0.7313, ES: 00/50 | BestVal=0.7313@E80\n",
      "Epoch: 90, Time: 0.0368, Loss: 0.7581, TrainAcc: 0.8284, ValAcc: 0.7367, ES: 00/50 | BestVal=0.7367@E90\n",
      "Epoch: 100, Time: 0.0369, Loss: 0.7256, TrainAcc: 0.8348, ValAcc: 0.7394, ES: 00/50 | BestVal=0.7394@E100\n",
      "Epoch: 110, Time: 0.0372, Loss: 0.7082, TrainAcc: 0.8388, ValAcc: 0.7412, ES: 00/50 | BestVal=0.7412@E110\n",
      "Epoch: 120, Time: 0.0350, Loss: 0.6862, TrainAcc: 0.8426, ValAcc: 0.7416, ES: 01/50 | BestVal=0.7417@E119\n",
      "Epoch: 130, Time: 0.0367, Loss: 0.6658, TrainAcc: 0.8476, ValAcc: 0.7410, ES: 11/50 | BestVal=0.7417@E119\n",
      "Epoch: 140, Time: 0.0346, Loss: 0.6508, TrainAcc: 0.8497, ValAcc: 0.7415, ES: 02/50 | BestVal=0.7421@E138\n",
      "Epoch: 150, Time: 0.0370, Loss: 0.6345, TrainAcc: 0.8533, ValAcc: 0.7425, ES: 00/50 | BestVal=0.7425@E150\n",
      "Epoch: 160, Time: 0.0350, Loss: 0.6227, TrainAcc: 0.8540, ValAcc: 0.7428, ES: 03/50 | BestVal=0.7431@E157\n",
      "Epoch: 170, Time: 0.0368, Loss: 0.6059, TrainAcc: 0.8573, ValAcc: 0.7432, ES: 00/50 | BestVal=0.7432@E170\n",
      "Epoch: 180, Time: 0.0353, Loss: 0.6003, TrainAcc: 0.8590, ValAcc: 0.7435, ES: 03/50 | BestVal=0.7435@E177\n",
      "Epoch: 190, Time: 0.0356, Loss: 0.5903, TrainAcc: 0.8612, ValAcc: 0.7424, ES: 03/50 | BestVal=0.7440@E187\n",
      "Finished running train at 05-22 17:21:02, running time = 7.27s.\n",
      "[MLP + TA] ValAcc: 0.7440, TestAcc: 0.7277\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/ogbn-arxiv.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:21:05\n",
      "Epoch: 0, Time: 0.0433, Loss: 3.9197, TrainAcc: 0.0167, ValAcc: 0.1351, ES: 00/50 | BestVal=0.1351@E0\n",
      "Epoch: 10, Time: 0.0447, Loss: 2.2804, TrainAcc: 0.4934, ValAcc: 0.5962, ES: 00/50 | BestVal=0.5962@E10\n",
      "Epoch: 20, Time: 0.0445, Loss: 1.8900, TrainAcc: 0.5663, ValAcc: 0.6381, ES: 00/50 | BestVal=0.6381@E20\n",
      "Epoch: 30, Time: 0.0442, Loss: 1.6735, TrainAcc: 0.6100, ValAcc: 0.6913, ES: 00/50 | BestVal=0.6913@E30\n",
      "Epoch: 40, Time: 0.0445, Loss: 1.5334, TrainAcc: 0.6426, ValAcc: 0.7103, ES: 00/50 | BestVal=0.7103@E40\n",
      "Epoch: 50, Time: 0.0562, Loss: 1.4310, TrainAcc: 0.6617, ValAcc: 0.7199, ES: 00/50 | BestVal=0.7199@E50\n",
      "Epoch: 60, Time: 0.0429, Loss: 1.3705, TrainAcc: 0.6690, ValAcc: 0.7224, ES: 00/50 | BestVal=0.7224@E60\n",
      "Epoch: 70, Time: 0.0422, Loss: 1.3280, TrainAcc: 0.6748, ValAcc: 0.7250, ES: 00/50 | BestVal=0.7250@E70\n",
      "Epoch: 80, Time: 0.0413, Loss: 1.2909, TrainAcc: 0.6800, ValAcc: 0.7291, ES: 01/50 | BestVal=0.7295@E79\n",
      "Epoch: 90, Time: 0.0426, Loss: 1.2610, TrainAcc: 0.6844, ValAcc: 0.7308, ES: 00/50 | BestVal=0.7308@E90\n",
      "Epoch: 100, Time: 0.0431, Loss: 1.2378, TrainAcc: 0.6893, ValAcc: 0.7352, ES: 00/50 | BestVal=0.7352@E100\n",
      "Epoch: 110, Time: 0.0439, Loss: 1.2171, TrainAcc: 0.6920, ValAcc: 0.7410, ES: 00/50 | BestVal=0.7410@E110\n",
      "Epoch: 120, Time: 0.0414, Loss: 1.2043, TrainAcc: 0.6937, ValAcc: 0.7419, ES: 04/50 | BestVal=0.7421@E116\n",
      "Epoch: 130, Time: 0.0428, Loss: 1.1844, TrainAcc: 0.6983, ValAcc: 0.7426, ES: 00/50 | BestVal=0.7426@E130\n",
      "Epoch: 140, Time: 0.0414, Loss: 1.1759, TrainAcc: 0.6995, ValAcc: 0.7425, ES: 08/50 | BestVal=0.7426@E132\n",
      "Epoch: 150, Time: 0.0429, Loss: 1.1616, TrainAcc: 0.7007, ValAcc: 0.7437, ES: 00/50 | BestVal=0.7437@E150\n",
      "Epoch: 160, Time: 0.0406, Loss: 1.1503, TrainAcc: 0.7035, ValAcc: 0.7429, ES: 10/50 | BestVal=0.7437@E150\n",
      "Epoch: 170, Time: 0.0503, Loss: 1.1446, TrainAcc: 0.7027, ValAcc: 0.7438, ES: 00/50 | BestVal=0.7438@E170\n",
      "Epoch: 180, Time: 0.0408, Loss: 1.1382, TrainAcc: 0.7027, ValAcc: 0.7439, ES: 08/50 | BestVal=0.7442@E172\n",
      "Epoch: 190, Time: 0.0423, Loss: 1.1291, TrainAcc: 0.7054, ValAcc: 0.7436, ES: 05/50 | BestVal=0.7444@E185\n",
      "Finished running train at 05-22 17:21:14, running time = 8.61s.\n",
      "[MLP + P] ValAcc: 0.7444, TestAcc: 0.7394\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed2.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:21:14\n",
      "Epoch: 0, Time: 0.0788, Loss: 3.8318, TrainAcc: 0.0353, ValAcc: 0.0862, ES: 00/50 | BestVal=0.0862@E0\n",
      "Epoch: 10, Time: 0.0518, Loss: 2.0567, TrainAcc: 0.5439, ValAcc: 0.6300, ES: 00/50 | BestVal=0.6300@E10\n",
      "Epoch: 20, Time: 0.0381, Loss: 1.6339, TrainAcc: 0.6222, ValAcc: 0.6844, ES: 00/50 | BestVal=0.6844@E20\n",
      "Epoch: 30, Time: 0.0382, Loss: 1.4221, TrainAcc: 0.6706, ValAcc: 0.7050, ES: 00/50 | BestVal=0.7050@E30\n",
      "Epoch: 40, Time: 0.0371, Loss: 1.2839, TrainAcc: 0.6971, ValAcc: 0.7126, ES: 00/50 | BestVal=0.7126@E40\n",
      "Epoch: 50, Time: 0.0376, Loss: 1.2052, TrainAcc: 0.7139, ValAcc: 0.7225, ES: 00/50 | BestVal=0.7225@E50\n",
      "Epoch: 60, Time: 0.0372, Loss: 1.1452, TrainAcc: 0.7268, ValAcc: 0.7264, ES: 00/50 | BestVal=0.7264@E60\n",
      "Epoch: 70, Time: 0.0356, Loss: 1.1006, TrainAcc: 0.7342, ValAcc: 0.7265, ES: 05/50 | BestVal=0.7274@E65\n",
      "Epoch: 80, Time: 0.0349, Loss: 1.0627, TrainAcc: 0.7387, ValAcc: 0.7274, ES: 03/50 | BestVal=0.7278@E77\n",
      "Epoch: 90, Time: 0.0354, Loss: 1.0306, TrainAcc: 0.7449, ValAcc: 0.7277, ES: 13/50 | BestVal=0.7278@E77\n",
      "Epoch: 100, Time: 0.0373, Loss: 1.0157, TrainAcc: 0.7482, ValAcc: 0.7346, ES: 00/50 | BestVal=0.7346@E100\n",
      "Epoch: 110, Time: 0.0371, Loss: 0.9894, TrainAcc: 0.7527, ValAcc: 0.7359, ES: 00/50 | BestVal=0.7359@E110\n",
      "Epoch: 120, Time: 0.0353, Loss: 0.9718, TrainAcc: 0.7556, ValAcc: 0.7369, ES: 01/50 | BestVal=0.7371@E119\n",
      "Epoch: 130, Time: 0.0353, Loss: 0.9532, TrainAcc: 0.7599, ValAcc: 0.7387, ES: 05/50 | BestVal=0.7389@E125\n",
      "Epoch: 140, Time: 0.0347, Loss: 0.9398, TrainAcc: 0.7619, ValAcc: 0.7396, ES: 04/50 | BestVal=0.7399@E136\n",
      "Epoch: 150, Time: 0.0348, Loss: 0.9270, TrainAcc: 0.7632, ValAcc: 0.7403, ES: 05/50 | BestVal=0.7406@E145\n",
      "Epoch: 160, Time: 0.0353, Loss: 0.9158, TrainAcc: 0.7679, ValAcc: 0.7401, ES: 07/50 | BestVal=0.7411@E153\n",
      "Epoch: 170, Time: 0.0358, Loss: 0.9056, TrainAcc: 0.7666, ValAcc: 0.7398, ES: 04/50 | BestVal=0.7415@E166\n",
      "Epoch: 180, Time: 0.0369, Loss: 0.8911, TrainAcc: 0.7715, ValAcc: 0.7416, ES: 00/50 | BestVal=0.7416@E180\n",
      "Epoch: 190, Time: 0.0401, Loss: 0.8858, TrainAcc: 0.7718, ValAcc: 0.7417, ES: 00/50 | BestVal=0.7417@E190\n",
      "Finished running train at 05-22 17:21:22, running time = 7.94s.\n",
      "[MLP + E] ValAcc: 0.7418, TestAcc: 0.7312\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7657, TestAcc: 0.7570\n",
      "\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:21:24\n",
      "Epoch: 0, Time: 0.0369, Loss: 3.9060, TrainAcc: 0.0164, ValAcc: 0.1429, ES: 00/50 | BestVal=0.1429@E0\n",
      "Epoch: 10, Time: 0.0350, Loss: 1.9119, TrainAcc: 0.6157, ValAcc: 0.6611, ES: 06/50 | BestVal=0.6619@E4\n",
      "Epoch: 20, Time: 0.0368, Loss: 1.4387, TrainAcc: 0.6834, ValAcc: 0.6899, ES: 00/50 | BestVal=0.6899@E20\n",
      "Epoch: 30, Time: 0.0369, Loss: 1.1949, TrainAcc: 0.7370, ValAcc: 0.7029, ES: 00/50 | BestVal=0.7029@E30\n",
      "Epoch: 40, Time: 0.0368, Loss: 1.0390, TrainAcc: 0.7686, ValAcc: 0.7137, ES: 00/50 | BestVal=0.7137@E40\n",
      "Epoch: 50, Time: 0.1015, Loss: 0.9409, TrainAcc: 0.7922, ValAcc: 0.7239, ES: 00/50 | BestVal=0.7239@E50\n",
      "Epoch: 60, Time: 0.0506, Loss: 0.8732, TrainAcc: 0.8053, ValAcc: 0.7250, ES: 01/50 | BestVal=0.7252@E59\n",
      "Epoch: 70, Time: 0.0385, Loss: 0.8248, TrainAcc: 0.8141, ValAcc: 0.7263, ES: 00/50 | BestVal=0.7263@E70\n",
      "Epoch: 80, Time: 0.0507, Loss: 0.7913, TrainAcc: 0.8196, ValAcc: 0.7279, ES: 00/50 | BestVal=0.7279@E80\n",
      "Epoch: 90, Time: 0.0369, Loss: 0.7621, TrainAcc: 0.8259, ValAcc: 0.7330, ES: 00/50 | BestVal=0.7330@E90\n",
      "Epoch: 100, Time: 0.0370, Loss: 0.7353, TrainAcc: 0.8313, ValAcc: 0.7361, ES: 00/50 | BestVal=0.7361@E100\n",
      "Epoch: 110, Time: 0.0349, Loss: 0.7146, TrainAcc: 0.8359, ValAcc: 0.7380, ES: 02/50 | BestVal=0.7382@E108\n",
      "Epoch: 120, Time: 0.0351, Loss: 0.6910, TrainAcc: 0.8400, ValAcc: 0.7378, ES: 04/50 | BestVal=0.7385@E116\n",
      "Epoch: 130, Time: 0.0351, Loss: 0.6719, TrainAcc: 0.8438, ValAcc: 0.7384, ES: 02/50 | BestVal=0.7390@E128\n",
      "Epoch: 140, Time: 0.0373, Loss: 0.6572, TrainAcc: 0.8473, ValAcc: 0.7390, ES: 00/50 | BestVal=0.7390@E140\n",
      "Epoch: 150, Time: 0.0352, Loss: 0.6412, TrainAcc: 0.8510, ValAcc: 0.7395, ES: 06/50 | BestVal=0.7404@E144\n",
      "Epoch: 160, Time: 0.0354, Loss: 0.6259, TrainAcc: 0.8540, ValAcc: 0.7399, ES: 03/50 | BestVal=0.7409@E157\n",
      "Epoch: 170, Time: 0.0368, Loss: 0.6189, TrainAcc: 0.8557, ValAcc: 0.7413, ES: 00/50 | BestVal=0.7413@E170\n",
      "Epoch: 180, Time: 0.0353, Loss: 0.6098, TrainAcc: 0.8585, ValAcc: 0.7405, ES: 10/50 | BestVal=0.7413@E170\n",
      "Epoch: 190, Time: 0.0355, Loss: 0.5928, TrainAcc: 0.8613, ValAcc: 0.7405, ES: 04/50 | BestVal=0.7415@E186\n",
      "Finished running train at 05-22 17:21:32, running time = 8.15s.\n",
      "[MLP + TA] ValAcc: 0.7415, TestAcc: 0.7265\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/ogbn-arxiv.csv\n",
      "\n",
      "Number of parameters: 126248\n",
      "Start running train at 05-22 17:21:34\n",
      "Epoch: 0, Time: 0.0497, Loss: 3.7306, TrainAcc: 0.0344, ValAcc: 0.2169, ES: 00/50 | BestVal=0.2169@E0\n",
      "Epoch: 10, Time: 0.0435, Loss: 2.1990, TrainAcc: 0.4997, ValAcc: 0.5935, ES: 00/50 | BestVal=0.5935@E10\n",
      "Epoch: 20, Time: 0.0420, Loss: 1.8496, TrainAcc: 0.5744, ValAcc: 0.6393, ES: 00/50 | BestVal=0.6393@E20\n",
      "Epoch: 30, Time: 0.0426, Loss: 1.6597, TrainAcc: 0.6064, ValAcc: 0.6801, ES: 00/50 | BestVal=0.6801@E30\n",
      "Epoch: 40, Time: 0.0433, Loss: 1.5184, TrainAcc: 0.6395, ValAcc: 0.7045, ES: 00/50 | BestVal=0.7045@E40\n",
      "Epoch: 50, Time: 0.1080, Loss: 1.4288, TrainAcc: 0.6588, ValAcc: 0.7119, ES: 00/50 | BestVal=0.7119@E50\n",
      "Epoch: 60, Time: 0.0626, Loss: 1.3629, TrainAcc: 0.6685, ValAcc: 0.7173, ES: 00/50 | BestVal=0.7173@E60\n",
      "Epoch: 70, Time: 0.0742, Loss: 1.3214, TrainAcc: 0.6739, ValAcc: 0.7239, ES: 00/50 | BestVal=0.7239@E70\n",
      "Epoch: 80, Time: 0.0459, Loss: 1.2893, TrainAcc: 0.6777, ValAcc: 0.7293, ES: 00/50 | BestVal=0.7293@E80\n",
      "Epoch: 90, Time: 0.0440, Loss: 1.2517, TrainAcc: 0.6841, ValAcc: 0.7348, ES: 00/50 | BestVal=0.7348@E90\n",
      "Epoch: 100, Time: 0.0440, Loss: 1.2312, TrainAcc: 0.6883, ValAcc: 0.7388, ES: 00/50 | BestVal=0.7388@E100\n",
      "Epoch: 110, Time: 0.0412, Loss: 1.2118, TrainAcc: 0.6920, ValAcc: 0.7405, ES: 01/50 | BestVal=0.7407@E109\n",
      "Epoch: 120, Time: 0.0427, Loss: 1.1944, TrainAcc: 0.6949, ValAcc: 0.7415, ES: 00/50 | BestVal=0.7415@E120\n",
      "Epoch: 130, Time: 0.0405, Loss: 1.1765, TrainAcc: 0.6982, ValAcc: 0.7420, ES: 05/50 | BestVal=0.7430@E125\n",
      "Epoch: 140, Time: 0.0411, Loss: 1.1625, TrainAcc: 0.7003, ValAcc: 0.7426, ES: 03/50 | BestVal=0.7432@E137\n",
      "Epoch: 150, Time: 0.0409, Loss: 1.1518, TrainAcc: 0.7021, ValAcc: 0.7428, ES: 13/50 | BestVal=0.7432@E137\n",
      "Epoch: 160, Time: 0.0425, Loss: 1.1463, TrainAcc: 0.7024, ValAcc: 0.7432, ES: 00/50 | BestVal=0.7432@E160\n",
      "Epoch: 170, Time: 0.0410, Loss: 1.1358, TrainAcc: 0.7027, ValAcc: 0.7433, ES: 05/50 | BestVal=0.7438@E165\n",
      "Epoch: 180, Time: 0.0401, Loss: 1.1303, TrainAcc: 0.7050, ValAcc: 0.7435, ES: 15/50 | BestVal=0.7438@E165\n",
      "Epoch: 190, Time: 0.0410, Loss: 1.1216, TrainAcc: 0.7042, ValAcc: 0.7433, ES: 04/50 | BestVal=0.7440@E186\n",
      "Finished running train at 05-22 17:21:43, running time = 9.20s.\n",
      "[MLP + P] ValAcc: 0.7443, TestAcc: 0.7392\n",
      "\n",
      "Loading pretrained LM features (explanations) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv2/microsoft/deberta-base-seed3.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:21:44\n",
      "Epoch: 0, Time: 0.0364, Loss: 3.7051, TrainAcc: 0.0481, ValAcc: 0.3205, ES: 00/50 | BestVal=0.3205@E0\n",
      "Epoch: 10, Time: 0.0371, Loss: 2.0153, TrainAcc: 0.5550, ValAcc: 0.6377, ES: 00/50 | BestVal=0.6377@E10\n",
      "Epoch: 20, Time: 0.0370, Loss: 1.6344, TrainAcc: 0.6239, ValAcc: 0.6651, ES: 00/50 | BestVal=0.6651@E20\n",
      "Epoch: 30, Time: 0.0371, Loss: 1.4318, TrainAcc: 0.6628, ValAcc: 0.7033, ES: 00/50 | BestVal=0.7033@E30\n",
      "Epoch: 40, Time: 0.0370, Loss: 1.2934, TrainAcc: 0.6975, ValAcc: 0.7198, ES: 00/50 | BestVal=0.7198@E40\n",
      "Epoch: 50, Time: 0.0371, Loss: 1.2036, TrainAcc: 0.7151, ValAcc: 0.7233, ES: 00/50 | BestVal=0.7233@E50\n",
      "Epoch: 60, Time: 0.0370, Loss: 1.1438, TrainAcc: 0.7250, ValAcc: 0.7265, ES: 00/50 | BestVal=0.7265@E60\n",
      "Epoch: 70, Time: 0.0350, Loss: 1.0984, TrainAcc: 0.7305, ValAcc: 0.7267, ES: 09/50 | BestVal=0.7268@E61\n",
      "Epoch: 80, Time: 0.0445, Loss: 1.0628, TrainAcc: 0.7366, ValAcc: 0.7285, ES: 00/50 | BestVal=0.7285@E80\n",
      "Epoch: 90, Time: 0.0371, Loss: 1.0332, TrainAcc: 0.7417, ValAcc: 0.7304, ES: 00/50 | BestVal=0.7304@E90\n",
      "Epoch: 100, Time: 0.0371, Loss: 1.0092, TrainAcc: 0.7474, ValAcc: 0.7360, ES: 00/50 | BestVal=0.7360@E100\n",
      "Epoch: 110, Time: 0.0374, Loss: 0.9844, TrainAcc: 0.7502, ValAcc: 0.7382, ES: 00/50 | BestVal=0.7382@E110\n",
      "Epoch: 120, Time: 0.0351, Loss: 0.9655, TrainAcc: 0.7537, ValAcc: 0.7397, ES: 01/50 | BestVal=0.7400@E119\n",
      "Epoch: 130, Time: 0.0353, Loss: 0.9530, TrainAcc: 0.7557, ValAcc: 0.7409, ES: 04/50 | BestVal=0.7415@E126\n",
      "Epoch: 140, Time: 0.0360, Loss: 0.9374, TrainAcc: 0.7600, ValAcc: 0.7421, ES: 06/50 | BestVal=0.7427@E134\n",
      "Epoch: 150, Time: 0.0352, Loss: 0.9216, TrainAcc: 0.7625, ValAcc: 0.7413, ES: 05/50 | BestVal=0.7428@E145\n",
      "Epoch: 160, Time: 0.0385, Loss: 0.9130, TrainAcc: 0.7641, ValAcc: 0.7424, ES: 03/50 | BestVal=0.7431@E157\n",
      "Epoch: 170, Time: 0.0371, Loss: 0.9026, TrainAcc: 0.7670, ValAcc: 0.7433, ES: 00/50 | BestVal=0.7433@E170\n",
      "Epoch: 180, Time: 0.0361, Loss: 0.8905, TrainAcc: 0.7682, ValAcc: 0.7431, ES: 09/50 | BestVal=0.7437@E171\n",
      "Epoch: 190, Time: 0.0351, Loss: 0.8794, TrainAcc: 0.7725, ValAcc: 0.7422, ES: 19/50 | BestVal=0.7437@E171\n",
      "Finished running train at 05-22 17:21:52, running time = 7.65s.\n",
      "[MLP + E] ValAcc: 0.7437, TestAcc: 0.7314\n",
      "\n",
      "(TA_P_E) ValAcc: 0.7613, TestAcc: 0.7561\n",
      "\n",
      "[TA] ValACC: 0.7426 ± 0.0013, TestAcc: 0.7265 ± 0.0015\n",
      "[P] ValACC: 0.7446 ± 0.0004, TestAcc: 0.7393 ± 0.0005\n",
      "[E] ValACC: 0.7429 ± 0.0021, TestAcc: 0.7306 ± 0.0021\n",
      "[ensemble] ValACC: 0.7642 ± 0.0021, TestAcc: 0.7565 ± 0.0009\n",
      "Running time: 29.63s\n",
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 137384\n",
      "Start running train at 05-22 17:21:55\n",
      "Epoch: 0, Time: 0.4381, Loss: 4.0625, TrainAcc: 0.0084, ValAcc: 0.5345, ES: 00/50 | BestVal=0.5345@E0\n",
      "Epoch: 10, Time: 0.0765, Loss: 1.0636, TrainAcc: 0.7391, ValAcc: 0.7048, ES: 00/50 | BestVal=0.7048@E10\n",
      "Epoch: 20, Time: 0.0762, Loss: 0.9212, TrainAcc: 0.7545, ValAcc: 0.7180, ES: 00/50 | BestVal=0.7180@E20\n",
      "Epoch: 30, Time: 0.1546, Loss: 0.8451, TrainAcc: 0.7625, ValAcc: 0.7304, ES: 00/50 | BestVal=0.7304@E30\n",
      "Epoch: 40, Time: 0.0794, Loss: 0.7953, TrainAcc: 0.7683, ValAcc: 0.7331, ES: 00/50 | BestVal=0.7331@E40\n",
      "Epoch: 50, Time: 0.0757, Loss: 0.7579, TrainAcc: 0.7739, ValAcc: 0.7372, ES: 00/50 | BestVal=0.7372@E50\n",
      "Epoch: 60, Time: 0.0788, Loss: 0.7488, TrainAcc: 0.7772, ValAcc: 0.7403, ES: 00/50 | BestVal=0.7403@E60\n",
      "Epoch: 70, Time: 0.0761, Loss: 0.7118, TrainAcc: 0.7818, ValAcc: 0.7443, ES: 01/50 | BestVal=0.7449@E69\n",
      "Epoch: 80, Time: 0.0765, Loss: 0.6890, TrainAcc: 0.7859, ValAcc: 0.7464, ES: 00/50 | BestVal=0.7464@E80\n",
      "Epoch: 90, Time: 0.0743, Loss: 0.6705, TrainAcc: 0.7893, ValAcc: 0.7470, ES: 01/50 | BestVal=0.7472@E89\n",
      "Epoch: 100, Time: 0.0743, Loss: 0.6569, TrainAcc: 0.7920, ValAcc: 0.7466, ES: 01/50 | BestVal=0.7475@E99\n",
      "Epoch: 110, Time: 0.0736, Loss: 0.6474, TrainAcc: 0.7934, ValAcc: 0.7486, ES: 02/50 | BestVal=0.7495@E108\n",
      "Epoch: 120, Time: 0.0736, Loss: 0.6328, TrainAcc: 0.7964, ValAcc: 0.7462, ES: 03/50 | BestVal=0.7508@E117\n",
      "Epoch: 130, Time: 0.0735, Loss: 0.6301, TrainAcc: 0.7968, ValAcc: 0.7478, ES: 06/50 | BestVal=0.7517@E124\n",
      "Epoch: 140, Time: 0.0738, Loss: 0.6112, TrainAcc: 0.8017, ValAcc: 0.7506, ES: 16/50 | BestVal=0.7517@E124\n",
      "Epoch: 150, Time: 0.0728, Loss: 0.6232, TrainAcc: 0.8005, ValAcc: 0.7494, ES: 26/50 | BestVal=0.7517@E124\n",
      "Epoch: 160, Time: 0.1927, Loss: 0.5973, TrainAcc: 0.8055, ValAcc: 0.7494, ES: 36/50 | BestVal=0.7517@E124\n",
      "Epoch: 170, Time: 0.0740, Loss: 0.5811, TrainAcc: 0.8086, ValAcc: 0.7358, ES: 02/50 | BestVal=0.7524@E168\n",
      "Epoch: 180, Time: 0.0744, Loss: 0.5832, TrainAcc: 0.8089, ValAcc: 0.7516, ES: 12/50 | BestVal=0.7524@E168\n",
      "Epoch: 190, Time: 0.0738, Loss: 0.5650, TrainAcc: 0.8125, ValAcc: 0.7520, ES: 01/50 | BestVal=0.7540@E189\n",
      "Finished running train at 05-22 17:22:12, running time = 16.45s.\n",
      "[GCN + TA] ValAcc: 0.7543, TestAcc: 0.7422\n",
      "\n",
      "Loading top-k prediction features ...\n",
      "Loading topk preds from gpt_preds/ogbn-arxiv.csv\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainEnsemble.py\", line 49, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainEnsemble.py\", line 19, in run\n",
      "    pred, acc = ensembler.train()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/GNNs/ensemble_trainer.py\", line 71, in train\n",
      "    trainer = self.TRAINER(self.cfg, feature_type)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/GNNs/gnn_trainer.py\", line 62, in __init__\n",
      "    features = load_gpt_preds(self.dataset_name, topk)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/data_utils/load.py\", line 22, in load_gpt_preds\n",
      "    pl[i][:len(pred)] = torch.tensor(pred[:topk], dtype=torch.long)+1\n",
      "KeyboardInterrupt\n",
      "An import exception occurred\n",
      "Loading pretrained LM features (title and abstract) ...\n",
      "LM_emb_path: prt_lm/ogbn-arxiv/microsoft/deberta-base-seed0.emb\n",
      "\n",
      "Number of parameters: 273576\n",
      "Start running train at 05-22 17:22:17\n",
      "Epoch: 0, Time: 0.4572, Loss: 3.8674, TrainAcc: 0.0066, ValAcc: 0.2244, ES: 00/50 | BestVal=0.2244@E0\n",
      "Epoch: 10, Time: 0.1198, Loss: 1.0021, TrainAcc: 0.7447, ValAcc: 0.6941, ES: 00/50 | BestVal=0.6941@E10\n",
      "Epoch: 20, Time: 0.1947, Loss: 0.7885, TrainAcc: 0.7846, ValAcc: 0.7243, ES: 00/50 | BestVal=0.7243@E20\n",
      "Epoch: 30, Time: 0.1203, Loss: 0.6427, TrainAcc: 0.8191, ValAcc: 0.7429, ES: 00/50 | BestVal=0.7429@E30\n",
      "Epoch: 40, Time: 0.1171, Loss: 0.5358, TrainAcc: 0.8495, ValAcc: 0.7481, ES: 04/50 | BestVal=0.7487@E36\n",
      "Epoch: 50, Time: 0.1191, Loss: 0.4805, TrainAcc: 0.8642, ValAcc: 0.7492, ES: 00/50 | BestVal=0.7492@E50\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name GCN seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name SAGE seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name RevGAT gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "[microsoft/deberta-base+MLP+E] TrainACC: 0.8463 ± 0.0042, ValACC: 0.7727 ± 0.003552795857008879, TestACC: 0.7729 ± 0.0017\n",
      "[microsoft/deberta-base+MLP+E+C] TrainACC: 0.8942 ± 0.0026, ValACC: 0.7754 ± 0.003508007440445362, TestACC: 0.7759 ± 0.0024\n",
      "[microsoft/deberta-base+MLP+E+S] TrainACC: 0.9999 ± 0.0000, ValACC: 0.7769 ± 0.0037171294239928578, TestACC: 0.7774 ± 0.0022\n",
      "[microsoft/deberta-base+MLP+Ensemble] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+C] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+S] TrainACC: 1.0000 ± 0.0000, ValACC: 0.7960 ± 0.005033340239927864, TestACC: 0.7983 ± 0.0025\n",
      "[microsoft/deberta-base+MLP+P] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+C] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+S] TrainACC: 0.9941 ± 0.0005, ValACC: 0.7613 ± 0.005003680329394017, TestACC: 0.7609 ± 0.0040\n",
      "[microsoft/deberta-base+MLP+TA] TrainACC: 0.8992 ± 0.0122, ValACC: 0.7768 ± 0.0029445384979247926, TestACC: 0.7767 ± 0.0008\n",
      "[microsoft/deberta-base+MLP+TA+C] TrainACC: 0.9190 ± 0.0080, ValACC: 0.7779 ± 0.0030984655067618225, TestACC: 0.7777 ± 0.0016\n",
      "[microsoft/deberta-base+MLP+TA+S] TrainACC: 0.9960 ± 0.0003, ValACC: 0.7822 ± 0.003196307234983218, TestACC: 0.7820 ± 0.0026\n",
      "Running time: 8.94s\n",
      "params_dict: {'alpha': 0.2619006279952869, 'A': 1, 'num_propagations': 40, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_GCN_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.6506305925296677, 'A': 2, 'num_propagations': 100, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_SAGE_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.46236078615130993, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_RevGAT_TA_None_seed0.pred'\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"MLP\", \"GCN\", \"SAGE\", \"RevGAT\"]:\n",
    "    !python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\"\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name RevGAT seed $SEED runs $RUNS cas.use_lm_pred True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: pubmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"pubmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Node2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running train at 05-22 10:46:39\n",
      "Epoch: 0, Time: 21.0059, Loss: 4.0978, TrainAcc: 0.2275, ValAcc: 0.2246, ES: \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 35, in <module>\n",
      "    main(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 18, in main\n",
      "    trainer.train()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/utils.py\", line 80, in wrapper\n",
      "    ret = func(*args, **kw)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 106, in train\n",
      "    val_acc, _, _ = self._evaluate()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 88, in _evaluate\n",
      "    test_acc = self.model.test(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch_geometric/nn/models/node2vec.py\", line 185, in test\n",
      "    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1302, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 452, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 359, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 279, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 253, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainNode2Vec dataset $dataset seed $SEED runs $RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP and GNNs on TAPE Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name GCN seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name SAGE seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name RevGAT gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "[microsoft/deberta-base+MLP+E] TrainACC: 0.8463 ± 0.0042, ValACC: 0.7727 ± 0.003552795857008879, TestACC: 0.7729 ± 0.0017\n",
      "[microsoft/deberta-base+MLP+E+C] TrainACC: 0.8942 ± 0.0026, ValACC: 0.7754 ± 0.003508007440445362, TestACC: 0.7759 ± 0.0024\n",
      "[microsoft/deberta-base+MLP+E+S] TrainACC: 0.9999 ± 0.0000, ValACC: 0.7769 ± 0.0037171294239928578, TestACC: 0.7774 ± 0.0022\n",
      "[microsoft/deberta-base+MLP+Ensemble] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+C] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+S] TrainACC: 1.0000 ± 0.0000, ValACC: 0.7960 ± 0.005033340239927864, TestACC: 0.7983 ± 0.0025\n",
      "[microsoft/deberta-base+MLP+P] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+C] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+S] TrainACC: 0.9941 ± 0.0005, ValACC: 0.7613 ± 0.005003680329394017, TestACC: 0.7609 ± 0.0040\n",
      "[microsoft/deberta-base+MLP+TA] TrainACC: 0.8992 ± 0.0122, ValACC: 0.7768 ± 0.0029445384979247926, TestACC: 0.7767 ± 0.0008\n",
      "[microsoft/deberta-base+MLP+TA+C] TrainACC: 0.9190 ± 0.0080, ValACC: 0.7779 ± 0.0030984655067618225, TestACC: 0.7777 ± 0.0016\n",
      "[microsoft/deberta-base+MLP+TA+S] TrainACC: 0.9960 ± 0.0003, ValACC: 0.7822 ± 0.003196307234983218, TestACC: 0.7820 ± 0.0026\n",
      "Running time: 8.94s\n",
      "params_dict: {'alpha': 0.2619006279952869, 'A': 1, 'num_propagations': 40, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_GCN_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.6506305925296677, 'A': 2, 'num_propagations': 100, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_SAGE_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.46236078615130993, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_RevGAT_TA_None_seed0.pred'\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"MLP\", \"GCN\", \"SAGE\", \"RevGAT\"]:\n",
    "    !python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\"\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name RevGAT seed $SEED runs $RUNS cas.use_lm_pred True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset: cora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cora\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Node2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start running train at 05-22 10:46:39\n",
      "Epoch: 0, Time: 21.0059, Loss: 4.0978, TrainAcc: 0.2275, ValAcc: 0.2246, ES: \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 35, in <module>\n",
      "    main(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/trainNode2Vec.py\", line 18, in main\n",
      "    trainer.train()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/utils.py\", line 80, in wrapper\n",
      "    ret = func(*args, **kw)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 106, in train\n",
      "    val_acc, _, _ = self._evaluate()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/Node2Vec/node2vec.py\", line 88, in _evaluate\n",
      "    test_acc = self.model.test(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch_geometric/nn/models/node2vec.py\", line 185, in test\n",
      "    clf = LogisticRegression(solver=solver, multi_class=multi_class, *args,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/base.py\", line 1151, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1302, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 65, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/utils/parallel.py\", line 127, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 452, in _logistic_regression_path\n",
      "    opt_res = optimize.minimize(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_minimize.py\", line 696, in minimize\n",
      "    res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_lbfgsb_py.py\", line 359, in _minimize_lbfgsb\n",
      "    f, g = func_and_grad(x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 285, in fun_and_grad\n",
      "    self._update_fun()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 251, in _update_fun\n",
      "    self._update_fun_impl()\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 155, in update_fun\n",
      "    self.f = fun_wrapped(self.x)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py\", line 137, in fun_wrapped\n",
      "    fx = fun(np.copy(x), *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 76, in __call__\n",
      "    self._compute_if_needed(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/scipy/optimize/_optimize.py\", line 70, in _compute_if_needed\n",
      "    fg = self.fun(x, *args)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/linear_model/_linear_loss.py\", line 279, in loss_gradient\n",
      "    loss, grad_pointwise = self.base_loss.loss_gradient(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/sklearn/_loss/loss.py\", line 253, in loss_gradient\n",
      "    return self.closs.loss_gradient(\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python -m core.trainNode2Vec dataset $dataset seed $SEED runs $RUNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train MLP and GNNs on TAPE Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name GCN seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name SAGE seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name RevGAT gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS\n",
    "!python -m core.trainEnsemble dataset $dataset gnn.model.name MLP gnn.train.lr 0.002 gnn.train.dropout 0.5 seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run CaS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.9961917624425123, 'alpha2': 0.5574100522517761, 'A1': 1, 'A2': 2, 'num_propagations1': 90, 'num_propagations2': 10, 'train_only': True}\n",
      "params_dict: {'alpha': 0.5784546711803843, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "params_dict: {'alpha1': 0.3869533846146773, 'alpha2': 0.12930515080046406, 'A1': 0, 'A2': 2, 'num_propagations1': 100, 'num_propagations2': 40, 'train_only': True}\n",
      "params_dict: {'alpha': 0.20305970175605254, 'A': 1, 'num_propagations': 50, 'labels': ['train']}\n",
      "[microsoft/deberta-base+MLP+E] TrainACC: 0.8463 ± 0.0042, ValACC: 0.7727 ± 0.003552795857008879, TestACC: 0.7729 ± 0.0017\n",
      "[microsoft/deberta-base+MLP+E+C] TrainACC: 0.8942 ± 0.0026, ValACC: 0.7754 ± 0.003508007440445362, TestACC: 0.7759 ± 0.0024\n",
      "[microsoft/deberta-base+MLP+E+S] TrainACC: 0.9999 ± 0.0000, ValACC: 0.7769 ± 0.0037171294239928578, TestACC: 0.7774 ± 0.0022\n",
      "[microsoft/deberta-base+MLP+Ensemble] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+C] TrainACC: 0.8740 ± 0.0064, ValACC: 0.7942 ± 0.004804349730039408, TestACC: 0.7955 ± 0.0029\n",
      "[microsoft/deberta-base+MLP+Ensemble+S] TrainACC: 1.0000 ± 0.0000, ValACC: 0.7960 ± 0.005033340239927864, TestACC: 0.7983 ± 0.0025\n",
      "[microsoft/deberta-base+MLP+P] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+C] TrainACC: 0.7771 ± 0.0013, ValACC: 0.7563 ± 0.004156346733379623, TestACC: 0.7552 ± 0.0043\n",
      "[microsoft/deberta-base+MLP+P+S] TrainACC: 0.9941 ± 0.0005, ValACC: 0.7613 ± 0.005003680329394017, TestACC: 0.7609 ± 0.0040\n",
      "[microsoft/deberta-base+MLP+TA] TrainACC: 0.8992 ± 0.0122, ValACC: 0.7768 ± 0.0029445384979247926, TestACC: 0.7767 ± 0.0008\n",
      "[microsoft/deberta-base+MLP+TA+C] TrainACC: 0.9190 ± 0.0080, ValACC: 0.7779 ± 0.0030984655067618225, TestACC: 0.7777 ± 0.0016\n",
      "[microsoft/deberta-base+MLP+TA+S] TrainACC: 0.9960 ± 0.0003, ValACC: 0.7822 ± 0.003196307234983218, TestACC: 0.7820 ± 0.0026\n",
      "Running time: 8.94s\n",
      "params_dict: {'alpha': 0.2619006279952869, 'A': 1, 'num_propagations': 40, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_GCN_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.6506305925296677, 'A': 2, 'num_propagations': 100, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_SAGE_TA_None_seed0.pred'\n",
      "params_dict: {'alpha': 0.46236078615130993, 'A': 1, 'num_propagations': 90, 'labels': ['train']}\n",
      "Traceback (most recent call last):\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 55, in <module>\n",
      "    run(cfg)\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/runCaS.py\", line 18, in run\n",
      "    tmp_result_df, tmp_raw_change_train_df, tmp_raw_change_valid_df, tmp_raw_change_test_df = runner.run()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 62, in run\n",
      "    model_preds = self._load_gnn_pred()\n",
      "  File \"/media/test/noppanat/tmp/TAPE-CaS/core/CaS/cas_runner.py\", line 362, in _load_gnn_pred\n",
      "    logits = torch.load(\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 699, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/media/test/noppanat/miniconda3/envs/cs471/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'output/arxiv_2023/microsoft/deberta-base_RevGAT_TA_None_seed0.pred'\n"
     ]
    }
   ],
   "source": [
    "for model_name in [\"MLP\", \"GCN\", \"SAGE\", \"RevGAT\"]:\n",
    "    !python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name $model_name seed $SEED runs $RUNS gnn.train.use_emb \"node2vec\"\n",
    "!python -m core.runCaS dataset $dataset gnn.model.name RevGAT seed $SEED runs $RUNS cas.use_lm_pred True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs471",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
